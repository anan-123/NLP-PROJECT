{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKQ4bH7qMGrA"
      },
      "source": [
        "# Making the Most of your Colab Subscription\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMMqmdiYMkvi"
      },
      "source": [
        "## Faster GPUs\n",
        "\n",
        "With Colab Pro you have priority access to our fastest GPUs and with Pro+ even more so. For example, you may get a T4 or P100 GPU at times when most users of standard Colab receive a slower K80 GPU. You can see what GPU you've been assigned at any time by executing the following cell.\n",
        "\n",
        "If the execution result of running the code cell below is \"Not connected to a GPU\", you can change the runtime by going to Runtime > Change runtime type in the menu to enable a GPU accelerator, and then re-execute the code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23TOba33L4qf",
        "outputId": "80f56f9f-f861-4dc3-ace9-c725d9d94d18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not connected to a GPU\n"
          ]
        }
      ],
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa-IrJS1aRVJ"
      },
      "source": [
        "In order to use a GPU with your notebook, select the Runtime > Change runtime type menu, and then set the hardware accelerator dropdown to GPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65MSuHKqNeBZ"
      },
      "source": [
        "## More memory\n",
        "\n",
        "With Colab Pro you have the option to access high-memory VMs when they are available, and with Pro+ even more so. To set your notebook preference to use a high-memory runtime, select the Runtime > 'Change runtime type' menu, and then select High-RAM in the Runtime shape dropdown.\n",
        "\n",
        "You can see how much memory you have available at any time by running the following code cell.\n",
        "\n",
        "\n",
        "\n",
        "If the execution result of running the code cell below is \"Not using a high-RAM runtime\", then you can enable a high-RAM runtime via Runtime > Change runtime type in the menu. Then select High-RAM in the Runtime shape dropdown. After, re-execute the code cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1G82GuO-tez",
        "outputId": "b68c593b-43b0-48e5-b735-ddc3d2a13bb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 37.8 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ],
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVBwSVDdWXQv",
        "outputId": "cc3c55cc-fc7a-49a1-f594-8f68ef4064dc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "import helper\n",
        "import numpy as np\n",
        "#import project_tests as tests\n",
        "import pandas as pd\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
        "from keras.layers.embeddings import Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.losses import categorical_crossentropy\n",
        "!cp \"/content/drive/My Drive/eng_dataset.txt\" .\n",
        "file_en = open('eng_dataset.txt','r')\n",
        "en_iter = iter(file_en)\n",
        "\n",
        "data=[]\n",
        "count = 0\n",
        "for line in en_iter:\n",
        "  if count < 6000:\n",
        "    data.append(line)\n",
        "    count=count+1\n",
        "  else:\n",
        "    break\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "print('Dataset Loaded')\n",
        "\n",
        "\n",
        "\n",
        "# Preprocess data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(data)\n",
        "vocab = tokenizer.word_index\n",
        "seqs = tokenizer.texts_to_sequences(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKIPBtvNWaXf",
        "outputId": "ddf256d5-6c81-43ab-c616-fefddc849e00"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izl9vO18T785",
        "outputId": "81425f21-9b47-4430-f17c-13b606c4336a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9301\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_sentence(seq, maxlen):\n",
        "    # Pads seq and slides windows\n",
        "    x = []\n",
        "    y = []\n",
        "    for i, w in enumerate(seq):\n",
        "        x_padded = pad_sequences([seq[:i]],\n",
        "                                 maxlen=maxlen - 1,\n",
        "                                 padding='pre')[0]  # Pads before each sequence\n",
        "       \n",
        "        #x=x_padded\n",
        "        x.append(x_padded)\n",
        "        y.append(w)\n",
        "        \n",
        "    return x, y\n",
        "\n",
        "# Pad sequences and slide windows\n",
        "maxlen = max([len(seq) for seq in seqs])\n",
        "x = []\n",
        "y = []\n",
        "for seq in seqs:\n",
        "    x_windows, y_windows = prepare_sentence(seq, maxlen)\n",
        "    x += x_windows \n",
        "    y += y_windows\n",
        "x = np.array(x)\n",
        "y = np.array(y) - 1  # The word <PAD> does not constitute a class\n",
        "#a=len(y)\n",
        "#b=len(vocab)\n",
        "#y = np.zeros((364226, 100), int)\n",
        "#y = np.zeros((a, b), int)\n",
        "#np.fill_diagonal(y, 1)\n",
        "#y = np.eye(len(vocab))[y]  # One hot encoding\n"
      ],
      "metadata": {
        "id": "EshhLB9pWfoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.eye(len(vocab))[y]"
      ],
      "metadata": {
        "id": "Xgjz2Lq2aQ4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xc= range(8)\n",
        "plt.figure()\n",
        "plt.plot(xc, train_loss)\n",
        "\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")"
      ],
      "metadata": {
        "id": "snLMp2CqiX5m",
        "outputId": "694d3161-e5c4-4e45-bf35-eeaeb409573d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import History \n",
        "from keras import callbacks\n",
        "import matplotlib.pyplot as plt\n",
        "# Define model\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=len(vocab) + 1,  # vocabulary size. Adding an\n",
        "                                            # extra element for <PAD> word\n",
        "                output_dim=6,  # size of embeddings\n",
        "                input_length=maxlen - 1))  # length of the padded sequences\n",
        "    model.add(LSTM(12))\n",
        "    model.add(Dropout(0.3))\n",
        "    model.add(Dense(len(vocab), activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(len(vocab), activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train network\n",
        "#model.fit(x, y, batch_size = 100,epochs=10,validation_split = 0.01)\n",
        "model_ckpt= create_model()\n",
        "checkpoint_path = \"./train_ckpt/cp.ckpt\"\n",
        "#cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,save_best_only=True, save_weights_only=True, verbose=1)\n",
        "cp_callback = callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    save_freq=2)\n",
        "model_ckpt.fit(x, y, batch_size = 100,epochs=10,validation_split = 0.01,callbacks=[cp_callback])\n",
        "train_loss = model_ckpt.history.history['loss']\n",
        "val_loss   = model_ckpt.history.history['val_loss']\n",
        "\n",
        "xc= range(10)\n",
        "plt.figure()\n",
        "plt.plo19(xc, train_loss)\n",
        "plt.plot(xc, val_loss)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SxEUHAzDWvoT",
        "outputId": "867a0a28-5e20-4ba8-db3d-28847aad3522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "1149/1615 [====================>.........] - ETA: 33:23 - loss: 6.3711 - accuracy: 0.1043\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1151/1615 [====================>.........] - ETA: 33:15 - loss: 6.3710 - accuracy: 0.1043\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1153/1615 [====================>.........] - ETA: 33:06 - loss: 6.3712 - accuracy: 0.1042\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1155/1615 [====================>.........] - ETA: 32:57 - loss: 6.3709 - accuracy: 0.1043\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1157/1615 [====================>.........] - ETA: 32:48 - loss: 6.3711 - accuracy: 0.1042\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1159/1615 [====================>.........] - ETA: 32:40 - loss: 6.3706 - accuracy: 0.1043\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1161/1615 [====================>.........] - ETA: 32:31 - loss: 6.3708 - accuracy: 0.1043\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1163/1615 [====================>.........] - ETA: 32:23 - loss: 6.3702 - accuracy: 0.1043\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1165/1615 [====================>.........] - ETA: 32:14 - loss: 6.3704 - accuracy: 0.1042\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1167/1615 [====================>.........] - ETA: 32:06 - loss: 6.3707 - accuracy: 0.1042\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1169/1615 [====================>.........] - ETA: 31:57 - loss: 6.3701 - accuracy: 0.1042\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1171/1615 [====================>.........] - ETA: 31:48 - loss: 6.3700 - accuracy: 0.1043\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1173/1615 [====================>.........] - ETA: 31:40 - loss: 6.3695 - accuracy: 0.1043\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1175/1615 [====================>.........] - ETA: 31:31 - loss: 6.3698 - accuracy: 0.1043\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1177/1615 [====================>.........] - ETA: 31:22 - loss: 6.3701 - accuracy: 0.1043\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1179/1615 [====================>.........] - ETA: 31:14 - loss: 6.3696 - accuracy: 0.1043\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1181/1615 [====================>.........] - ETA: 31:06 - loss: 6.3697 - accuracy: 0.1043\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1183/1615 [====================>.........] - ETA: 30:57 - loss: 6.3698 - accuracy: 0.1043\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1185/1615 [=====================>........] - ETA: 30:49 - loss: 6.3701 - accuracy: 0.1044\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1187/1615 [=====================>........] - ETA: 30:40 - loss: 6.3704 - accuracy: 0.1044\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1189/1615 [=====================>........] - ETA: 30:31 - loss: 6.3699 - accuracy: 0.1044\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1191/1615 [=====================>........] - ETA: 30:22 - loss: 6.3694 - accuracy: 0.1044\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1193/1615 [=====================>........] - ETA: 30:14 - loss: 6.3685 - accuracy: 0.1044\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1195/1615 [=====================>........] - ETA: 30:05 - loss: 6.3684 - accuracy: 0.1044\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1197/1615 [=====================>........] - ETA: 29:57 - loss: 6.3683 - accuracy: 0.1045\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1199/1615 [=====================>........] - ETA: 29:48 - loss: 6.3681 - accuracy: 0.1045\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1201/1615 [=====================>........] - ETA: 29:40 - loss: 6.3681 - accuracy: 0.1045\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1203/1615 [=====================>........] - ETA: 29:31 - loss: 6.3679 - accuracy: 0.1045\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1205/1615 [=====================>........] - ETA: 29:22 - loss: 6.3682 - accuracy: 0.1045\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1207/1615 [=====================>........] - ETA: 29:14 - loss: 6.3678 - accuracy: 0.1045\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1209/1615 [=====================>........] - ETA: 29:05 - loss: 6.3680 - accuracy: 0.1045\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1211/1615 [=====================>........] - ETA: 28:56 - loss: 6.3683 - accuracy: 0.1046\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1213/1615 [=====================>........] - ETA: 28:48 - loss: 6.3679 - accuracy: 0.1046\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1215/1615 [=====================>........] - ETA: 28:39 - loss: 6.3678 - accuracy: 0.1046\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1217/1615 [=====================>........] - ETA: 28:31 - loss: 6.3674 - accuracy: 0.1046\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1219/1615 [=====================>........] - ETA: 28:22 - loss: 6.3675 - accuracy: 0.1046\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1221/1615 [=====================>........] - ETA: 28:14 - loss: 6.3678 - accuracy: 0.1046\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1223/1615 [=====================>........] - ETA: 28:05 - loss: 6.3677 - accuracy: 0.1046\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1225/1615 [=====================>........] - ETA: 27:56 - loss: 6.3676 - accuracy: 0.1046\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1227/1615 [=====================>........] - ETA: 27:48 - loss: 6.3685 - accuracy: 0.1046\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1229/1615 [=====================>........] - ETA: 27:39 - loss: 6.3684 - accuracy: 0.1046\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1231/1615 [=====================>........] - ETA: 27:30 - loss: 6.3686 - accuracy: 0.1046\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1233/1615 [=====================>........] - ETA: 27:22 - loss: 6.3688 - accuracy: 0.1047\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1235/1615 [=====================>........] - ETA: 27:13 - loss: 6.3686 - accuracy: 0.1047\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1237/1615 [=====================>........] - ETA: 27:05 - loss: 6.3686 - accuracy: 0.1047\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1239/1615 [======================>.......] - ETA: 26:56 - loss: 6.3691 - accuracy: 0.1047\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1241/1615 [======================>.......] - ETA: 26:47 - loss: 6.3690 - accuracy: 0.1047\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1243/1615 [======================>.......] - ETA: 26:39 - loss: 6.3691 - accuracy: 0.1047\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1245/1615 [======================>.......] - ETA: 26:30 - loss: 6.3691 - accuracy: 0.1047\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1247/1615 [======================>.......] - ETA: 26:22 - loss: 6.3684 - accuracy: 0.1048\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1249/1615 [======================>.......] - ETA: 26:13 - loss: 6.3685 - accuracy: 0.1048\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1251/1615 [======================>.......] - ETA: 26:05 - loss: 6.3685 - accuracy: 0.1047\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1253/1615 [======================>.......] - ETA: 25:56 - loss: 6.3684 - accuracy: 0.1047\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1255/1615 [======================>.......] - ETA: 25:47 - loss: 6.3683 - accuracy: 0.1047\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1257/1615 [======================>.......] - ETA: 25:39 - loss: 6.3685 - accuracy: 0.1047\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1259/1615 [======================>.......] - ETA: 25:30 - loss: 6.3690 - accuracy: 0.1047\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1261/1615 [======================>.......] - ETA: 25:22 - loss: 6.3685 - accuracy: 0.1047\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1263/1615 [======================>.......] - ETA: 25:13 - loss: 6.3681 - accuracy: 0.1048\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1265/1615 [======================>.......] - ETA: 25:04 - loss: 6.3682 - accuracy: 0.1048\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1267/1615 [======================>.......] - ETA: 24:56 - loss: 6.3680 - accuracy: 0.1048\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1269/1615 [======================>.......] - ETA: 24:47 - loss: 6.3679 - accuracy: 0.1048\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1271/1615 [======================>.......] - ETA: 24:39 - loss: 6.3671 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1273/1615 [======================>.......] - ETA: 24:30 - loss: 6.3672 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1275/1615 [======================>.......] - ETA: 24:21 - loss: 6.3675 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1277/1615 [======================>.......] - ETA: 24:13 - loss: 6.3671 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1279/1615 [======================>.......] - ETA: 24:04 - loss: 6.3666 - accuracy: 0.1050\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1281/1615 [======================>.......] - ETA: 23:55 - loss: 6.3671 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1283/1615 [======================>.......] - ETA: 23:47 - loss: 6.3672 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1285/1615 [======================>.......] - ETA: 23:38 - loss: 6.3678 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1287/1615 [======================>.......] - ETA: 23:30 - loss: 6.3673 - accuracy: 0.1050\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1289/1615 [======================>.......] - ETA: 23:21 - loss: 6.3676 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1291/1615 [======================>.......] - ETA: 23:12 - loss: 6.3680 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1293/1615 [=======================>......] - ETA: 23:04 - loss: 6.3681 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1295/1615 [=======================>......] - ETA: 22:56 - loss: 6.3679 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1297/1615 [=======================>......] - ETA: 22:47 - loss: 6.3677 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1299/1615 [=======================>......] - ETA: 22:38 - loss: 6.3678 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1301/1615 [=======================>......] - ETA: 22:29 - loss: 6.3677 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1303/1615 [=======================>......] - ETA: 22:21 - loss: 6.3674 - accuracy: 0.1050\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1305/1615 [=======================>......] - ETA: 22:12 - loss: 6.3674 - accuracy: 0.1050\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1307/1615 [=======================>......] - ETA: 22:04 - loss: 6.3676 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1309/1615 [=======================>......] - ETA: 21:55 - loss: 6.3682 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1311/1615 [=======================>......] - ETA: 21:47 - loss: 6.3684 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1313/1615 [=======================>......] - ETA: 21:38 - loss: 6.3678 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1315/1615 [=======================>......] - ETA: 21:29 - loss: 6.3678 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1317/1615 [=======================>......] - ETA: 21:21 - loss: 6.3676 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1319/1615 [=======================>......] - ETA: 21:12 - loss: 6.3679 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1321/1615 [=======================>......] - ETA: 21:03 - loss: 6.3680 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1323/1615 [=======================>......] - ETA: 20:55 - loss: 6.3678 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1325/1615 [=======================>......] - ETA: 20:46 - loss: 6.3681 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1327/1615 [=======================>......] - ETA: 20:38 - loss: 6.3677 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1329/1615 [=======================>......] - ETA: 20:29 - loss: 6.3675 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1331/1615 [=======================>......] - ETA: 20:21 - loss: 6.3673 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1333/1615 [=======================>......] - ETA: 20:12 - loss: 6.3670 - accuracy: 0.1049\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1335/1615 [=======================>......] - ETA: 20:03 - loss: 6.3668 - accuracy: 0.1050\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1337/1615 [=======================>......] - ETA: 19:55 - loss: 6.3669 - accuracy: 0.1050\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1339/1615 [=======================>......] - ETA: 19:46 - loss: 6.3669 - accuracy: 0.1050\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1341/1615 [=======================>......] - ETA: 19:38 - loss: 6.3664 - accuracy: 0.1051\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1343/1615 [=======================>......] - ETA: 19:29 - loss: 6.3664 - accuracy: 0.1051\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1345/1615 [=======================>......] - ETA: 19:20 - loss: 6.3663 - accuracy: 0.1050\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1347/1615 [========================>.....] - ETA: 19:12 - loss: 6.3661 - accuracy: 0.1050\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1349/1615 [========================>.....] - ETA: 19:03 - loss: 6.3663 - accuracy: 0.1050\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1351/1615 [========================>.....] - ETA: 18:55 - loss: 6.3664 - accuracy: 0.1050\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1353/1615 [========================>.....] - ETA: 18:46 - loss: 6.3663 - accuracy: 0.1051\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1355/1615 [========================>.....] - ETA: 18:37 - loss: 6.3662 - accuracy: 0.1051\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1357/1615 [========================>.....] - ETA: 18:29 - loss: 6.3660 - accuracy: 0.1052\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1359/1615 [========================>.....] - ETA: 18:20 - loss: 6.3657 - accuracy: 0.1052\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1361/1615 [========================>.....] - ETA: 18:12 - loss: 6.3656 - accuracy: 0.1052\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1363/1615 [========================>.....] - ETA: 18:03 - loss: 6.3656 - accuracy: 0.1052\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1365/1615 [========================>.....] - ETA: 17:54 - loss: 6.3656 - accuracy: 0.1052\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1367/1615 [========================>.....] - ETA: 17:46 - loss: 6.3655 - accuracy: 0.1052\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1369/1615 [========================>.....] - ETA: 17:37 - loss: 6.3653 - accuracy: 0.1052\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1371/1615 [========================>.....] - ETA: 17:29 - loss: 6.3657 - accuracy: 0.1051\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1373/1615 [========================>.....] - ETA: 17:20 - loss: 6.3651 - accuracy: 0.1052\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1375/1615 [========================>.....] - ETA: 17:11 - loss: 6.3655 - accuracy: 0.1052\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1377/1615 [========================>.....] - ETA: 17:03 - loss: 6.3655 - accuracy: 0.1052\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1379/1615 [========================>.....] - ETA: 16:54 - loss: 6.3653 - accuracy: 0.1053\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1381/1615 [========================>.....] - ETA: 16:46 - loss: 6.3654 - accuracy: 0.1052\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1383/1615 [========================>.....] - ETA: 16:37 - loss: 6.3658 - accuracy: 0.1052\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1385/1615 [========================>.....] - ETA: 16:29 - loss: 6.3653 - accuracy: 0.1053\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1387/1615 [========================>.....] - ETA: 16:20 - loss: 6.3652 - accuracy: 0.1053\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1389/1615 [========================>.....] - ETA: 16:11 - loss: 6.3653 - accuracy: 0.1053\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1391/1615 [========================>.....] - ETA: 16:03 - loss: 6.3654 - accuracy: 0.1053\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1393/1615 [========================>.....] - ETA: 15:54 - loss: 6.3658 - accuracy: 0.1053\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1395/1615 [========================>.....] - ETA: 15:45 - loss: 6.3659 - accuracy: 0.1053\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1397/1615 [========================>.....] - ETA: 15:37 - loss: 6.3660 - accuracy: 0.1053\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1399/1615 [========================>.....] - ETA: 15:28 - loss: 6.3657 - accuracy: 0.1053\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1401/1615 [=========================>....] - ETA: 15:20 - loss: 6.3654 - accuracy: 0.1054\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1403/1615 [=========================>....] - ETA: 15:11 - loss: 6.3657 - accuracy: 0.1054\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1405/1615 [=========================>....] - ETA: 15:02 - loss: 6.3653 - accuracy: 0.1054\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1407/1615 [=========================>....] - ETA: 14:54 - loss: 6.3651 - accuracy: 0.1054\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1409/1615 [=========================>....] - ETA: 14:45 - loss: 6.3652 - accuracy: 0.1053\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1411/1615 [=========================>....] - ETA: 14:37 - loss: 6.3655 - accuracy: 0.1054\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1413/1615 [=========================>....] - ETA: 14:28 - loss: 6.3653 - accuracy: 0.1054\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1415/1615 [=========================>....] - ETA: 14:20 - loss: 6.3648 - accuracy: 0.1054\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1417/1615 [=========================>....] - ETA: 14:11 - loss: 6.3645 - accuracy: 0.1054\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1419/1615 [=========================>....] - ETA: 14:02 - loss: 6.3641 - accuracy: 0.1055\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1421/1615 [=========================>....] - ETA: 13:54 - loss: 6.3643 - accuracy: 0.1054\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1423/1615 [=========================>....] - ETA: 13:45 - loss: 6.3639 - accuracy: 0.1055\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1425/1615 [=========================>....] - ETA: 13:37 - loss: 6.3642 - accuracy: 0.1054\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1427/1615 [=========================>....] - ETA: 13:28 - loss: 6.3642 - accuracy: 0.1054\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1429/1615 [=========================>....] - ETA: 13:20 - loss: 6.3642 - accuracy: 0.1054\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1431/1615 [=========================>....] - ETA: 13:11 - loss: 6.3641 - accuracy: 0.1054\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1433/1615 [=========================>....] - ETA: 13:02 - loss: 6.3641 - accuracy: 0.1054\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1435/1615 [=========================>....] - ETA: 12:53 - loss: 6.3641 - accuracy: 0.1054\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1437/1615 [=========================>....] - ETA: 12:45 - loss: 6.3641 - accuracy: 0.1055\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1439/1615 [=========================>....] - ETA: 12:37 - loss: 6.3639 - accuracy: 0.1055\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1441/1615 [=========================>....] - ETA: 12:28 - loss: 6.3642 - accuracy: 0.1055\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1443/1615 [=========================>....] - ETA: 12:19 - loss: 6.3641 - accuracy: 0.1055\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1445/1615 [=========================>....] - ETA: 12:11 - loss: 6.3640 - accuracy: 0.1055\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1447/1615 [=========================>....] - ETA: 12:02 - loss: 6.3644 - accuracy: 0.1055\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1449/1615 [=========================>....] - ETA: 11:53 - loss: 6.3639 - accuracy: 0.1055\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1451/1615 [=========================>....] - ETA: 11:45 - loss: 6.3639 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1453/1615 [=========================>....] - ETA: 11:36 - loss: 6.3638 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1455/1615 [==========================>...] - ETA: 11:28 - loss: 6.3636 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1457/1615 [==========================>...] - ETA: 11:19 - loss: 6.3639 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1459/1615 [==========================>...] - ETA: 11:10 - loss: 6.3643 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1461/1615 [==========================>...] - ETA: 11:02 - loss: 6.3652 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1463/1615 [==========================>...] - ETA: 10:53 - loss: 6.3651 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1465/1615 [==========================>...] - ETA: 10:44 - loss: 6.3651 - accuracy: 0.1055\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1467/1615 [==========================>...] - ETA: 10:36 - loss: 6.3649 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1469/1615 [==========================>...] - ETA: 10:27 - loss: 6.3646 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1471/1615 [==========================>...] - ETA: 10:19 - loss: 6.3647 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1473/1615 [==========================>...] - ETA: 10:10 - loss: 6.3646 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1475/1615 [==========================>...] - ETA: 10:02 - loss: 6.3648 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1477/1615 [==========================>...] - ETA: 9:53 - loss: 6.3643 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1479/1615 [==========================>...] - ETA: 9:44 - loss: 6.3641 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1481/1615 [==========================>...] - ETA: 9:36 - loss: 6.3643 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1483/1615 [==========================>...] - ETA: 9:27 - loss: 6.3643 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1485/1615 [==========================>...] - ETA: 9:19 - loss: 6.3641 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1487/1615 [==========================>...] - ETA: 9:10 - loss: 6.3640 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1489/1615 [==========================>...] - ETA: 9:01 - loss: 6.3642 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1491/1615 [==========================>...] - ETA: 8:53 - loss: 6.3638 - accuracy: 0.1057\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1493/1615 [==========================>...] - ETA: 8:44 - loss: 6.3642 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1495/1615 [==========================>...] - ETA: 8:36 - loss: 6.3642 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1497/1615 [==========================>...] - ETA: 8:27 - loss: 6.3641 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1499/1615 [==========================>...] - ETA: 8:18 - loss: 6.3638 - accuracy: 0.1057\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1501/1615 [==========================>...] - ETA: 8:10 - loss: 6.3639 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1503/1615 [==========================>...] - ETA: 8:01 - loss: 6.3640 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1505/1615 [==========================>...] - ETA: 7:53 - loss: 6.3640 - accuracy: 0.1056\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1507/1615 [==========================>...] - ETA: 7:44 - loss: 6.3635 - accuracy: 0.1057\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1509/1615 [===========================>..] - ETA: 7:35 - loss: 6.3633 - accuracy: 0.1057\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1511/1615 [===========================>..] - ETA: 7:27 - loss: 6.3639 - accuracy: 0.1057\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1513/1615 [===========================>..] - ETA: 7:18 - loss: 6.3636 - accuracy: 0.1058\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1515/1615 [===========================>..] - ETA: 7:10 - loss: 6.3636 - accuracy: 0.1058\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1517/1615 [===========================>..] - ETA: 7:01 - loss: 6.3636 - accuracy: 0.1058\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1519/1615 [===========================>..] - ETA: 6:52 - loss: 6.3633 - accuracy: 0.1058\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1521/1615 [===========================>..] - ETA: 6:44 - loss: 6.3633 - accuracy: 0.1058\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1523/1615 [===========================>..] - ETA: 6:35 - loss: 6.3631 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1525/1615 [===========================>..] - ETA: 6:27 - loss: 6.3631 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1527/1615 [===========================>..] - ETA: 6:18 - loss: 6.3629 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1529/1615 [===========================>..] - ETA: 6:09 - loss: 6.3631 - accuracy: 0.1058\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1531/1615 [===========================>..] - ETA: 6:01 - loss: 6.3631 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1533/1615 [===========================>..] - ETA: 5:52 - loss: 6.3633 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1535/1615 [===========================>..] - ETA: 5:44 - loss: 6.3633 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1537/1615 [===========================>..] - ETA: 5:35 - loss: 6.3633 - accuracy: 0.1058\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1539/1615 [===========================>..] - ETA: 5:26 - loss: 6.3637 - accuracy: 0.1058\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1541/1615 [===========================>..] - ETA: 5:18 - loss: 6.3632 - accuracy: 0.1058\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1543/1615 [===========================>..] - ETA: 5:09 - loss: 6.3632 - accuracy: 0.1058\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1545/1615 [===========================>..] - ETA: 5:01 - loss: 6.3629 - accuracy: 0.1058\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1547/1615 [===========================>..] - ETA: 4:52 - loss: 6.3628 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1549/1615 [===========================>..] - ETA: 4:43 - loss: 6.3627 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1551/1615 [===========================>..] - ETA: 4:35 - loss: 6.3626 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1553/1615 [===========================>..] - ETA: 4:26 - loss: 6.3628 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1555/1615 [===========================>..] - ETA: 4:18 - loss: 6.3627 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1557/1615 [===========================>..] - ETA: 4:09 - loss: 6.3629 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1559/1615 [===========================>..] - ETA: 4:00 - loss: 6.3628 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1561/1615 [===========================>..] - ETA: 3:52 - loss: 6.3625 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1563/1615 [============================>.] - ETA: 3:43 - loss: 6.3622 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1565/1615 [============================>.] - ETA: 3:35 - loss: 6.3623 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1567/1615 [============================>.] - ETA: 3:26 - loss: 6.3623 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1569/1615 [============================>.] - ETA: 3:17 - loss: 6.3624 - accuracy: 0.1058\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1571/1615 [============================>.] - ETA: 3:09 - loss: 6.3625 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1573/1615 [============================>.] - ETA: 3:00 - loss: 6.3626 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1575/1615 [============================>.] - ETA: 2:52 - loss: 6.3629 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1577/1615 [============================>.] - ETA: 2:43 - loss: 6.3629 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1579/1615 [============================>.] - ETA: 2:34 - loss: 6.3629 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1581/1615 [============================>.] - ETA: 2:26 - loss: 6.3628 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1583/1615 [============================>.] - ETA: 2:17 - loss: 6.3630 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1585/1615 [============================>.] - ETA: 2:09 - loss: 6.3631 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1587/1615 [============================>.] - ETA: 2:00 - loss: 6.3629 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1589/1615 [============================>.] - ETA: 1:51 - loss: 6.3628 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1591/1615 [============================>.] - ETA: 1:43 - loss: 6.3630 - accuracy: 0.1058\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1593/1615 [============================>.] - ETA: 1:34 - loss: 6.3629 - accuracy: 0.1058\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1595/1615 [============================>.] - ETA: 1:26 - loss: 6.3629 - accuracy: 0.1058\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1597/1615 [============================>.] - ETA: 1:17 - loss: 6.3628 - accuracy: 0.1058\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1599/1615 [============================>.] - ETA: 1:08 - loss: 6.3624 - accuracy: 0.1059\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1601/1615 [============================>.] - ETA: 1:00 - loss: 6.3625 - accuracy: 0.1058\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1603/1615 [============================>.] - ETA: 51s - loss: 6.3625 - accuracy: 0.1058\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1605/1615 [============================>.] - ETA: 43s - loss: 6.3624 - accuracy: 0.1058\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1607/1615 [============================>.] - ETA: 34s - loss: 6.3621 - accuracy: 0.1058\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1609/1615 [============================>.] - ETA: 25s - loss: 6.3620 - accuracy: 0.1058\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1611/1615 [============================>.] - ETA: 17s - loss: 6.3616 - accuracy: 0.1058\n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1613/1615 [============================>.] - ETA: 8s - loss: 6.3615 - accuracy: 0.1058 \n",
            "Epoch 3: saving model to ./train_ckpt/cp.ckpt\n",
            "1615/1615 [==============================] - 6952s 4s/step - loss: 6.3614 - accuracy: 0.1058 - val_loss: 7.3447 - val_accuracy: 0.1115\n",
            "Epoch 4/10\n",
            "\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "   2/1615 [..............................] - ETA: 1:06:01 - loss: 6.3871 - accuracy: 0.0950\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "   4/1615 [..............................] - ETA: 1:38:34 - loss: 6.4073 - accuracy: 0.1050\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "   6/1615 [..............................] - ETA: 1:48:23 - loss: 6.2730 - accuracy: 0.1167\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "   8/1615 [..............................] - ETA: 1:50:35 - loss: 6.2492 - accuracy: 0.1213\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  10/1615 [..............................] - ETA: 1:52:00 - loss: 6.2079 - accuracy: 0.1250\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  12/1615 [..............................] - ETA: 1:52:19 - loss: 6.1654 - accuracy: 0.1292\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  14/1615 [..............................] - ETA: 1:52:36 - loss: 6.1632 - accuracy: 0.1257\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  16/1615 [..............................] - ETA: 1:52:21 - loss: 6.1668 - accuracy: 0.1269\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  18/1615 [..............................] - ETA: 1:52:11 - loss: 6.1706 - accuracy: 0.1250\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  20/1615 [..............................] - ETA: 1:51:58 - loss: 6.1680 - accuracy: 0.1235\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  22/1615 [..............................] - ETA: 1:52:08 - loss: 6.1691 - accuracy: 0.1227\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  24/1615 [..............................] - ETA: 1:51:24 - loss: 6.1798 - accuracy: 0.1221\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  26/1615 [..............................] - ETA: 1:50:53 - loss: 6.1842 - accuracy: 0.1200\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  28/1615 [..............................] - ETA: 1:50:32 - loss: 6.1975 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  30/1615 [..............................] - ETA: 1:50:09 - loss: 6.2004 - accuracy: 0.1190\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  32/1615 [..............................] - ETA: 1:49:38 - loss: 6.2030 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  34/1615 [..............................] - ETA: 1:49:13 - loss: 6.2135 - accuracy: 0.1182\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  36/1615 [..............................] - ETA: 1:49:18 - loss: 6.2200 - accuracy: 0.1169\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  38/1615 [..............................] - ETA: 1:49:21 - loss: 6.2096 - accuracy: 0.1179\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  40/1615 [..............................] - ETA: 1:49:12 - loss: 6.1934 - accuracy: 0.1200\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  42/1615 [..............................] - ETA: 1:49:07 - loss: 6.2014 - accuracy: 0.1195\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  44/1615 [..............................] - ETA: 1:48:53 - loss: 6.2017 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  46/1615 [..............................] - ETA: 1:48:34 - loss: 6.1990 - accuracy: 0.1196\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  48/1615 [..............................] - ETA: 1:48:38 - loss: 6.2011 - accuracy: 0.1192\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  50/1615 [..............................] - ETA: 1:48:29 - loss: 6.1975 - accuracy: 0.1204\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  52/1615 [..............................] - ETA: 1:48:20 - loss: 6.2056 - accuracy: 0.1194\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  54/1615 [>.............................] - ETA: 1:48:05 - loss: 6.2157 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  56/1615 [>.............................] - ETA: 1:47:56 - loss: 6.2298 - accuracy: 0.1177\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  58/1615 [>.............................] - ETA: 1:47:41 - loss: 6.2311 - accuracy: 0.1172\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  60/1615 [>.............................] - ETA: 1:47:33 - loss: 6.2242 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  62/1615 [>.............................] - ETA: 1:47:19 - loss: 6.2209 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  64/1615 [>.............................] - ETA: 1:47:19 - loss: 6.2252 - accuracy: 0.1180\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  66/1615 [>.............................] - ETA: 1:47:11 - loss: 6.2212 - accuracy: 0.1182\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  68/1615 [>.............................] - ETA: 1:46:58 - loss: 6.2194 - accuracy: 0.1182\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  70/1615 [>.............................] - ETA: 1:46:44 - loss: 6.2110 - accuracy: 0.1191\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  72/1615 [>.............................] - ETA: 1:46:47 - loss: 6.2009 - accuracy: 0.1194\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  74/1615 [>.............................] - ETA: 1:46:44 - loss: 6.2044 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  76/1615 [>.............................] - ETA: 1:46:41 - loss: 6.2020 - accuracy: 0.1174\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  78/1615 [>.............................] - ETA: 1:46:39 - loss: 6.2019 - accuracy: 0.1177\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  80/1615 [>.............................] - ETA: 1:46:38 - loss: 6.2021 - accuracy: 0.1175\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  82/1615 [>.............................] - ETA: 1:46:47 - loss: 6.2081 - accuracy: 0.1161\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  84/1615 [>.............................] - ETA: 1:46:34 - loss: 6.2154 - accuracy: 0.1156\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  86/1615 [>.............................] - ETA: 1:46:36 - loss: 6.2122 - accuracy: 0.1163\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  88/1615 [>.............................] - ETA: 1:46:22 - loss: 6.2141 - accuracy: 0.1165\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  90/1615 [>.............................] - ETA: 1:46:15 - loss: 6.2139 - accuracy: 0.1164\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  92/1615 [>.............................] - ETA: 1:46:30 - loss: 6.2200 - accuracy: 0.1160\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  94/1615 [>.............................] - ETA: 1:46:14 - loss: 6.2109 - accuracy: 0.1161\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  96/1615 [>.............................] - ETA: 1:46:11 - loss: 6.2142 - accuracy: 0.1156\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "  98/1615 [>.............................] - ETA: 1:45:53 - loss: 6.2138 - accuracy: 0.1155\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 100/1615 [>.............................] - ETA: 1:46:13 - loss: 6.2129 - accuracy: 0.1153\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 102/1615 [>.............................] - ETA: 1:45:57 - loss: 6.2112 - accuracy: 0.1158\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 104/1615 [>.............................] - ETA: 1:45:40 - loss: 6.2075 - accuracy: 0.1161\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 106/1615 [>.............................] - ETA: 1:45:34 - loss: 6.2026 - accuracy: 0.1160\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 108/1615 [=>............................] - ETA: 1:45:30 - loss: 6.1993 - accuracy: 0.1160\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 110/1615 [=>............................] - ETA: 1:45:36 - loss: 6.1985 - accuracy: 0.1163\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 112/1615 [=>............................] - ETA: 1:45:19 - loss: 6.1955 - accuracy: 0.1166\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 114/1615 [=>............................] - ETA: 1:45:11 - loss: 6.2019 - accuracy: 0.1161\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 116/1615 [=>............................] - ETA: 1:45:03 - loss: 6.2022 - accuracy: 0.1163\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 118/1615 [=>............................] - ETA: 1:45:02 - loss: 6.2032 - accuracy: 0.1163\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 120/1615 [=>............................] - ETA: 1:44:57 - loss: 6.1965 - accuracy: 0.1174\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 122/1615 [=>............................] - ETA: 1:44:49 - loss: 6.1899 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 124/1615 [=>............................] - ETA: 1:45:01 - loss: 6.1848 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 126/1615 [=>............................] - ETA: 1:44:46 - loss: 6.1823 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 128/1615 [=>............................] - ETA: 1:44:34 - loss: 6.1815 - accuracy: 0.1197\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 130/1615 [=>............................] - ETA: 1:44:26 - loss: 6.1847 - accuracy: 0.1198\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 132/1615 [=>............................] - ETA: 1:44:20 - loss: 6.1896 - accuracy: 0.1197\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 134/1615 [=>............................] - ETA: 1:44:14 - loss: 6.1894 - accuracy: 0.1196\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 136/1615 [=>............................] - ETA: 1:44:06 - loss: 6.1917 - accuracy: 0.1193\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 138/1615 [=>............................] - ETA: 1:43:57 - loss: 6.1843 - accuracy: 0.1196\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 140/1615 [=>............................] - ETA: 1:44:08 - loss: 6.1792 - accuracy: 0.1200\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 142/1615 [=>............................] - ETA: 1:43:53 - loss: 6.1817 - accuracy: 0.1196\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 144/1615 [=>............................] - ETA: 1:43:39 - loss: 6.1786 - accuracy: 0.1195\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 146/1615 [=>............................] - ETA: 1:43:32 - loss: 6.1809 - accuracy: 0.1194\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 148/1615 [=>............................] - ETA: 1:43:23 - loss: 6.1787 - accuracy: 0.1193\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 150/1615 [=>............................] - ETA: 1:43:18 - loss: 6.1807 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 152/1615 [=>............................] - ETA: 1:43:10 - loss: 6.1772 - accuracy: 0.1191\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 154/1615 [=>............................] - ETA: 1:43:01 - loss: 6.1733 - accuracy: 0.1197\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 156/1615 [=>............................] - ETA: 1:42:55 - loss: 6.1724 - accuracy: 0.1196\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 158/1615 [=>............................] - ETA: 1:42:47 - loss: 6.1710 - accuracy: 0.1198\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 160/1615 [=>............................] - ETA: 1:42:40 - loss: 6.1716 - accuracy: 0.1197\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 162/1615 [==>...........................] - ETA: 1:42:33 - loss: 6.1702 - accuracy: 0.1196\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 164/1615 [==>...........................] - ETA: 1:42:28 - loss: 6.1726 - accuracy: 0.1195\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 166/1615 [==>...........................] - ETA: 1:42:19 - loss: 6.1767 - accuracy: 0.1192\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 168/1615 [==>...........................] - ETA: 1:42:24 - loss: 6.1791 - accuracy: 0.1190\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 170/1615 [==>...........................] - ETA: 1:42:10 - loss: 6.1775 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 172/1615 [==>...........................] - ETA: 1:41:57 - loss: 6.1763 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 174/1615 [==>...........................] - ETA: 1:41:51 - loss: 6.1761 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 176/1615 [==>...........................] - ETA: 1:41:43 - loss: 6.1774 - accuracy: 0.1191\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 178/1615 [==>...........................] - ETA: 1:41:46 - loss: 6.1764 - accuracy: 0.1192\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 180/1615 [==>...........................] - ETA: 1:41:34 - loss: 6.1769 - accuracy: 0.1194\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 182/1615 [==>...........................] - ETA: 1:41:23 - loss: 6.1766 - accuracy: 0.1195\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 184/1615 [==>...........................] - ETA: 1:41:13 - loss: 6.1764 - accuracy: 0.1195\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 186/1615 [==>...........................] - ETA: 1:41:05 - loss: 6.1797 - accuracy: 0.1191\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 188/1615 [==>...........................] - ETA: 1:41:00 - loss: 6.1803 - accuracy: 0.1191\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 190/1615 [==>...........................] - ETA: 1:40:52 - loss: 6.1791 - accuracy: 0.1192\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 192/1615 [==>...........................] - ETA: 1:40:43 - loss: 6.1838 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 194/1615 [==>...........................] - ETA: 1:40:34 - loss: 6.1850 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 196/1615 [==>...........................] - ETA: 1:40:27 - loss: 6.1881 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 198/1615 [==>...........................] - ETA: 1:40:20 - loss: 6.1885 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 200/1615 [==>...........................] - ETA: 1:40:13 - loss: 6.1893 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 202/1615 [==>...........................] - ETA: 1:40:05 - loss: 6.1894 - accuracy: 0.1181\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 204/1615 [==>...........................] - ETA: 1:39:55 - loss: 6.1877 - accuracy: 0.1179\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 206/1615 [==>...........................] - ETA: 1:39:49 - loss: 6.1888 - accuracy: 0.1179\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 208/1615 [==>...........................] - ETA: 1:39:41 - loss: 6.1888 - accuracy: 0.1179\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 210/1615 [==>...........................] - ETA: 1:39:33 - loss: 6.1900 - accuracy: 0.1181\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 212/1615 [==>...........................] - ETA: 1:39:25 - loss: 6.1917 - accuracy: 0.1182\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 214/1615 [==>...........................] - ETA: 1:39:18 - loss: 6.1921 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 216/1615 [===>..........................] - ETA: 1:39:10 - loss: 6.1926 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 218/1615 [===>..........................] - ETA: 1:39:02 - loss: 6.1944 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 220/1615 [===>..........................] - ETA: 1:38:54 - loss: 6.1967 - accuracy: 0.1182\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 222/1615 [===>..........................] - ETA: 1:38:46 - loss: 6.1996 - accuracy: 0.1181\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 224/1615 [===>..........................] - ETA: 1:38:38 - loss: 6.2002 - accuracy: 0.1181\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 226/1615 [===>..........................] - ETA: 1:38:31 - loss: 6.1990 - accuracy: 0.1181\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 228/1615 [===>..........................] - ETA: 1:38:23 - loss: 6.2001 - accuracy: 0.1178\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 230/1615 [===>..........................] - ETA: 1:38:15 - loss: 6.2007 - accuracy: 0.1177\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 232/1615 [===>..........................] - ETA: 1:38:08 - loss: 6.2014 - accuracy: 0.1175\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 234/1615 [===>..........................] - ETA: 1:38:01 - loss: 6.1972 - accuracy: 0.1178\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 236/1615 [===>..........................] - ETA: 1:37:52 - loss: 6.1947 - accuracy: 0.1178\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 238/1615 [===>..........................] - ETA: 1:37:44 - loss: 6.1925 - accuracy: 0.1179\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 240/1615 [===>..........................] - ETA: 1:37:35 - loss: 6.1895 - accuracy: 0.1178\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 242/1615 [===>..........................] - ETA: 1:37:27 - loss: 6.1913 - accuracy: 0.1175\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 244/1615 [===>..........................] - ETA: 1:37:30 - loss: 6.1923 - accuracy: 0.1173\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 246/1615 [===>..........................] - ETA: 1:37:19 - loss: 6.1883 - accuracy: 0.1174\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 248/1615 [===>..........................] - ETA: 1:37:08 - loss: 6.1878 - accuracy: 0.1173\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 250/1615 [===>..........................] - ETA: 1:36:58 - loss: 6.1871 - accuracy: 0.1173\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 252/1615 [===>..........................] - ETA: 1:36:46 - loss: 6.1855 - accuracy: 0.1173\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 254/1615 [===>..........................] - ETA: 1:36:39 - loss: 6.1859 - accuracy: 0.1176\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 256/1615 [===>..........................] - ETA: 1:36:32 - loss: 6.1866 - accuracy: 0.1175\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 258/1615 [===>..........................] - ETA: 1:36:29 - loss: 6.1853 - accuracy: 0.1174\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 260/1615 [===>..........................] - ETA: 1:36:22 - loss: 6.1869 - accuracy: 0.1172\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 262/1615 [===>..........................] - ETA: 1:36:12 - loss: 6.1859 - accuracy: 0.1173\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 264/1615 [===>..........................] - ETA: 1:35:59 - loss: 6.1875 - accuracy: 0.1171\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 266/1615 [===>..........................] - ETA: 1:35:58 - loss: 6.1868 - accuracy: 0.1171\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 268/1615 [===>..........................] - ETA: 1:35:47 - loss: 6.1884 - accuracy: 0.1173\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 270/1615 [====>.........................] - ETA: 1:35:42 - loss: 6.1842 - accuracy: 0.1177\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 272/1615 [====>.........................] - ETA: 1:35:30 - loss: 6.1851 - accuracy: 0.1176\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 274/1615 [====>.........................] - ETA: 1:35:22 - loss: 6.1846 - accuracy: 0.1177\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 276/1615 [====>.........................] - ETA: 1:35:13 - loss: 6.1815 - accuracy: 0.1180\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 278/1615 [====>.........................] - ETA: 1:35:01 - loss: 6.1821 - accuracy: 0.1178\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 280/1615 [====>.........................] - ETA: 1:34:52 - loss: 6.1854 - accuracy: 0.1177\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 282/1615 [====>.........................] - ETA: 1:34:43 - loss: 6.1863 - accuracy: 0.1176\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 284/1615 [====>.........................] - ETA: 1:34:47 - loss: 6.1851 - accuracy: 0.1180\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 286/1615 [====>.........................] - ETA: 1:34:35 - loss: 6.1859 - accuracy: 0.1179\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 288/1615 [====>.........................] - ETA: 1:34:25 - loss: 6.1869 - accuracy: 0.1177\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 290/1615 [====>.........................] - ETA: 1:34:15 - loss: 6.1876 - accuracy: 0.1177\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 292/1615 [====>.........................] - ETA: 1:34:05 - loss: 6.1896 - accuracy: 0.1176\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 294/1615 [====>.........................] - ETA: 1:33:56 - loss: 6.1880 - accuracy: 0.1177\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 296/1615 [====>.........................] - ETA: 1:33:48 - loss: 6.1867 - accuracy: 0.1177\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 298/1615 [====>.........................] - ETA: 1:33:46 - loss: 6.1870 - accuracy: 0.1176\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 300/1615 [====>.........................] - ETA: 1:33:35 - loss: 6.1875 - accuracy: 0.1177\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 302/1615 [====>.........................] - ETA: 1:33:26 - loss: 6.1875 - accuracy: 0.1175\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 304/1615 [====>.........................] - ETA: 1:33:15 - loss: 6.1877 - accuracy: 0.1172\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 306/1615 [====>.........................] - ETA: 1:33:07 - loss: 6.1877 - accuracy: 0.1173\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 308/1615 [====>.........................] - ETA: 1:32:59 - loss: 6.1848 - accuracy: 0.1175\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 310/1615 [====>.........................] - ETA: 1:32:51 - loss: 6.1841 - accuracy: 0.1174\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 312/1615 [====>.........................] - ETA: 1:32:45 - loss: 6.1845 - accuracy: 0.1175\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 314/1615 [====>.........................] - ETA: 1:32:33 - loss: 6.1857 - accuracy: 0.1174\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 316/1615 [====>.........................] - ETA: 1:32:31 - loss: 6.1860 - accuracy: 0.1172\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 318/1615 [====>.........................] - ETA: 1:32:21 - loss: 6.1875 - accuracy: 0.1171\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 320/1615 [====>.........................] - ETA: 1:32:09 - loss: 6.1860 - accuracy: 0.1171\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 322/1615 [====>.........................] - ETA: 1:32:00 - loss: 6.1847 - accuracy: 0.1171\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 324/1615 [=====>........................] - ETA: 1:31:52 - loss: 6.1870 - accuracy: 0.1169\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 326/1615 [=====>........................] - ETA: 1:31:50 - loss: 6.1862 - accuracy: 0.1170\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 328/1615 [=====>........................] - ETA: 1:31:38 - loss: 6.1868 - accuracy: 0.1170\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 330/1615 [=====>........................] - ETA: 1:31:28 - loss: 6.1849 - accuracy: 0.1174\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 332/1615 [=====>........................] - ETA: 1:31:19 - loss: 6.1854 - accuracy: 0.1172\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 334/1615 [=====>........................] - ETA: 1:31:16 - loss: 6.1867 - accuracy: 0.1171\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 336/1615 [=====>........................] - ETA: 1:31:07 - loss: 6.1879 - accuracy: 0.1171\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 338/1615 [=====>........................] - ETA: 1:30:58 - loss: 6.1895 - accuracy: 0.1170\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 340/1615 [=====>........................] - ETA: 1:30:48 - loss: 6.1898 - accuracy: 0.1171\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 342/1615 [=====>........................] - ETA: 1:30:39 - loss: 6.1904 - accuracy: 0.1171\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 344/1615 [=====>........................] - ETA: 1:30:31 - loss: 6.1919 - accuracy: 0.1169\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 346/1615 [=====>........................] - ETA: 1:30:23 - loss: 6.1921 - accuracy: 0.1170\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 348/1615 [=====>........................] - ETA: 1:30:14 - loss: 6.1927 - accuracy: 0.1169\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 350/1615 [=====>........................] - ETA: 1:30:05 - loss: 6.1943 - accuracy: 0.1167\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 352/1615 [=====>........................] - ETA: 1:29:57 - loss: 6.1958 - accuracy: 0.1167\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 354/1615 [=====>........................] - ETA: 1:29:49 - loss: 6.1949 - accuracy: 0.1168\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 356/1615 [=====>........................] - ETA: 1:29:40 - loss: 6.1943 - accuracy: 0.1169\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 358/1615 [=====>........................] - ETA: 1:29:31 - loss: 6.1945 - accuracy: 0.1169\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 360/1615 [=====>........................] - ETA: 1:29:23 - loss: 6.1933 - accuracy: 0.1169\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 362/1615 [=====>........................] - ETA: 1:29:18 - loss: 6.1939 - accuracy: 0.1170\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 364/1615 [=====>........................] - ETA: 1:29:06 - loss: 6.1936 - accuracy: 0.1168\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 366/1615 [=====>........................] - ETA: 1:28:57 - loss: 6.1918 - accuracy: 0.1169\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 368/1615 [=====>........................] - ETA: 1:28:53 - loss: 6.1901 - accuracy: 0.1170\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 370/1615 [=====>........................] - ETA: 1:28:42 - loss: 6.1919 - accuracy: 0.1168\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 372/1615 [=====>........................] - ETA: 1:28:34 - loss: 6.1915 - accuracy: 0.1170\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 374/1615 [=====>........................] - ETA: 1:28:25 - loss: 6.1926 - accuracy: 0.1168\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 376/1615 [=====>........................] - ETA: 1:28:17 - loss: 6.1926 - accuracy: 0.1169\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 378/1615 [======>.......................] - ETA: 1:28:08 - loss: 6.1945 - accuracy: 0.1167\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 380/1615 [======>.......................] - ETA: 1:28:05 - loss: 6.1940 - accuracy: 0.1166\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 382/1615 [======>.......................] - ETA: 1:27:55 - loss: 6.1950 - accuracy: 0.1164\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 384/1615 [======>.......................] - ETA: 1:27:46 - loss: 6.1941 - accuracy: 0.1163\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 386/1615 [======>.......................] - ETA: 1:27:37 - loss: 6.1955 - accuracy: 0.1160\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 388/1615 [======>.......................] - ETA: 1:27:27 - loss: 6.1955 - accuracy: 0.1160\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 390/1615 [======>.......................] - ETA: 1:27:18 - loss: 6.1955 - accuracy: 0.1159\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 392/1615 [======>.......................] - ETA: 1:27:10 - loss: 6.1961 - accuracy: 0.1160\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 394/1615 [======>.......................] - ETA: 1:27:01 - loss: 6.1960 - accuracy: 0.1159\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 396/1615 [======>.......................] - ETA: 1:26:52 - loss: 6.1950 - accuracy: 0.1159\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 398/1615 [======>.......................] - ETA: 1:26:44 - loss: 6.1959 - accuracy: 0.1158\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 400/1615 [======>.......................] - ETA: 1:26:36 - loss: 6.1969 - accuracy: 0.1158\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 402/1615 [======>.......................] - ETA: 1:26:28 - loss: 6.1948 - accuracy: 0.1160\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 404/1615 [======>.......................] - ETA: 1:26:20 - loss: 6.1953 - accuracy: 0.1160\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 406/1615 [======>.......................] - ETA: 1:26:12 - loss: 6.1962 - accuracy: 0.1159\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 408/1615 [======>.......................] - ETA: 1:26:03 - loss: 6.1972 - accuracy: 0.1158\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 410/1615 [======>.......................] - ETA: 1:25:53 - loss: 6.1973 - accuracy: 0.1157\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 412/1615 [======>.......................] - ETA: 1:25:46 - loss: 6.1962 - accuracy: 0.1157\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 414/1615 [======>.......................] - ETA: 1:25:37 - loss: 6.1972 - accuracy: 0.1156\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 416/1615 [======>.......................] - ETA: 1:25:29 - loss: 6.1969 - accuracy: 0.1156\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 418/1615 [======>.......................] - ETA: 1:25:21 - loss: 6.1968 - accuracy: 0.1156\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 420/1615 [======>.......................] - ETA: 1:25:13 - loss: 6.1965 - accuracy: 0.1156\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 422/1615 [======>.......................] - ETA: 1:25:03 - loss: 6.1973 - accuracy: 0.1155\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 424/1615 [======>.......................] - ETA: 1:24:55 - loss: 6.1975 - accuracy: 0.1155\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 426/1615 [======>.......................] - ETA: 1:24:47 - loss: 6.1984 - accuracy: 0.1155\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 428/1615 [======>.......................] - ETA: 1:24:38 - loss: 6.2002 - accuracy: 0.1153\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 430/1615 [======>.......................] - ETA: 1:24:30 - loss: 6.1992 - accuracy: 0.1151\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 432/1615 [=======>......................] - ETA: 1:24:22 - loss: 6.1993 - accuracy: 0.1151\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 434/1615 [=======>......................] - ETA: 1:24:13 - loss: 6.1996 - accuracy: 0.1152\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 436/1615 [=======>......................] - ETA: 1:24:05 - loss: 6.1994 - accuracy: 0.1153\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 438/1615 [=======>......................] - ETA: 1:23:57 - loss: 6.1986 - accuracy: 0.1153\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 440/1615 [=======>......................] - ETA: 1:23:48 - loss: 6.1980 - accuracy: 0.1154\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 442/1615 [=======>......................] - ETA: 1:23:39 - loss: 6.1990 - accuracy: 0.1154\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 444/1615 [=======>......................] - ETA: 1:23:30 - loss: 6.1977 - accuracy: 0.1155\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 446/1615 [=======>......................] - ETA: 1:23:22 - loss: 6.1968 - accuracy: 0.1155\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 448/1615 [=======>......................] - ETA: 1:23:19 - loss: 6.1964 - accuracy: 0.1156\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 450/1615 [=======>......................] - ETA: 1:23:09 - loss: 6.1961 - accuracy: 0.1156\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 452/1615 [=======>......................] - ETA: 1:22:59 - loss: 6.1958 - accuracy: 0.1157\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 454/1615 [=======>......................] - ETA: 1:22:49 - loss: 6.1945 - accuracy: 0.1159\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 456/1615 [=======>......................] - ETA: 1:22:44 - loss: 6.1946 - accuracy: 0.1159\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 458/1615 [=======>......................] - ETA: 1:22:36 - loss: 6.1952 - accuracy: 0.1160\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 460/1615 [=======>......................] - ETA: 1:22:26 - loss: 6.1957 - accuracy: 0.1162\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 462/1615 [=======>......................] - ETA: 1:22:16 - loss: 6.1936 - accuracy: 0.1164\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 464/1615 [=======>......................] - ETA: 1:22:06 - loss: 6.1932 - accuracy: 0.1165\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 466/1615 [=======>......................] - ETA: 1:21:58 - loss: 6.1929 - accuracy: 0.1166\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 468/1615 [=======>......................] - ETA: 1:21:50 - loss: 6.1920 - accuracy: 0.1166\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 470/1615 [=======>......................] - ETA: 1:21:44 - loss: 6.1907 - accuracy: 0.1167\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 472/1615 [=======>......................] - ETA: 1:21:34 - loss: 6.1897 - accuracy: 0.1168\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 474/1615 [=======>......................] - ETA: 1:21:27 - loss: 6.1905 - accuracy: 0.1168\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 476/1615 [=======>......................] - ETA: 1:21:16 - loss: 6.1903 - accuracy: 0.1168\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 478/1615 [=======>......................] - ETA: 1:21:07 - loss: 6.1912 - accuracy: 0.1169\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 480/1615 [=======>......................] - ETA: 1:20:59 - loss: 6.1932 - accuracy: 0.1168\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 482/1615 [=======>......................] - ETA: 1:20:51 - loss: 6.1936 - accuracy: 0.1168\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 484/1615 [=======>......................] - ETA: 1:20:44 - loss: 6.1930 - accuracy: 0.1168\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 486/1615 [========>.....................] - ETA: 1:20:38 - loss: 6.1934 - accuracy: 0.1168\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 488/1615 [========>.....................] - ETA: 1:20:29 - loss: 6.1923 - accuracy: 0.1168\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 490/1615 [========>.....................] - ETA: 1:20:19 - loss: 6.1923 - accuracy: 0.1169\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 492/1615 [========>.....................] - ETA: 1:20:09 - loss: 6.1934 - accuracy: 0.1168\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 494/1615 [========>.....................] - ETA: 1:20:00 - loss: 6.1944 - accuracy: 0.1168\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 496/1615 [========>.....................] - ETA: 1:19:51 - loss: 6.1942 - accuracy: 0.1168\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 498/1615 [========>.....................] - ETA: 1:19:43 - loss: 6.1939 - accuracy: 0.1169\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 500/1615 [========>.....................] - ETA: 1:19:34 - loss: 6.1941 - accuracy: 0.1169\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 502/1615 [========>.....................] - ETA: 1:19:28 - loss: 6.1948 - accuracy: 0.1169\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 504/1615 [========>.....................] - ETA: 1:19:20 - loss: 6.1954 - accuracy: 0.1169\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 506/1615 [========>.....................] - ETA: 1:19:12 - loss: 6.1952 - accuracy: 0.1168\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 508/1615 [========>.....................] - ETA: 1:19:03 - loss: 6.1949 - accuracy: 0.1167\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 510/1615 [========>.....................] - ETA: 1:18:53 - loss: 6.1960 - accuracy: 0.1167\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 512/1615 [========>.....................] - ETA: 1:18:44 - loss: 6.1964 - accuracy: 0.1168\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 514/1615 [========>.....................] - ETA: 1:18:38 - loss: 6.1968 - accuracy: 0.1169\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 516/1615 [========>.....................] - ETA: 1:18:29 - loss: 6.1967 - accuracy: 0.1169\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 518/1615 [========>.....................] - ETA: 1:18:21 - loss: 6.1969 - accuracy: 0.1170\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 520/1615 [========>.....................] - ETA: 1:18:12 - loss: 6.1972 - accuracy: 0.1170\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 522/1615 [========>.....................] - ETA: 1:18:04 - loss: 6.1956 - accuracy: 0.1171\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 524/1615 [========>.....................] - ETA: 1:17:55 - loss: 6.1965 - accuracy: 0.1170\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 526/1615 [========>.....................] - ETA: 1:17:45 - loss: 6.1971 - accuracy: 0.1169\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 528/1615 [========>.....................] - ETA: 1:17:39 - loss: 6.1976 - accuracy: 0.1168\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 530/1615 [========>.....................] - ETA: 1:17:30 - loss: 6.1966 - accuracy: 0.1169\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 532/1615 [========>.....................] - ETA: 1:17:21 - loss: 6.1952 - accuracy: 0.1170\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 534/1615 [========>.....................] - ETA: 1:17:12 - loss: 6.1959 - accuracy: 0.1170\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 536/1615 [========>.....................] - ETA: 1:17:03 - loss: 6.1957 - accuracy: 0.1170\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 538/1615 [========>.....................] - ETA: 1:16:54 - loss: 6.1956 - accuracy: 0.1170\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 540/1615 [=========>....................] - ETA: 1:16:46 - loss: 6.1975 - accuracy: 0.1169\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 542/1615 [=========>....................] - ETA: 1:16:37 - loss: 6.1967 - accuracy: 0.1170\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 544/1615 [=========>....................] - ETA: 1:16:28 - loss: 6.1965 - accuracy: 0.1170\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 546/1615 [=========>....................] - ETA: 1:16:19 - loss: 6.1965 - accuracy: 0.1171\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 548/1615 [=========>....................] - ETA: 1:16:11 - loss: 6.1956 - accuracy: 0.1171\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 550/1615 [=========>....................] - ETA: 1:16:03 - loss: 6.1958 - accuracy: 0.1171\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 552/1615 [=========>....................] - ETA: 1:15:54 - loss: 6.1957 - accuracy: 0.1172\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 554/1615 [=========>....................] - ETA: 1:15:46 - loss: 6.1949 - accuracy: 0.1172\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 556/1615 [=========>....................] - ETA: 1:15:37 - loss: 6.1954 - accuracy: 0.1171\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 558/1615 [=========>....................] - ETA: 1:15:30 - loss: 6.1951 - accuracy: 0.1172\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 560/1615 [=========>....................] - ETA: 1:15:20 - loss: 6.1955 - accuracy: 0.1172\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 562/1615 [=========>....................] - ETA: 1:15:12 - loss: 6.1953 - accuracy: 0.1172\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 564/1615 [=========>....................] - ETA: 1:15:03 - loss: 6.1955 - accuracy: 0.1172\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 566/1615 [=========>....................] - ETA: 1:14:55 - loss: 6.1954 - accuracy: 0.1172\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 568/1615 [=========>....................] - ETA: 1:14:47 - loss: 6.1957 - accuracy: 0.1172\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 570/1615 [=========>....................] - ETA: 1:14:38 - loss: 6.1961 - accuracy: 0.1171\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 572/1615 [=========>....................] - ETA: 1:14:29 - loss: 6.1952 - accuracy: 0.1173\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 574/1615 [=========>....................] - ETA: 1:14:21 - loss: 6.1948 - accuracy: 0.1173\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 576/1615 [=========>....................] - ETA: 1:14:12 - loss: 6.1946 - accuracy: 0.1173\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 578/1615 [=========>....................] - ETA: 1:14:04 - loss: 6.1952 - accuracy: 0.1173\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 580/1615 [=========>....................] - ETA: 1:13:56 - loss: 6.1953 - accuracy: 0.1172\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 582/1615 [=========>....................] - ETA: 1:13:49 - loss: 6.1956 - accuracy: 0.1171\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 584/1615 [=========>....................] - ETA: 1:13:39 - loss: 6.1951 - accuracy: 0.1173\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 586/1615 [=========>....................] - ETA: 1:13:32 - loss: 6.1951 - accuracy: 0.1172\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 588/1615 [=========>....................] - ETA: 1:13:22 - loss: 6.1959 - accuracy: 0.1173\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 590/1615 [=========>....................] - ETA: 1:13:13 - loss: 6.1955 - accuracy: 0.1173\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 592/1615 [=========>....................] - ETA: 1:13:04 - loss: 6.1952 - accuracy: 0.1172\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 594/1615 [==========>...................] - ETA: 1:12:56 - loss: 6.1957 - accuracy: 0.1171\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 596/1615 [==========>...................] - ETA: 1:12:47 - loss: 6.1955 - accuracy: 0.1171\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 598/1615 [==========>...................] - ETA: 1:12:38 - loss: 6.1956 - accuracy: 0.1171\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 600/1615 [==========>...................] - ETA: 1:12:30 - loss: 6.1965 - accuracy: 0.1171\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 602/1615 [==========>...................] - ETA: 1:12:21 - loss: 6.1958 - accuracy: 0.1171\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 604/1615 [==========>...................] - ETA: 1:12:13 - loss: 6.1953 - accuracy: 0.1172\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 606/1615 [==========>...................] - ETA: 1:12:05 - loss: 6.1954 - accuracy: 0.1173\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 608/1615 [==========>...................] - ETA: 1:11:56 - loss: 6.1951 - accuracy: 0.1173\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 610/1615 [==========>...................] - ETA: 1:11:47 - loss: 6.1954 - accuracy: 0.1172\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 612/1615 [==========>...................] - ETA: 1:11:39 - loss: 6.1960 - accuracy: 0.1173\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 614/1615 [==========>...................] - ETA: 1:11:32 - loss: 6.1949 - accuracy: 0.1174\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 616/1615 [==========>...................] - ETA: 1:11:22 - loss: 6.1951 - accuracy: 0.1172\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 618/1615 [==========>...................] - ETA: 1:11:13 - loss: 6.1949 - accuracy: 0.1171\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 620/1615 [==========>...................] - ETA: 1:11:05 - loss: 6.1945 - accuracy: 0.1173\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 622/1615 [==========>...................] - ETA: 1:10:56 - loss: 6.1948 - accuracy: 0.1173\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 624/1615 [==========>...................] - ETA: 1:10:47 - loss: 6.1958 - accuracy: 0.1172\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 626/1615 [==========>...................] - ETA: 1:10:39 - loss: 6.1962 - accuracy: 0.1172\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 628/1615 [==========>...................] - ETA: 1:10:32 - loss: 6.1954 - accuracy: 0.1172\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 630/1615 [==========>...................] - ETA: 1:10:22 - loss: 6.1953 - accuracy: 0.1174\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 632/1615 [==========>...................] - ETA: 1:10:14 - loss: 6.1947 - accuracy: 0.1174\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 634/1615 [==========>...................] - ETA: 1:10:05 - loss: 6.1953 - accuracy: 0.1174\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 636/1615 [==========>...................] - ETA: 1:09:56 - loss: 6.1954 - accuracy: 0.1175\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 638/1615 [==========>...................] - ETA: 1:09:48 - loss: 6.1958 - accuracy: 0.1174\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 640/1615 [==========>...................] - ETA: 1:09:39 - loss: 6.1946 - accuracy: 0.1174\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 642/1615 [==========>...................] - ETA: 1:09:30 - loss: 6.1960 - accuracy: 0.1174\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 644/1615 [==========>...................] - ETA: 1:09:22 - loss: 6.1956 - accuracy: 0.1173\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 646/1615 [===========>..................] - ETA: 1:09:14 - loss: 6.1952 - accuracy: 0.1174\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 648/1615 [===========>..................] - ETA: 1:09:05 - loss: 6.1947 - accuracy: 0.1175\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 650/1615 [===========>..................] - ETA: 1:08:56 - loss: 6.1941 - accuracy: 0.1176\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 652/1615 [===========>..................] - ETA: 1:08:48 - loss: 6.1947 - accuracy: 0.1175\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 654/1615 [===========>..................] - ETA: 1:08:39 - loss: 6.1947 - accuracy: 0.1176\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 656/1615 [===========>..................] - ETA: 1:08:31 - loss: 6.1942 - accuracy: 0.1176\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 658/1615 [===========>..................] - ETA: 1:08:23 - loss: 6.1935 - accuracy: 0.1178\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 660/1615 [===========>..................] - ETA: 1:08:14 - loss: 6.1934 - accuracy: 0.1178\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 662/1615 [===========>..................] - ETA: 1:08:08 - loss: 6.1934 - accuracy: 0.1178\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 664/1615 [===========>..................] - ETA: 1:07:57 - loss: 6.1924 - accuracy: 0.1179\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 666/1615 [===========>..................] - ETA: 1:07:48 - loss: 6.1917 - accuracy: 0.1179\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 668/1615 [===========>..................] - ETA: 1:07:40 - loss: 6.1921 - accuracy: 0.1179\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 670/1615 [===========>..................] - ETA: 1:07:31 - loss: 6.1923 - accuracy: 0.1179\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 672/1615 [===========>..................] - ETA: 1:07:23 - loss: 6.1920 - accuracy: 0.1179\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 674/1615 [===========>..................] - ETA: 1:07:14 - loss: 6.1910 - accuracy: 0.1181\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 676/1615 [===========>..................] - ETA: 1:07:06 - loss: 6.1920 - accuracy: 0.1180\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 678/1615 [===========>..................] - ETA: 1:06:57 - loss: 6.1923 - accuracy: 0.1180\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 680/1615 [===========>..................] - ETA: 1:06:49 - loss: 6.1917 - accuracy: 0.1182\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 682/1615 [===========>..................] - ETA: 1:06:40 - loss: 6.1920 - accuracy: 0.1181\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 684/1615 [===========>..................] - ETA: 1:06:32 - loss: 6.1914 - accuracy: 0.1180\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 686/1615 [===========>..................] - ETA: 1:06:23 - loss: 6.1913 - accuracy: 0.1180\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 688/1615 [===========>..................] - ETA: 1:06:17 - loss: 6.1904 - accuracy: 0.1181\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 690/1615 [===========>..................] - ETA: 1:06:07 - loss: 6.1901 - accuracy: 0.1181\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 692/1615 [===========>..................] - ETA: 1:05:58 - loss: 6.1897 - accuracy: 0.1182\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 694/1615 [===========>..................] - ETA: 1:05:49 - loss: 6.1898 - accuracy: 0.1181\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 696/1615 [===========>..................] - ETA: 1:05:40 - loss: 6.1893 - accuracy: 0.1181\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 698/1615 [===========>..................] - ETA: 1:05:32 - loss: 6.1893 - accuracy: 0.1181\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 700/1615 [============>.................] - ETA: 1:05:26 - loss: 6.1897 - accuracy: 0.1182\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 702/1615 [============>.................] - ETA: 1:05:15 - loss: 6.1894 - accuracy: 0.1182\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 704/1615 [============>.................] - ETA: 1:05:08 - loss: 6.1889 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 706/1615 [============>.................] - ETA: 1:04:58 - loss: 6.1893 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 708/1615 [============>.................] - ETA: 1:04:51 - loss: 6.1899 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 710/1615 [============>.................] - ETA: 1:04:41 - loss: 6.1899 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 712/1615 [============>.................] - ETA: 1:04:34 - loss: 6.1896 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 714/1615 [============>.................] - ETA: 1:04:24 - loss: 6.1895 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 716/1615 [============>.................] - ETA: 1:04:15 - loss: 6.1895 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 718/1615 [============>.................] - ETA: 1:04:08 - loss: 6.1888 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 720/1615 [============>.................] - ETA: 1:03:58 - loss: 6.1884 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 722/1615 [============>.................] - ETA: 1:03:49 - loss: 6.1887 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 724/1615 [============>.................] - ETA: 1:03:41 - loss: 6.1876 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 726/1615 [============>.................] - ETA: 1:03:32 - loss: 6.1877 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 728/1615 [============>.................] - ETA: 1:03:24 - loss: 6.1877 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 730/1615 [============>.................] - ETA: 1:03:18 - loss: 6.1881 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 732/1615 [============>.................] - ETA: 1:03:07 - loss: 6.1881 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 734/1615 [============>.................] - ETA: 1:03:01 - loss: 6.1888 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 736/1615 [============>.................] - ETA: 1:02:50 - loss: 6.1888 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 738/1615 [============>.................] - ETA: 1:02:42 - loss: 6.1891 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 740/1615 [============>.................] - ETA: 1:02:33 - loss: 6.1884 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 742/1615 [============>.................] - ETA: 1:02:24 - loss: 6.1880 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 744/1615 [============>.................] - ETA: 1:02:17 - loss: 6.1878 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 746/1615 [============>.................] - ETA: 1:02:07 - loss: 6.1870 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 748/1615 [============>.................] - ETA: 1:02:00 - loss: 6.1870 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 750/1615 [============>.................] - ETA: 1:01:50 - loss: 6.1871 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 752/1615 [============>.................] - ETA: 1:01:41 - loss: 6.1872 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 754/1615 [=============>................] - ETA: 1:01:32 - loss: 6.1878 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 756/1615 [=============>................] - ETA: 1:01:24 - loss: 6.1882 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 758/1615 [=============>................] - ETA: 1:01:17 - loss: 6.1881 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 760/1615 [=============>................] - ETA: 1:01:07 - loss: 6.1883 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 762/1615 [=============>................] - ETA: 1:01:00 - loss: 6.1877 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 764/1615 [=============>................] - ETA: 1:00:50 - loss: 6.1875 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 766/1615 [=============>................] - ETA: 1:00:42 - loss: 6.1877 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 768/1615 [=============>................] - ETA: 1:00:33 - loss: 6.1871 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 770/1615 [=============>................] - ETA: 1:00:25 - loss: 6.1864 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 772/1615 [=============>................] - ETA: 1:00:17 - loss: 6.1870 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 774/1615 [=============>................] - ETA: 1:00:07 - loss: 6.1868 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 776/1615 [=============>................] - ETA: 1:00:00 - loss: 6.1877 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 778/1615 [=============>................] - ETA: 59:50 - loss: 6.1878 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 780/1615 [=============>................] - ETA: 59:42 - loss: 6.1884 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 782/1615 [=============>................] - ETA: 59:33 - loss: 6.1883 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 784/1615 [=============>................] - ETA: 59:24 - loss: 6.1890 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 786/1615 [=============>................] - ETA: 59:17 - loss: 6.1884 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 788/1615 [=============>................] - ETA: 59:08 - loss: 6.1886 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 790/1615 [=============>................] - ETA: 59:00 - loss: 6.1885 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 792/1615 [=============>................] - ETA: 58:50 - loss: 6.1888 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 794/1615 [=============>................] - ETA: 58:43 - loss: 6.1880 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 796/1615 [=============>................] - ETA: 58:33 - loss: 6.1875 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 798/1615 [=============>................] - ETA: 58:25 - loss: 6.1872 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 800/1615 [=============>................] - ETA: 58:17 - loss: 6.1878 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 802/1615 [=============>................] - ETA: 58:08 - loss: 6.1884 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 804/1615 [=============>................] - ETA: 57:59 - loss: 6.1886 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 806/1615 [=============>................] - ETA: 57:51 - loss: 6.1888 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 808/1615 [==============>...............] - ETA: 57:42 - loss: 6.1894 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 810/1615 [==============>...............] - ETA: 57:35 - loss: 6.1894 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 812/1615 [==============>...............] - ETA: 57:25 - loss: 6.1892 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 814/1615 [==============>...............] - ETA: 57:17 - loss: 6.1890 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 816/1615 [==============>...............] - ETA: 57:08 - loss: 6.1888 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 818/1615 [==============>...............] - ETA: 57:00 - loss: 6.1887 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 820/1615 [==============>...............] - ETA: 56:51 - loss: 6.1885 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 822/1615 [==============>...............] - ETA: 56:42 - loss: 6.1881 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 824/1615 [==============>...............] - ETA: 56:34 - loss: 6.1883 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 826/1615 [==============>...............] - ETA: 56:25 - loss: 6.1882 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 828/1615 [==============>...............] - ETA: 56:16 - loss: 6.1882 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 830/1615 [==============>...............] - ETA: 56:08 - loss: 6.1875 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 832/1615 [==============>...............] - ETA: 55:59 - loss: 6.1868 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 834/1615 [==============>...............] - ETA: 55:53 - loss: 6.1870 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 836/1615 [==============>...............] - ETA: 55:43 - loss: 6.1881 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 838/1615 [==============>...............] - ETA: 55:34 - loss: 6.1881 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 840/1615 [==============>...............] - ETA: 55:25 - loss: 6.1881 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 842/1615 [==============>...............] - ETA: 55:17 - loss: 6.1875 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 844/1615 [==============>...............] - ETA: 55:09 - loss: 6.1875 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 846/1615 [==============>...............] - ETA: 55:00 - loss: 6.1875 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 848/1615 [==============>...............] - ETA: 54:51 - loss: 6.1870 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 850/1615 [==============>...............] - ETA: 54:43 - loss: 6.1874 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 852/1615 [==============>...............] - ETA: 54:34 - loss: 6.1874 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 854/1615 [==============>...............] - ETA: 54:26 - loss: 6.1869 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 856/1615 [==============>...............] - ETA: 54:17 - loss: 6.1870 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 858/1615 [==============>...............] - ETA: 54:08 - loss: 6.1863 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 860/1615 [==============>...............] - ETA: 54:00 - loss: 6.1866 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 862/1615 [===============>..............] - ETA: 53:52 - loss: 6.1869 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 864/1615 [===============>..............] - ETA: 53:42 - loss: 6.1870 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 866/1615 [===============>..............] - ETA: 53:34 - loss: 6.1873 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 868/1615 [===============>..............] - ETA: 53:25 - loss: 6.1874 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 870/1615 [===============>..............] - ETA: 53:17 - loss: 6.1880 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 872/1615 [===============>..............] - ETA: 53:08 - loss: 6.1887 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 874/1615 [===============>..............] - ETA: 53:00 - loss: 6.1891 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 876/1615 [===============>..............] - ETA: 52:51 - loss: 6.1896 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 878/1615 [===============>..............] - ETA: 52:43 - loss: 6.1899 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 880/1615 [===============>..............] - ETA: 52:34 - loss: 6.1900 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 882/1615 [===============>..............] - ETA: 52:27 - loss: 6.1900 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 884/1615 [===============>..............] - ETA: 52:17 - loss: 6.1891 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 886/1615 [===============>..............] - ETA: 52:08 - loss: 6.1894 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 888/1615 [===============>..............] - ETA: 52:00 - loss: 6.1896 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 890/1615 [===============>..............] - ETA: 51:51 - loss: 6.1899 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 892/1615 [===============>..............] - ETA: 51:43 - loss: 6.1910 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 894/1615 [===============>..............] - ETA: 51:34 - loss: 6.1912 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 896/1615 [===============>..............] - ETA: 51:25 - loss: 6.1910 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 898/1615 [===============>..............] - ETA: 51:17 - loss: 6.1907 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 900/1615 [===============>..............] - ETA: 51:08 - loss: 6.1907 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 902/1615 [===============>..............] - ETA: 51:01 - loss: 6.1905 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 904/1615 [===============>..............] - ETA: 50:51 - loss: 6.1900 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 906/1615 [===============>..............] - ETA: 50:44 - loss: 6.1900 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 908/1615 [===============>..............] - ETA: 50:34 - loss: 6.1898 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 910/1615 [===============>..............] - ETA: 50:26 - loss: 6.1904 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 912/1615 [===============>..............] - ETA: 50:18 - loss: 6.1902 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 914/1615 [===============>..............] - ETA: 50:09 - loss: 6.1903 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 916/1615 [================>.............] - ETA: 50:00 - loss: 6.1899 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 918/1615 [================>.............] - ETA: 49:52 - loss: 6.1906 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 920/1615 [================>.............] - ETA: 49:43 - loss: 6.1904 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 922/1615 [================>.............] - ETA: 49:34 - loss: 6.1906 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 924/1615 [================>.............] - ETA: 49:26 - loss: 6.1906 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 926/1615 [================>.............] - ETA: 49:17 - loss: 6.1905 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 928/1615 [================>.............] - ETA: 49:08 - loss: 6.1904 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 930/1615 [================>.............] - ETA: 49:01 - loss: 6.1900 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 932/1615 [================>.............] - ETA: 48:51 - loss: 6.1906 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 934/1615 [================>.............] - ETA: 48:44 - loss: 6.1906 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 936/1615 [================>.............] - ETA: 48:35 - loss: 6.1906 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 938/1615 [================>.............] - ETA: 48:26 - loss: 6.1904 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 940/1615 [================>.............] - ETA: 48:18 - loss: 6.1906 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 942/1615 [================>.............] - ETA: 48:09 - loss: 6.1904 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 944/1615 [================>.............] - ETA: 48:01 - loss: 6.1899 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 946/1615 [================>.............] - ETA: 47:52 - loss: 6.1898 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 948/1615 [================>.............] - ETA: 47:43 - loss: 6.1893 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 950/1615 [================>.............] - ETA: 47:34 - loss: 6.1898 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 952/1615 [================>.............] - ETA: 47:26 - loss: 6.1892 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 954/1615 [================>.............] - ETA: 47:17 - loss: 6.1891 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 956/1615 [================>.............] - ETA: 47:09 - loss: 6.1885 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 958/1615 [================>.............] - ETA: 47:00 - loss: 6.1887 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 960/1615 [================>.............] - ETA: 46:53 - loss: 6.1892 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 962/1615 [================>.............] - ETA: 46:43 - loss: 6.1898 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 964/1615 [================>.............] - ETA: 46:36 - loss: 6.1901 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 966/1615 [================>.............] - ETA: 46:26 - loss: 6.1896 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 968/1615 [================>.............] - ETA: 46:17 - loss: 6.1902 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 970/1615 [=================>............] - ETA: 46:10 - loss: 6.1906 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 972/1615 [=================>............] - ETA: 46:00 - loss: 6.1908 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 974/1615 [=================>............] - ETA: 45:52 - loss: 6.1906 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 976/1615 [=================>............] - ETA: 45:43 - loss: 6.1913 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 978/1615 [=================>............] - ETA: 45:35 - loss: 6.1912 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 980/1615 [=================>............] - ETA: 45:26 - loss: 6.1910 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 982/1615 [=================>............] - ETA: 45:17 - loss: 6.1911 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 984/1615 [=================>............] - ETA: 45:10 - loss: 6.1909 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 986/1615 [=================>............] - ETA: 45:00 - loss: 6.1902 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 988/1615 [=================>............] - ETA: 44:53 - loss: 6.1905 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 990/1615 [=================>............] - ETA: 44:43 - loss: 6.1895 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 992/1615 [=================>............] - ETA: 44:35 - loss: 6.1902 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 994/1615 [=================>............] - ETA: 44:26 - loss: 6.1904 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 996/1615 [=================>............] - ETA: 44:17 - loss: 6.1901 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            " 998/1615 [=================>............] - ETA: 44:09 - loss: 6.1899 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1000/1615 [=================>............] - ETA: 44:00 - loss: 6.1903 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1002/1615 [=================>............] - ETA: 43:52 - loss: 6.1908 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1004/1615 [=================>............] - ETA: 43:43 - loss: 6.1905 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1006/1615 [=================>............] - ETA: 43:34 - loss: 6.1906 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1008/1615 [=================>............] - ETA: 43:25 - loss: 6.1906 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1010/1615 [=================>............] - ETA: 43:17 - loss: 6.1901 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1012/1615 [=================>............] - ETA: 43:08 - loss: 6.1903 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1014/1615 [=================>............] - ETA: 43:01 - loss: 6.1905 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1016/1615 [=================>............] - ETA: 42:51 - loss: 6.1913 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1018/1615 [=================>............] - ETA: 42:43 - loss: 6.1920 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1020/1615 [=================>............] - ETA: 42:34 - loss: 6.1913 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1022/1615 [=================>............] - ETA: 42:26 - loss: 6.1903 - accuracy: 0.1190\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1024/1615 [==================>...........] - ETA: 42:17 - loss: 6.1912 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1026/1615 [==================>...........] - ETA: 42:08 - loss: 6.1907 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1028/1615 [==================>...........] - ETA: 42:00 - loss: 6.1906 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1030/1615 [==================>...........] - ETA: 41:51 - loss: 6.1910 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1032/1615 [==================>...........] - ETA: 41:43 - loss: 6.1910 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1034/1615 [==================>...........] - ETA: 41:34 - loss: 6.1914 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1036/1615 [==================>...........] - ETA: 41:26 - loss: 6.1909 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1038/1615 [==================>...........] - ETA: 41:17 - loss: 6.1903 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1040/1615 [==================>...........] - ETA: 41:08 - loss: 6.1906 - accuracy: 0.1189\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1042/1615 [==================>...........] - ETA: 41:00 - loss: 6.1909 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1044/1615 [==================>...........] - ETA: 40:52 - loss: 6.1911 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1046/1615 [==================>...........] - ETA: 40:43 - loss: 6.1911 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1048/1615 [==================>...........] - ETA: 40:34 - loss: 6.1916 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1050/1615 [==================>...........] - ETA: 40:25 - loss: 6.1919 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1052/1615 [==================>...........] - ETA: 40:17 - loss: 6.1919 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1054/1615 [==================>...........] - ETA: 40:08 - loss: 6.1923 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1056/1615 [==================>...........] - ETA: 40:01 - loss: 6.1927 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1058/1615 [==================>...........] - ETA: 39:51 - loss: 6.1924 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1060/1615 [==================>...........] - ETA: 39:43 - loss: 6.1921 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1062/1615 [==================>...........] - ETA: 39:34 - loss: 6.1922 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1064/1615 [==================>...........] - ETA: 39:25 - loss: 6.1922 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1066/1615 [==================>...........] - ETA: 39:17 - loss: 6.1921 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1068/1615 [==================>...........] - ETA: 39:08 - loss: 6.1931 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1070/1615 [==================>...........] - ETA: 39:00 - loss: 6.1934 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1072/1615 [==================>...........] - ETA: 38:51 - loss: 6.1935 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1074/1615 [==================>...........] - ETA: 38:43 - loss: 6.1934 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1076/1615 [==================>...........] - ETA: 38:34 - loss: 6.1929 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1078/1615 [===================>..........] - ETA: 38:25 - loss: 6.1929 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1080/1615 [===================>..........] - ETA: 38:17 - loss: 6.1924 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1082/1615 [===================>..........] - ETA: 38:08 - loss: 6.1919 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1084/1615 [===================>..........] - ETA: 38:00 - loss: 6.1917 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1086/1615 [===================>..........] - ETA: 37:51 - loss: 6.1918 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1088/1615 [===================>..........] - ETA: 37:43 - loss: 6.1911 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1090/1615 [===================>..........] - ETA: 37:34 - loss: 6.1913 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1092/1615 [===================>..........] - ETA: 37:25 - loss: 6.1913 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1094/1615 [===================>..........] - ETA: 37:17 - loss: 6.1913 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1096/1615 [===================>..........] - ETA: 37:08 - loss: 6.1912 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1098/1615 [===================>..........] - ETA: 37:00 - loss: 6.1906 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1100/1615 [===================>..........] - ETA: 36:51 - loss: 6.1904 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1102/1615 [===================>..........] - ETA: 36:42 - loss: 6.1911 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1104/1615 [===================>..........] - ETA: 36:34 - loss: 6.1909 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1106/1615 [===================>..........] - ETA: 36:25 - loss: 6.1913 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1108/1615 [===================>..........] - ETA: 36:17 - loss: 6.1916 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1110/1615 [===================>..........] - ETA: 36:08 - loss: 6.1916 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1112/1615 [===================>..........] - ETA: 36:00 - loss: 6.1918 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1114/1615 [===================>..........] - ETA: 35:51 - loss: 6.1917 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1116/1615 [===================>..........] - ETA: 35:43 - loss: 6.1912 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1118/1615 [===================>..........] - ETA: 35:34 - loss: 6.1916 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1120/1615 [===================>..........] - ETA: 35:25 - loss: 6.1915 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1122/1615 [===================>..........] - ETA: 35:17 - loss: 6.1913 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1124/1615 [===================>..........] - ETA: 35:08 - loss: 6.1908 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1126/1615 [===================>..........] - ETA: 35:00 - loss: 6.1907 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1128/1615 [===================>..........] - ETA: 34:51 - loss: 6.1907 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1130/1615 [===================>..........] - ETA: 34:42 - loss: 6.1911 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1132/1615 [====================>.........] - ETA: 34:34 - loss: 6.1901 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1134/1615 [====================>.........] - ETA: 34:25 - loss: 6.1898 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1136/1615 [====================>.........] - ETA: 34:17 - loss: 6.1898 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1138/1615 [====================>.........] - ETA: 34:08 - loss: 6.1902 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1140/1615 [====================>.........] - ETA: 33:59 - loss: 6.1904 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1142/1615 [====================>.........] - ETA: 33:51 - loss: 6.1904 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1144/1615 [====================>.........] - ETA: 33:42 - loss: 6.1905 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1146/1615 [====================>.........] - ETA: 33:34 - loss: 6.1911 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1148/1615 [====================>.........] - ETA: 33:25 - loss: 6.1910 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1150/1615 [====================>.........] - ETA: 33:17 - loss: 6.1910 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1152/1615 [====================>.........] - ETA: 33:08 - loss: 6.1911 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1154/1615 [====================>.........] - ETA: 32:59 - loss: 6.1902 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1156/1615 [====================>.........] - ETA: 32:51 - loss: 6.1903 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1158/1615 [====================>.........] - ETA: 32:42 - loss: 6.1907 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1160/1615 [====================>.........] - ETA: 32:34 - loss: 6.1909 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1162/1615 [====================>.........] - ETA: 32:25 - loss: 6.1910 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1164/1615 [====================>.........] - ETA: 32:17 - loss: 6.1912 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1166/1615 [====================>.........] - ETA: 32:08 - loss: 6.1909 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1168/1615 [====================>.........] - ETA: 31:59 - loss: 6.1905 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1170/1615 [====================>.........] - ETA: 31:51 - loss: 6.1906 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1172/1615 [====================>.........] - ETA: 31:42 - loss: 6.1910 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1174/1615 [====================>.........] - ETA: 31:33 - loss: 6.1914 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1176/1615 [====================>.........] - ETA: 31:25 - loss: 6.1913 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1178/1615 [====================>.........] - ETA: 31:16 - loss: 6.1913 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1180/1615 [====================>.........] - ETA: 31:08 - loss: 6.1913 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1182/1615 [====================>.........] - ETA: 30:59 - loss: 6.1917 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1184/1615 [====================>.........] - ETA: 30:51 - loss: 6.1918 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1186/1615 [=====================>........] - ETA: 30:42 - loss: 6.1922 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1188/1615 [=====================>........] - ETA: 30:33 - loss: 6.1921 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1190/1615 [=====================>........] - ETA: 30:26 - loss: 6.1923 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1192/1615 [=====================>........] - ETA: 30:16 - loss: 6.1928 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1194/1615 [=====================>........] - ETA: 30:08 - loss: 6.1922 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1196/1615 [=====================>........] - ETA: 29:59 - loss: 6.1918 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1198/1615 [=====================>........] - ETA: 29:50 - loss: 6.1922 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1200/1615 [=====================>........] - ETA: 29:43 - loss: 6.1919 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1202/1615 [=====================>........] - ETA: 29:33 - loss: 6.1925 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1204/1615 [=====================>........] - ETA: 29:25 - loss: 6.1929 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1206/1615 [=====================>........] - ETA: 29:16 - loss: 6.1927 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1208/1615 [=====================>........] - ETA: 29:08 - loss: 6.1923 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1210/1615 [=====================>........] - ETA: 28:59 - loss: 6.1917 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1212/1615 [=====================>........] - ETA: 28:50 - loss: 6.1913 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1214/1615 [=====================>........] - ETA: 28:42 - loss: 6.1916 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1216/1615 [=====================>........] - ETA: 28:33 - loss: 6.1916 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1218/1615 [=====================>........] - ETA: 28:25 - loss: 6.1911 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1220/1615 [=====================>........] - ETA: 28:16 - loss: 6.1913 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1222/1615 [=====================>........] - ETA: 28:08 - loss: 6.1916 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1224/1615 [=====================>........] - ETA: 27:59 - loss: 6.1920 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1226/1615 [=====================>........] - ETA: 27:50 - loss: 6.1916 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1228/1615 [=====================>........] - ETA: 27:42 - loss: 6.1917 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1230/1615 [=====================>........] - ETA: 27:33 - loss: 6.1910 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1232/1615 [=====================>........] - ETA: 27:25 - loss: 6.1910 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1234/1615 [=====================>........] - ETA: 27:16 - loss: 6.1912 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1236/1615 [=====================>........] - ETA: 27:08 - loss: 6.1912 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1238/1615 [=====================>........] - ETA: 26:59 - loss: 6.1919 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1240/1615 [======================>.......] - ETA: 26:50 - loss: 6.1919 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1242/1615 [======================>.......] - ETA: 26:42 - loss: 6.1920 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1244/1615 [======================>.......] - ETA: 26:33 - loss: 6.1925 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1246/1615 [======================>.......] - ETA: 26:25 - loss: 6.1923 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1248/1615 [======================>.......] - ETA: 26:16 - loss: 6.1921 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1250/1615 [======================>.......] - ETA: 26:08 - loss: 6.1920 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1252/1615 [======================>.......] - ETA: 25:59 - loss: 6.1915 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1254/1615 [======================>.......] - ETA: 25:50 - loss: 6.1916 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1256/1615 [======================>.......] - ETA: 25:41 - loss: 6.1921 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1258/1615 [======================>.......] - ETA: 25:33 - loss: 6.1921 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1260/1615 [======================>.......] - ETA: 25:24 - loss: 6.1921 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1262/1615 [======================>.......] - ETA: 25:16 - loss: 6.1922 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1264/1615 [======================>.......] - ETA: 25:07 - loss: 6.1915 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1266/1615 [======================>.......] - ETA: 24:59 - loss: 6.1915 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1268/1615 [======================>.......] - ETA: 24:50 - loss: 6.1914 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1270/1615 [======================>.......] - ETA: 24:41 - loss: 6.1913 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1272/1615 [======================>.......] - ETA: 24:33 - loss: 6.1917 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1274/1615 [======================>.......] - ETA: 24:25 - loss: 6.1916 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1276/1615 [======================>.......] - ETA: 24:16 - loss: 6.1920 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1278/1615 [======================>.......] - ETA: 24:07 - loss: 6.1918 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1280/1615 [======================>.......] - ETA: 23:58 - loss: 6.1918 - accuracy: 0.1182\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1282/1615 [======================>.......] - ETA: 23:50 - loss: 6.1917 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1284/1615 [======================>.......] - ETA: 23:41 - loss: 6.1921 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1286/1615 [======================>.......] - ETA: 23:33 - loss: 6.1924 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1288/1615 [======================>.......] - ETA: 23:24 - loss: 6.1923 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1290/1615 [======================>.......] - ETA: 23:15 - loss: 6.1928 - accuracy: 0.1182\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1292/1615 [=======================>......] - ETA: 23:07 - loss: 6.1929 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1294/1615 [=======================>......] - ETA: 22:58 - loss: 6.1930 - accuracy: 0.1182\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1296/1615 [=======================>......] - ETA: 22:50 - loss: 6.1928 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1298/1615 [=======================>......] - ETA: 22:41 - loss: 6.1927 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1300/1615 [=======================>......] - ETA: 22:33 - loss: 6.1928 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1302/1615 [=======================>......] - ETA: 22:24 - loss: 6.1925 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1304/1615 [=======================>......] - ETA: 22:15 - loss: 6.1924 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1306/1615 [=======================>......] - ETA: 22:07 - loss: 6.1925 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1308/1615 [=======================>......] - ETA: 21:58 - loss: 6.1925 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1310/1615 [=======================>......] - ETA: 21:50 - loss: 6.1926 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1312/1615 [=======================>......] - ETA: 21:41 - loss: 6.1924 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1314/1615 [=======================>......] - ETA: 21:33 - loss: 6.1928 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1316/1615 [=======================>......] - ETA: 21:24 - loss: 6.1926 - accuracy: 0.1182\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1318/1615 [=======================>......] - ETA: 21:15 - loss: 6.1932 - accuracy: 0.1182\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1320/1615 [=======================>......] - ETA: 21:07 - loss: 6.1931 - accuracy: 0.1182\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1322/1615 [=======================>......] - ETA: 20:58 - loss: 6.1924 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1324/1615 [=======================>......] - ETA: 20:50 - loss: 6.1926 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1326/1615 [=======================>......] - ETA: 20:41 - loss: 6.1927 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1328/1615 [=======================>......] - ETA: 20:32 - loss: 6.1925 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1330/1615 [=======================>......] - ETA: 20:24 - loss: 6.1928 - accuracy: 0.1183\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1332/1615 [=======================>......] - ETA: 20:15 - loss: 6.1925 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1334/1615 [=======================>......] - ETA: 20:07 - loss: 6.1926 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1336/1615 [=======================>......] - ETA: 19:58 - loss: 6.1931 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1338/1615 [=======================>......] - ETA: 19:49 - loss: 6.1936 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1340/1615 [=======================>......] - ETA: 19:41 - loss: 6.1930 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1342/1615 [=======================>......] - ETA: 19:32 - loss: 6.1933 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1344/1615 [=======================>......] - ETA: 19:24 - loss: 6.1931 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1346/1615 [========================>.....] - ETA: 19:15 - loss: 6.1930 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1348/1615 [========================>.....] - ETA: 19:06 - loss: 6.1931 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1350/1615 [========================>.....] - ETA: 18:58 - loss: 6.1929 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1352/1615 [========================>.....] - ETA: 18:49 - loss: 6.1930 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1354/1615 [========================>.....] - ETA: 18:41 - loss: 6.1934 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1356/1615 [========================>.....] - ETA: 18:32 - loss: 6.1938 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1358/1615 [========================>.....] - ETA: 18:24 - loss: 6.1938 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1360/1615 [========================>.....] - ETA: 18:15 - loss: 6.1940 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1362/1615 [========================>.....] - ETA: 18:06 - loss: 6.1935 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1364/1615 [========================>.....] - ETA: 17:58 - loss: 6.1932 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1366/1615 [========================>.....] - ETA: 17:49 - loss: 6.1935 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1368/1615 [========================>.....] - ETA: 17:41 - loss: 6.1937 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1370/1615 [========================>.....] - ETA: 17:32 - loss: 6.1941 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1372/1615 [========================>.....] - ETA: 17:23 - loss: 6.1938 - accuracy: 0.1184\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1374/1615 [========================>.....] - ETA: 17:15 - loss: 6.1937 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1376/1615 [========================>.....] - ETA: 17:06 - loss: 6.1941 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1378/1615 [========================>.....] - ETA: 16:58 - loss: 6.1939 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1380/1615 [========================>.....] - ETA: 16:49 - loss: 6.1938 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1382/1615 [========================>.....] - ETA: 16:40 - loss: 6.1939 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1384/1615 [========================>.....] - ETA: 16:32 - loss: 6.1939 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1386/1615 [========================>.....] - ETA: 16:23 - loss: 6.1935 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1388/1615 [========================>.....] - ETA: 16:15 - loss: 6.1935 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1390/1615 [========================>.....] - ETA: 16:06 - loss: 6.1936 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1392/1615 [========================>.....] - ETA: 15:57 - loss: 6.1935 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1394/1615 [========================>.....] - ETA: 15:49 - loss: 6.1929 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1396/1615 [========================>.....] - ETA: 15:40 - loss: 6.1931 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1398/1615 [========================>.....] - ETA: 15:32 - loss: 6.1930 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1400/1615 [=========================>....] - ETA: 15:23 - loss: 6.1927 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1402/1615 [=========================>....] - ETA: 15:15 - loss: 6.1924 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1404/1615 [=========================>....] - ETA: 15:06 - loss: 6.1929 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1406/1615 [=========================>....] - ETA: 14:58 - loss: 6.1931 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1408/1615 [=========================>....] - ETA: 14:49 - loss: 6.1931 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1410/1615 [=========================>....] - ETA: 14:40 - loss: 6.1930 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1412/1615 [=========================>....] - ETA: 14:32 - loss: 6.1926 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1414/1615 [=========================>....] - ETA: 14:23 - loss: 6.1924 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1416/1615 [=========================>....] - ETA: 14:14 - loss: 6.1925 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1418/1615 [=========================>....] - ETA: 14:06 - loss: 6.1924 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1420/1615 [=========================>....] - ETA: 13:57 - loss: 6.1924 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1422/1615 [=========================>....] - ETA: 13:49 - loss: 6.1926 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1424/1615 [=========================>....] - ETA: 13:40 - loss: 6.1927 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1426/1615 [=========================>....] - ETA: 13:31 - loss: 6.1928 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1428/1615 [=========================>....] - ETA: 13:23 - loss: 6.1923 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1430/1615 [=========================>....] - ETA: 13:14 - loss: 6.1924 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1432/1615 [=========================>....] - ETA: 13:06 - loss: 6.1925 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1434/1615 [=========================>....] - ETA: 12:57 - loss: 6.1922 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1436/1615 [=========================>....] - ETA: 12:49 - loss: 6.1918 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1438/1615 [=========================>....] - ETA: 12:40 - loss: 6.1919 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1440/1615 [=========================>....] - ETA: 12:31 - loss: 6.1926 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1442/1615 [=========================>....] - ETA: 12:23 - loss: 6.1929 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1444/1615 [=========================>....] - ETA: 12:14 - loss: 6.1927 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1446/1615 [=========================>....] - ETA: 12:06 - loss: 6.1931 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1448/1615 [=========================>....] - ETA: 11:57 - loss: 6.1932 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1450/1615 [=========================>....] - ETA: 11:49 - loss: 6.1933 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1452/1615 [=========================>....] - ETA: 11:40 - loss: 6.1933 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1454/1615 [==========================>...] - ETA: 11:31 - loss: 6.1932 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1456/1615 [==========================>...] - ETA: 11:23 - loss: 6.1933 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1458/1615 [==========================>...] - ETA: 11:14 - loss: 6.1936 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1460/1615 [==========================>...] - ETA: 11:05 - loss: 6.1938 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1462/1615 [==========================>...] - ETA: 10:57 - loss: 6.1940 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1464/1615 [==========================>...] - ETA: 10:48 - loss: 6.1941 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1466/1615 [==========================>...] - ETA: 10:40 - loss: 6.1942 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1468/1615 [==========================>...] - ETA: 10:31 - loss: 6.1941 - accuracy: 0.1185\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1470/1615 [==========================>...] - ETA: 10:22 - loss: 6.1939 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1472/1615 [==========================>...] - ETA: 10:14 - loss: 6.1939 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1474/1615 [==========================>...] - ETA: 10:05 - loss: 6.1941 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1476/1615 [==========================>...] - ETA: 9:57 - loss: 6.1941 - accuracy: 0.1186 \n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1478/1615 [==========================>...] - ETA: 9:48 - loss: 6.1943 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1480/1615 [==========================>...] - ETA: 9:39 - loss: 6.1936 - accuracy: 0.1186\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1482/1615 [==========================>...] - ETA: 9:31 - loss: 6.1932 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1484/1615 [==========================>...] - ETA: 9:22 - loss: 6.1933 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1486/1615 [==========================>...] - ETA: 9:14 - loss: 6.1931 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1488/1615 [==========================>...] - ETA: 9:05 - loss: 6.1930 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1490/1615 [==========================>...] - ETA: 8:57 - loss: 6.1930 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1492/1615 [==========================>...] - ETA: 8:48 - loss: 6.1931 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1494/1615 [==========================>...] - ETA: 8:40 - loss: 6.1929 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1496/1615 [==========================>...] - ETA: 8:31 - loss: 6.1927 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1498/1615 [==========================>...] - ETA: 8:22 - loss: 6.1930 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1500/1615 [==========================>...] - ETA: 8:14 - loss: 6.1928 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1502/1615 [==========================>...] - ETA: 8:05 - loss: 6.1925 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1504/1615 [==========================>...] - ETA: 7:57 - loss: 6.1926 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1506/1615 [==========================>...] - ETA: 7:48 - loss: 6.1927 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1508/1615 [===========================>..] - ETA: 7:39 - loss: 6.1926 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1510/1615 [===========================>..] - ETA: 7:31 - loss: 6.1931 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1512/1615 [===========================>..] - ETA: 7:22 - loss: 6.1929 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1514/1615 [===========================>..] - ETA: 7:13 - loss: 6.1927 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1516/1615 [===========================>..] - ETA: 7:05 - loss: 6.1927 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1518/1615 [===========================>..] - ETA: 6:56 - loss: 6.1931 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1520/1615 [===========================>..] - ETA: 6:48 - loss: 6.1933 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1522/1615 [===========================>..] - ETA: 6:39 - loss: 6.1933 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1524/1615 [===========================>..] - ETA: 6:30 - loss: 6.1933 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1526/1615 [===========================>..] - ETA: 6:22 - loss: 6.1932 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1528/1615 [===========================>..] - ETA: 6:13 - loss: 6.1930 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1530/1615 [===========================>..] - ETA: 6:05 - loss: 6.1930 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1532/1615 [===========================>..] - ETA: 5:56 - loss: 6.1927 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1534/1615 [===========================>..] - ETA: 5:47 - loss: 6.1929 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1536/1615 [===========================>..] - ETA: 5:39 - loss: 6.1930 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1538/1615 [===========================>..] - ETA: 5:30 - loss: 6.1924 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1540/1615 [===========================>..] - ETA: 5:22 - loss: 6.1925 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1542/1615 [===========================>..] - ETA: 5:13 - loss: 6.1925 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1544/1615 [===========================>..] - ETA: 5:05 - loss: 6.1925 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1546/1615 [===========================>..] - ETA: 4:56 - loss: 6.1929 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1548/1615 [===========================>..] - ETA: 4:47 - loss: 6.1930 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1550/1615 [===========================>..] - ETA: 4:39 - loss: 6.1929 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1552/1615 [===========================>..] - ETA: 4:30 - loss: 6.1926 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1554/1615 [===========================>..] - ETA: 4:22 - loss: 6.1934 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1556/1615 [===========================>..] - ETA: 4:13 - loss: 6.1934 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1558/1615 [===========================>..] - ETA: 4:04 - loss: 6.1934 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1560/1615 [===========================>..] - ETA: 3:56 - loss: 6.1932 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1562/1615 [============================>.] - ETA: 3:47 - loss: 6.1932 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1564/1615 [============================>.] - ETA: 3:39 - loss: 6.1935 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1566/1615 [============================>.] - ETA: 3:30 - loss: 6.1934 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1568/1615 [============================>.] - ETA: 3:21 - loss: 6.1933 - accuracy: 0.1187\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1570/1615 [============================>.] - ETA: 3:13 - loss: 6.1927 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1572/1615 [============================>.] - ETA: 3:04 - loss: 6.1925 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1574/1615 [============================>.] - ETA: 2:56 - loss: 6.1924 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1576/1615 [============================>.] - ETA: 2:47 - loss: 6.1922 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1578/1615 [============================>.] - ETA: 2:38 - loss: 6.1920 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1580/1615 [============================>.] - ETA: 2:30 - loss: 6.1921 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1582/1615 [============================>.] - ETA: 2:21 - loss: 6.1921 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1584/1615 [============================>.] - ETA: 2:13 - loss: 6.1923 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1586/1615 [============================>.] - ETA: 2:04 - loss: 6.1921 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1588/1615 [============================>.] - ETA: 1:56 - loss: 6.1918 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1590/1615 [============================>.] - ETA: 1:47 - loss: 6.1919 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1592/1615 [============================>.] - ETA: 1:38 - loss: 6.1919 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1594/1615 [============================>.] - ETA: 1:30 - loss: 6.1914 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1596/1615 [============================>.] - ETA: 1:21 - loss: 6.1913 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1598/1615 [============================>.] - ETA: 1:13 - loss: 6.1915 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1600/1615 [============================>.] - ETA: 1:04 - loss: 6.1914 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1602/1615 [============================>.] - ETA: 55s - loss: 6.1910 - accuracy: 0.1188 \n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1604/1615 [============================>.] - ETA: 47s - loss: 6.1911 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1606/1615 [============================>.] - ETA: 38s - loss: 6.1908 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1608/1615 [============================>.] - ETA: 30s - loss: 6.1908 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1610/1615 [============================>.] - ETA: 21s - loss: 6.1909 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1612/1615 [============================>.] - ETA: 12s - loss: 6.1910 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1614/1615 [============================>.] - ETA: 4s - loss: 6.1913 - accuracy: 0.1188\n",
            "Epoch 4: saving model to ./train_ckpt/cp.ckpt\n",
            "1615/1615 [==============================] - 6949s 4s/step - loss: 6.1916 - accuracy: 0.1187 - val_loss: 7.4182 - val_accuracy: 0.1072\n",
            "Epoch 5/10\n",
            "   1/1615 [..............................] - ETA: 51:34 - loss: 5.3594 - accuracy: 0.2000\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "   3/1615 [..............................] - ETA: 1:39:11 - loss: 5.7876 - accuracy: 0.1633\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "   5/1615 [..............................] - ETA: 1:37:45 - loss: 5.9096 - accuracy: 0.1340\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "   7/1615 [..............................] - ETA: 1:36:46 - loss: 5.9854 - accuracy: 0.1400\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "   9/1615 [..............................] - ETA: 1:39:49 - loss: 6.0146 - accuracy: 0.1378\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  11/1615 [..............................] - ETA: 1:40:42 - loss: 6.0018 - accuracy: 0.1345\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  13/1615 [..............................] - ETA: 1:42:33 - loss: 6.0764 - accuracy: 0.1285\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  15/1615 [..............................] - ETA: 1:45:25 - loss: 6.0877 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  17/1615 [..............................] - ETA: 1:49:10 - loss: 6.0741 - accuracy: 0.1276\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  19/1615 [..............................] - ETA: 1:47:19 - loss: 6.0918 - accuracy: 0.1268\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  21/1615 [..............................] - ETA: 1:47:25 - loss: 6.0826 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  23/1615 [..............................] - ETA: 1:47:59 - loss: 6.0588 - accuracy: 0.1283\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  25/1615 [..............................] - ETA: 1:48:10 - loss: 6.0815 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  27/1615 [..............................] - ETA: 1:48:35 - loss: 6.0931 - accuracy: 0.1222\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  29/1615 [..............................] - ETA: 1:48:44 - loss: 6.0862 - accuracy: 0.1228\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  31/1615 [..............................] - ETA: 1:49:59 - loss: 6.0748 - accuracy: 0.1216\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  33/1615 [..............................] - ETA: 1:49:05 - loss: 6.0956 - accuracy: 0.1194\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  35/1615 [..............................] - ETA: 1:50:32 - loss: 6.0887 - accuracy: 0.1197\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  37/1615 [..............................] - ETA: 1:49:36 - loss: 6.1133 - accuracy: 0.1173\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  39/1615 [..............................] - ETA: 1:49:26 - loss: 6.1116 - accuracy: 0.1192\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  41/1615 [..............................] - ETA: 1:49:21 - loss: 6.1167 - accuracy: 0.1185\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  43/1615 [..............................] - ETA: 1:49:33 - loss: 6.1090 - accuracy: 0.1200\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  45/1615 [..............................] - ETA: 1:49:48 - loss: 6.1113 - accuracy: 0.1209\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  47/1615 [..............................] - ETA: 1:49:35 - loss: 6.1105 - accuracy: 0.1223\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  49/1615 [..............................] - ETA: 1:49:31 - loss: 6.1023 - accuracy: 0.1222\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  51/1615 [..............................] - ETA: 1:49:37 - loss: 6.0996 - accuracy: 0.1231\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  53/1615 [..............................] - ETA: 1:49:35 - loss: 6.0869 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  55/1615 [>.............................] - ETA: 1:49:28 - loss: 6.0881 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  57/1615 [>.............................] - ETA: 1:49:47 - loss: 6.0718 - accuracy: 0.1267\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  59/1615 [>.............................] - ETA: 1:49:12 - loss: 6.0753 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  61/1615 [>.............................] - ETA: 1:49:16 - loss: 6.0726 - accuracy: 0.1257\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  63/1615 [>.............................] - ETA: 1:49:07 - loss: 6.0728 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  65/1615 [>.............................] - ETA: 1:49:05 - loss: 6.0817 - accuracy: 0.1265\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  67/1615 [>.............................] - ETA: 1:49:13 - loss: 6.0743 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  69/1615 [>.............................] - ETA: 1:48:50 - loss: 6.0624 - accuracy: 0.1268\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  71/1615 [>.............................] - ETA: 1:48:49 - loss: 6.0598 - accuracy: 0.1277\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  73/1615 [>.............................] - ETA: 1:48:41 - loss: 6.0552 - accuracy: 0.1273\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  75/1615 [>.............................] - ETA: 1:48:36 - loss: 6.0499 - accuracy: 0.1288\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  77/1615 [>.............................] - ETA: 1:48:57 - loss: 6.0469 - accuracy: 0.1291\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  79/1615 [>.............................] - ETA: 1:48:50 - loss: 6.0451 - accuracy: 0.1296\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  81/1615 [>.............................] - ETA: 1:48:22 - loss: 6.0469 - accuracy: 0.1286\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  83/1615 [>.............................] - ETA: 1:48:14 - loss: 6.0508 - accuracy: 0.1284\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  85/1615 [>.............................] - ETA: 1:48:16 - loss: 6.0621 - accuracy: 0.1269\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  87/1615 [>.............................] - ETA: 1:48:02 - loss: 6.0671 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  89/1615 [>.............................] - ETA: 1:47:59 - loss: 6.0752 - accuracy: 0.1252\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  91/1615 [>.............................] - ETA: 1:47:53 - loss: 6.0734 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  93/1615 [>.............................] - ETA: 1:48:07 - loss: 6.0731 - accuracy: 0.1240\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  95/1615 [>.............................] - ETA: 1:47:48 - loss: 6.0687 - accuracy: 0.1242\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  97/1615 [>.............................] - ETA: 1:47:30 - loss: 6.0680 - accuracy: 0.1243\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "  99/1615 [>.............................] - ETA: 1:47:50 - loss: 6.0649 - accuracy: 0.1248\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 101/1615 [>.............................] - ETA: 1:47:25 - loss: 6.0759 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 103/1615 [>.............................] - ETA: 1:47:10 - loss: 6.0781 - accuracy: 0.1231\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 105/1615 [>.............................] - ETA: 1:47:01 - loss: 6.0815 - accuracy: 0.1220\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 107/1615 [>.............................] - ETA: 1:47:15 - loss: 6.0858 - accuracy: 0.1211\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 109/1615 [=>............................] - ETA: 1:46:49 - loss: 6.0793 - accuracy: 0.1220\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 111/1615 [=>............................] - ETA: 1:46:43 - loss: 6.0778 - accuracy: 0.1215\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 113/1615 [=>............................] - ETA: 1:46:34 - loss: 6.0837 - accuracy: 0.1215\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 115/1615 [=>............................] - ETA: 1:46:29 - loss: 6.0807 - accuracy: 0.1215\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 117/1615 [=>............................] - ETA: 1:46:20 - loss: 6.0778 - accuracy: 0.1214\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 119/1615 [=>............................] - ETA: 1:46:12 - loss: 6.0760 - accuracy: 0.1211\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 121/1615 [=>............................] - ETA: 1:46:08 - loss: 6.0808 - accuracy: 0.1211\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 123/1615 [=>............................] - ETA: 1:45:57 - loss: 6.0825 - accuracy: 0.1212\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 125/1615 [=>............................] - ETA: 1:46:08 - loss: 6.0883 - accuracy: 0.1213\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 127/1615 [=>............................] - ETA: 1:45:52 - loss: 6.0839 - accuracy: 0.1219\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 129/1615 [=>............................] - ETA: 1:45:33 - loss: 6.0862 - accuracy: 0.1219\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 131/1615 [=>............................] - ETA: 1:45:37 - loss: 6.0868 - accuracy: 0.1218\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 133/1615 [=>............................] - ETA: 1:45:35 - loss: 6.0906 - accuracy: 0.1218\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 135/1615 [=>............................] - ETA: 1:45:13 - loss: 6.0922 - accuracy: 0.1218\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 137/1615 [=>............................] - ETA: 1:45:04 - loss: 6.0912 - accuracy: 0.1216\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 139/1615 [=>............................] - ETA: 1:44:53 - loss: 6.0903 - accuracy: 0.1214\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 141/1615 [=>............................] - ETA: 1:44:46 - loss: 6.0873 - accuracy: 0.1218\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 143/1615 [=>............................] - ETA: 1:44:38 - loss: 6.0870 - accuracy: 0.1217\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 145/1615 [=>............................] - ETA: 1:44:32 - loss: 6.0864 - accuracy: 0.1224\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 147/1615 [=>............................] - ETA: 1:44:37 - loss: 6.0883 - accuracy: 0.1222\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 149/1615 [=>............................] - ETA: 1:44:16 - loss: 6.0855 - accuracy: 0.1226\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 151/1615 [=>............................] - ETA: 1:44:08 - loss: 6.0877 - accuracy: 0.1226\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 153/1615 [=>............................] - ETA: 1:43:58 - loss: 6.0897 - accuracy: 0.1220\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 155/1615 [=>............................] - ETA: 1:43:53 - loss: 6.0925 - accuracy: 0.1217\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 157/1615 [=>............................] - ETA: 1:43:59 - loss: 6.0954 - accuracy: 0.1213\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 159/1615 [=>............................] - ETA: 1:43:41 - loss: 6.0937 - accuracy: 0.1213\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 161/1615 [=>............................] - ETA: 1:43:42 - loss: 6.0931 - accuracy: 0.1212\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 163/1615 [==>...........................] - ETA: 1:43:26 - loss: 6.0909 - accuracy: 0.1212\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 165/1615 [==>...........................] - ETA: 1:43:13 - loss: 6.0910 - accuracy: 0.1213\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 167/1615 [==>...........................] - ETA: 1:43:03 - loss: 6.0889 - accuracy: 0.1214\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 169/1615 [==>...........................] - ETA: 1:42:55 - loss: 6.0888 - accuracy: 0.1217\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 171/1615 [==>...........................] - ETA: 1:42:47 - loss: 6.0880 - accuracy: 0.1215\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 173/1615 [==>...........................] - ETA: 1:42:38 - loss: 6.0888 - accuracy: 0.1217\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 175/1615 [==>...........................] - ETA: 1:42:43 - loss: 6.0867 - accuracy: 0.1218\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 177/1615 [==>...........................] - ETA: 1:42:25 - loss: 6.0848 - accuracy: 0.1220\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 179/1615 [==>...........................] - ETA: 1:42:14 - loss: 6.0840 - accuracy: 0.1221\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 181/1615 [==>...........................] - ETA: 1:42:08 - loss: 6.0848 - accuracy: 0.1219\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 183/1615 [==>...........................] - ETA: 1:42:12 - loss: 6.0872 - accuracy: 0.1217\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 185/1615 [==>...........................] - ETA: 1:41:54 - loss: 6.0860 - accuracy: 0.1217\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 187/1615 [==>...........................] - ETA: 1:41:43 - loss: 6.0896 - accuracy: 0.1213\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 189/1615 [==>...........................] - ETA: 1:41:44 - loss: 6.0918 - accuracy: 0.1212\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 191/1615 [==>...........................] - ETA: 1:41:29 - loss: 6.0883 - accuracy: 0.1216\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 193/1615 [==>...........................] - ETA: 1:41:32 - loss: 6.0914 - accuracy: 0.1212\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 195/1615 [==>...........................] - ETA: 1:41:15 - loss: 6.0915 - accuracy: 0.1214\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 197/1615 [==>...........................] - ETA: 1:41:04 - loss: 6.0892 - accuracy: 0.1218\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 199/1615 [==>...........................] - ETA: 1:40:55 - loss: 6.0890 - accuracy: 0.1218\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 201/1615 [==>...........................] - ETA: 1:40:45 - loss: 6.0902 - accuracy: 0.1216\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 203/1615 [==>...........................] - ETA: 1:40:50 - loss: 6.0940 - accuracy: 0.1213\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 205/1615 [==>...........................] - ETA: 1:40:34 - loss: 6.0942 - accuracy: 0.1217\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 207/1615 [==>...........................] - ETA: 1:40:32 - loss: 6.0919 - accuracy: 0.1219\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 209/1615 [==>...........................] - ETA: 1:40:17 - loss: 6.0913 - accuracy: 0.1219\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 211/1615 [==>...........................] - ETA: 1:40:13 - loss: 6.0896 - accuracy: 0.1219\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 213/1615 [==>...........................] - ETA: 1:39:57 - loss: 6.0901 - accuracy: 0.1216\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 215/1615 [==>...........................] - ETA: 1:39:48 - loss: 6.0911 - accuracy: 0.1217\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 217/1615 [===>..........................] - ETA: 1:39:50 - loss: 6.0871 - accuracy: 0.1220\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 219/1615 [===>..........................] - ETA: 1:39:40 - loss: 6.0875 - accuracy: 0.1221\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 221/1615 [===>..........................] - ETA: 1:39:27 - loss: 6.0884 - accuracy: 0.1223\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 223/1615 [===>..........................] - ETA: 1:39:18 - loss: 6.0893 - accuracy: 0.1222\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 225/1615 [===>..........................] - ETA: 1:39:09 - loss: 6.0896 - accuracy: 0.1221\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 227/1615 [===>..........................] - ETA: 1:39:11 - loss: 6.0916 - accuracy: 0.1219\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 229/1615 [===>..........................] - ETA: 1:38:57 - loss: 6.0933 - accuracy: 0.1219\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 231/1615 [===>..........................] - ETA: 1:38:43 - loss: 6.0933 - accuracy: 0.1217\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 233/1615 [===>..........................] - ETA: 1:38:34 - loss: 6.0948 - accuracy: 0.1215\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 235/1615 [===>..........................] - ETA: 1:38:34 - loss: 6.0960 - accuracy: 0.1214\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 237/1615 [===>..........................] - ETA: 1:38:18 - loss: 6.0984 - accuracy: 0.1213\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 239/1615 [===>..........................] - ETA: 1:38:09 - loss: 6.0972 - accuracy: 0.1214\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 241/1615 [===>..........................] - ETA: 1:38:04 - loss: 6.0959 - accuracy: 0.1215\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 243/1615 [===>..........................] - ETA: 1:37:53 - loss: 6.0947 - accuracy: 0.1216\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 245/1615 [===>..........................] - ETA: 1:37:48 - loss: 6.0931 - accuracy: 0.1218\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 247/1615 [===>..........................] - ETA: 1:37:36 - loss: 6.0912 - accuracy: 0.1217\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 249/1615 [===>..........................] - ETA: 1:37:29 - loss: 6.0924 - accuracy: 0.1216\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 251/1615 [===>..........................] - ETA: 1:37:21 - loss: 6.0950 - accuracy: 0.1216\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 253/1615 [===>..........................] - ETA: 1:37:12 - loss: 6.0949 - accuracy: 0.1215\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 255/1615 [===>..........................] - ETA: 1:37:03 - loss: 6.0923 - accuracy: 0.1220\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 257/1615 [===>..........................] - ETA: 1:36:54 - loss: 6.0918 - accuracy: 0.1219\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 259/1615 [===>..........................] - ETA: 1:36:45 - loss: 6.0933 - accuracy: 0.1218\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 261/1615 [===>..........................] - ETA: 1:36:37 - loss: 6.0929 - accuracy: 0.1220\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 263/1615 [===>..........................] - ETA: 1:36:33 - loss: 6.0933 - accuracy: 0.1220\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 265/1615 [===>..........................] - ETA: 1:36:20 - loss: 6.0941 - accuracy: 0.1217\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 267/1615 [===>..........................] - ETA: 1:36:12 - loss: 6.0942 - accuracy: 0.1219\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 269/1615 [===>..........................] - ETA: 1:36:05 - loss: 6.0937 - accuracy: 0.1221\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 271/1615 [====>.........................] - ETA: 1:35:56 - loss: 6.0921 - accuracy: 0.1221\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 273/1615 [====>.........................] - ETA: 1:35:48 - loss: 6.0917 - accuracy: 0.1222\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 275/1615 [====>.........................] - ETA: 1:35:40 - loss: 6.0917 - accuracy: 0.1222\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 277/1615 [====>.........................] - ETA: 1:35:31 - loss: 6.0921 - accuracy: 0.1223\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 279/1615 [====>.........................] - ETA: 1:35:23 - loss: 6.0914 - accuracy: 0.1224\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 281/1615 [====>.........................] - ETA: 1:35:14 - loss: 6.0924 - accuracy: 0.1221\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 283/1615 [====>.........................] - ETA: 1:35:05 - loss: 6.0949 - accuracy: 0.1220\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 285/1615 [====>.........................] - ETA: 1:34:58 - loss: 6.0962 - accuracy: 0.1219\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 287/1615 [====>.........................] - ETA: 1:34:49 - loss: 6.0933 - accuracy: 0.1222\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 289/1615 [====>.........................] - ETA: 1:34:41 - loss: 6.0943 - accuracy: 0.1223\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 291/1615 [====>.........................] - ETA: 1:34:32 - loss: 6.0934 - accuracy: 0.1224\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 293/1615 [====>.........................] - ETA: 1:34:24 - loss: 6.0930 - accuracy: 0.1225\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 295/1615 [====>.........................] - ETA: 1:34:16 - loss: 6.0950 - accuracy: 0.1224\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 297/1615 [====>.........................] - ETA: 1:34:08 - loss: 6.0966 - accuracy: 0.1224\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 299/1615 [====>.........................] - ETA: 1:33:59 - loss: 6.0962 - accuracy: 0.1225\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 301/1615 [====>.........................] - ETA: 1:33:50 - loss: 6.0961 - accuracy: 0.1229\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 303/1615 [====>.........................] - ETA: 1:33:43 - loss: 6.0939 - accuracy: 0.1232\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 305/1615 [====>.........................] - ETA: 1:33:34 - loss: 6.0906 - accuracy: 0.1235\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 307/1615 [====>.........................] - ETA: 1:33:25 - loss: 6.0898 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 309/1615 [====>.........................] - ETA: 1:33:16 - loss: 6.0905 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 311/1615 [====>.........................] - ETA: 1:33:08 - loss: 6.0914 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 313/1615 [====>.........................] - ETA: 1:33:00 - loss: 6.0911 - accuracy: 0.1235\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 315/1615 [====>.........................] - ETA: 1:32:51 - loss: 6.0911 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 317/1615 [====>.........................] - ETA: 1:32:44 - loss: 6.0887 - accuracy: 0.1239\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 319/1615 [====>.........................] - ETA: 1:32:35 - loss: 6.0911 - accuracy: 0.1238\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 321/1615 [====>.........................] - ETA: 1:32:26 - loss: 6.0911 - accuracy: 0.1238\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 323/1615 [=====>........................] - ETA: 1:32:25 - loss: 6.0886 - accuracy: 0.1239\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 325/1615 [=====>........................] - ETA: 1:32:13 - loss: 6.0903 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 327/1615 [=====>........................] - ETA: 1:32:01 - loss: 6.0893 - accuracy: 0.1238\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 329/1615 [=====>........................] - ETA: 1:31:51 - loss: 6.0880 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 331/1615 [=====>........................] - ETA: 1:31:44 - loss: 6.0855 - accuracy: 0.1239\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 333/1615 [=====>........................] - ETA: 1:31:36 - loss: 6.0866 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 335/1615 [=====>........................] - ETA: 1:31:26 - loss: 6.0861 - accuracy: 0.1234\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 337/1615 [=====>........................] - ETA: 1:31:19 - loss: 6.0845 - accuracy: 0.1235\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 339/1615 [=====>........................] - ETA: 1:31:11 - loss: 6.0837 - accuracy: 0.1235\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 341/1615 [=====>........................] - ETA: 1:31:03 - loss: 6.0847 - accuracy: 0.1235\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 343/1615 [=====>........................] - ETA: 1:30:53 - loss: 6.0859 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 345/1615 [=====>........................] - ETA: 1:30:45 - loss: 6.0866 - accuracy: 0.1235\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 347/1615 [=====>........................] - ETA: 1:30:43 - loss: 6.0867 - accuracy: 0.1234\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 349/1615 [=====>........................] - ETA: 1:30:33 - loss: 6.0859 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 351/1615 [=====>........................] - ETA: 1:30:23 - loss: 6.0848 - accuracy: 0.1238\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 353/1615 [=====>........................] - ETA: 1:30:13 - loss: 6.0845 - accuracy: 0.1238\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 355/1615 [=====>........................] - ETA: 1:30:03 - loss: 6.0857 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 357/1615 [=====>........................] - ETA: 1:29:55 - loss: 6.0869 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 359/1615 [=====>........................] - ETA: 1:29:45 - loss: 6.0856 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 361/1615 [=====>........................] - ETA: 1:29:37 - loss: 6.0854 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 363/1615 [=====>........................] - ETA: 1:29:28 - loss: 6.0859 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 365/1615 [=====>........................] - ETA: 1:29:25 - loss: 6.0850 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 367/1615 [=====>........................] - ETA: 1:29:13 - loss: 6.0846 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 369/1615 [=====>........................] - ETA: 1:29:02 - loss: 6.0844 - accuracy: 0.1235\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 371/1615 [=====>........................] - ETA: 1:28:59 - loss: 6.0834 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 373/1615 [=====>........................] - ETA: 1:28:48 - loss: 6.0849 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 375/1615 [=====>........................] - ETA: 1:28:37 - loss: 6.0841 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 377/1615 [======>.......................] - ETA: 1:28:29 - loss: 6.0851 - accuracy: 0.1233\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 379/1615 [======>.......................] - ETA: 1:28:25 - loss: 6.0851 - accuracy: 0.1233\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 381/1615 [======>.......................] - ETA: 1:28:13 - loss: 6.0859 - accuracy: 0.1232\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 383/1615 [======>.......................] - ETA: 1:28:03 - loss: 6.0851 - accuracy: 0.1235\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 385/1615 [======>.......................] - ETA: 1:27:55 - loss: 6.0855 - accuracy: 0.1235\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 387/1615 [======>.......................] - ETA: 1:27:46 - loss: 6.0838 - accuracy: 0.1238\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 389/1615 [======>.......................] - ETA: 1:27:37 - loss: 6.0828 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 391/1615 [======>.......................] - ETA: 1:27:28 - loss: 6.0816 - accuracy: 0.1238\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 393/1615 [======>.......................] - ETA: 1:27:25 - loss: 6.0813 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 395/1615 [======>.......................] - ETA: 1:27:11 - loss: 6.0818 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 397/1615 [======>.......................] - ETA: 1:27:02 - loss: 6.0829 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 399/1615 [======>.......................] - ETA: 1:26:59 - loss: 6.0814 - accuracy: 0.1238\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 401/1615 [======>.......................] - ETA: 1:26:46 - loss: 6.0812 - accuracy: 0.1239\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 403/1615 [======>.......................] - ETA: 1:26:37 - loss: 6.0813 - accuracy: 0.1238\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 405/1615 [======>.......................] - ETA: 1:26:34 - loss: 6.0818 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 407/1615 [======>.......................] - ETA: 1:26:21 - loss: 6.0810 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 409/1615 [======>.......................] - ETA: 1:26:12 - loss: 6.0811 - accuracy: 0.1235\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 411/1615 [======>.......................] - ETA: 1:26:04 - loss: 6.0819 - accuracy: 0.1235\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 413/1615 [======>.......................] - ETA: 1:25:55 - loss: 6.0826 - accuracy: 0.1232\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 415/1615 [======>.......................] - ETA: 1:25:52 - loss: 6.0820 - accuracy: 0.1232\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 417/1615 [======>.......................] - ETA: 1:25:41 - loss: 6.0812 - accuracy: 0.1234\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 419/1615 [======>.......................] - ETA: 1:25:34 - loss: 6.0801 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 421/1615 [======>.......................] - ETA: 1:25:22 - loss: 6.0791 - accuracy: 0.1238\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 423/1615 [======>.......................] - ETA: 1:25:12 - loss: 6.0796 - accuracy: 0.1240\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 425/1615 [======>.......................] - ETA: 1:25:04 - loss: 6.0788 - accuracy: 0.1240\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 427/1615 [======>.......................] - ETA: 1:24:56 - loss: 6.0781 - accuracy: 0.1239\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 429/1615 [======>.......................] - ETA: 1:24:47 - loss: 6.0781 - accuracy: 0.1239\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 431/1615 [=======>......................] - ETA: 1:24:40 - loss: 6.0776 - accuracy: 0.1241\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 433/1615 [=======>......................] - ETA: 1:24:33 - loss: 6.0765 - accuracy: 0.1242\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 435/1615 [=======>......................] - ETA: 1:24:22 - loss: 6.0770 - accuracy: 0.1242\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 437/1615 [=======>......................] - ETA: 1:24:13 - loss: 6.0778 - accuracy: 0.1242\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 439/1615 [=======>......................] - ETA: 1:24:05 - loss: 6.0784 - accuracy: 0.1241\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 441/1615 [=======>......................] - ETA: 1:23:59 - loss: 6.0795 - accuracy: 0.1241\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 443/1615 [=======>......................] - ETA: 1:23:48 - loss: 6.0787 - accuracy: 0.1240\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 445/1615 [=======>......................] - ETA: 1:23:43 - loss: 6.0775 - accuracy: 0.1241\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 447/1615 [=======>......................] - ETA: 1:23:32 - loss: 6.0786 - accuracy: 0.1240\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 449/1615 [=======>......................] - ETA: 1:23:22 - loss: 6.0807 - accuracy: 0.1238\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 451/1615 [=======>......................] - ETA: 1:23:19 - loss: 6.0810 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 453/1615 [=======>......................] - ETA: 1:23:07 - loss: 6.0804 - accuracy: 0.1238\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 455/1615 [=======>......................] - ETA: 1:22:57 - loss: 6.0807 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 457/1615 [=======>......................] - ETA: 1:22:48 - loss: 6.0799 - accuracy: 0.1238\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 459/1615 [=======>......................] - ETA: 1:22:39 - loss: 6.0804 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 461/1615 [=======>......................] - ETA: 1:22:33 - loss: 6.0809 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 463/1615 [=======>......................] - ETA: 1:22:22 - loss: 6.0810 - accuracy: 0.1238\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 465/1615 [=======>......................] - ETA: 1:22:14 - loss: 6.0800 - accuracy: 0.1238\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 467/1615 [=======>......................] - ETA: 1:22:06 - loss: 6.0790 - accuracy: 0.1239\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 469/1615 [=======>......................] - ETA: 1:21:57 - loss: 6.0784 - accuracy: 0.1239\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 471/1615 [=======>......................] - ETA: 1:21:51 - loss: 6.0799 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 473/1615 [=======>......................] - ETA: 1:21:42 - loss: 6.0799 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 475/1615 [=======>......................] - ETA: 1:21:31 - loss: 6.0784 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 477/1615 [=======>......................] - ETA: 1:21:25 - loss: 6.0772 - accuracy: 0.1238\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 479/1615 [=======>......................] - ETA: 1:21:14 - loss: 6.0770 - accuracy: 0.1238\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 481/1615 [=======>......................] - ETA: 1:21:06 - loss: 6.0778 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 483/1615 [=======>......................] - ETA: 1:20:59 - loss: 6.0783 - accuracy: 0.1235\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 485/1615 [========>.....................] - ETA: 1:20:49 - loss: 6.0774 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 487/1615 [========>.....................] - ETA: 1:20:40 - loss: 6.0776 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 489/1615 [========>.....................] - ETA: 1:20:32 - loss: 6.0763 - accuracy: 0.1238\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 491/1615 [========>.....................] - ETA: 1:20:23 - loss: 6.0763 - accuracy: 0.1240\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 493/1615 [========>.....................] - ETA: 1:20:16 - loss: 6.0754 - accuracy: 0.1240\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 495/1615 [========>.....................] - ETA: 1:20:06 - loss: 6.0746 - accuracy: 0.1240\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 497/1615 [========>.....................] - ETA: 1:19:57 - loss: 6.0732 - accuracy: 0.1241\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 499/1615 [========>.....................] - ETA: 1:19:50 - loss: 6.0732 - accuracy: 0.1240\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 501/1615 [========>.....................] - ETA: 1:19:40 - loss: 6.0730 - accuracy: 0.1241\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 503/1615 [========>.....................] - ETA: 1:19:33 - loss: 6.0749 - accuracy: 0.1240\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 505/1615 [========>.....................] - ETA: 1:19:26 - loss: 6.0755 - accuracy: 0.1239\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 507/1615 [========>.....................] - ETA: 1:19:14 - loss: 6.0748 - accuracy: 0.1240\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 509/1615 [========>.....................] - ETA: 1:19:06 - loss: 6.0755 - accuracy: 0.1239\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 511/1615 [========>.....................] - ETA: 1:18:58 - loss: 6.0739 - accuracy: 0.1240\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 513/1615 [========>.....................] - ETA: 1:18:49 - loss: 6.0733 - accuracy: 0.1241\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 515/1615 [========>.....................] - ETA: 1:18:40 - loss: 6.0735 - accuracy: 0.1241\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 517/1615 [========>.....................] - ETA: 1:18:32 - loss: 6.0746 - accuracy: 0.1241\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 519/1615 [========>.....................] - ETA: 1:18:23 - loss: 6.0760 - accuracy: 0.1241\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 521/1615 [========>.....................] - ETA: 1:18:17 - loss: 6.0754 - accuracy: 0.1242\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 523/1615 [========>.....................] - ETA: 1:18:07 - loss: 6.0765 - accuracy: 0.1242\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 525/1615 [========>.....................] - ETA: 1:17:58 - loss: 6.0760 - accuracy: 0.1243\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 527/1615 [========>.....................] - ETA: 1:17:53 - loss: 6.0778 - accuracy: 0.1242\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 529/1615 [========>.....................] - ETA: 1:17:41 - loss: 6.0790 - accuracy: 0.1240\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 531/1615 [========>.....................] - ETA: 1:17:32 - loss: 6.0792 - accuracy: 0.1241\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 533/1615 [========>.....................] - ETA: 1:17:27 - loss: 6.0786 - accuracy: 0.1242\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 535/1615 [========>.....................] - ETA: 1:17:15 - loss: 6.0779 - accuracy: 0.1244\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 537/1615 [========>.....................] - ETA: 1:17:06 - loss: 6.0787 - accuracy: 0.1243\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 539/1615 [=========>....................] - ETA: 1:16:58 - loss: 6.0774 - accuracy: 0.1244\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 541/1615 [=========>....................] - ETA: 1:16:51 - loss: 6.0770 - accuracy: 0.1244\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 543/1615 [=========>....................] - ETA: 1:16:41 - loss: 6.0761 - accuracy: 0.1244\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 545/1615 [=========>....................] - ETA: 1:16:32 - loss: 6.0763 - accuracy: 0.1244\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 547/1615 [=========>....................] - ETA: 1:16:26 - loss: 6.0770 - accuracy: 0.1244\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 549/1615 [=========>....................] - ETA: 1:16:16 - loss: 6.0765 - accuracy: 0.1244\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 551/1615 [=========>....................] - ETA: 1:16:07 - loss: 6.0761 - accuracy: 0.1245\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 553/1615 [=========>....................] - ETA: 1:15:59 - loss: 6.0765 - accuracy: 0.1244\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 555/1615 [=========>....................] - ETA: 1:15:50 - loss: 6.0765 - accuracy: 0.1244\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 557/1615 [=========>....................] - ETA: 1:15:41 - loss: 6.0780 - accuracy: 0.1243\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 559/1615 [=========>....................] - ETA: 1:15:32 - loss: 6.0775 - accuracy: 0.1244\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 561/1615 [=========>....................] - ETA: 1:15:26 - loss: 6.0770 - accuracy: 0.1243\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 563/1615 [=========>....................] - ETA: 1:15:15 - loss: 6.0774 - accuracy: 0.1243\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 565/1615 [=========>....................] - ETA: 1:15:07 - loss: 6.0775 - accuracy: 0.1244\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 567/1615 [=========>....................] - ETA: 1:14:58 - loss: 6.0780 - accuracy: 0.1244\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 569/1615 [=========>....................] - ETA: 1:14:49 - loss: 6.0781 - accuracy: 0.1243\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 571/1615 [=========>....................] - ETA: 1:14:41 - loss: 6.0776 - accuracy: 0.1244\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 573/1615 [=========>....................] - ETA: 1:14:33 - loss: 6.0776 - accuracy: 0.1244\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 575/1615 [=========>....................] - ETA: 1:14:24 - loss: 6.0779 - accuracy: 0.1243\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 577/1615 [=========>....................] - ETA: 1:14:16 - loss: 6.0771 - accuracy: 0.1243\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 579/1615 [=========>....................] - ETA: 1:14:07 - loss: 6.0759 - accuracy: 0.1243\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 581/1615 [=========>....................] - ETA: 1:13:59 - loss: 6.0759 - accuracy: 0.1242\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 583/1615 [=========>....................] - ETA: 1:13:52 - loss: 6.0761 - accuracy: 0.1242\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 585/1615 [=========>....................] - ETA: 1:13:41 - loss: 6.0752 - accuracy: 0.1243\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 587/1615 [=========>....................] - ETA: 1:13:33 - loss: 6.0753 - accuracy: 0.1243\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 589/1615 [=========>....................] - ETA: 1:13:24 - loss: 6.0759 - accuracy: 0.1243\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 591/1615 [=========>....................] - ETA: 1:13:16 - loss: 6.0756 - accuracy: 0.1244\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 593/1615 [==========>...................] - ETA: 1:13:07 - loss: 6.0755 - accuracy: 0.1244\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 595/1615 [==========>...................] - ETA: 1:12:58 - loss: 6.0749 - accuracy: 0.1243\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 597/1615 [==========>...................] - ETA: 1:12:50 - loss: 6.0747 - accuracy: 0.1243\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 599/1615 [==========>...................] - ETA: 1:12:42 - loss: 6.0746 - accuracy: 0.1242\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 601/1615 [==========>...................] - ETA: 1:12:33 - loss: 6.0750 - accuracy: 0.1241\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 603/1615 [==========>...................] - ETA: 1:12:25 - loss: 6.0757 - accuracy: 0.1240\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 605/1615 [==========>...................] - ETA: 1:12:16 - loss: 6.0753 - accuracy: 0.1241\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 607/1615 [==========>...................] - ETA: 1:12:09 - loss: 6.0759 - accuracy: 0.1240\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 609/1615 [==========>...................] - ETA: 1:12:02 - loss: 6.0763 - accuracy: 0.1241\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 611/1615 [==========>...................] - ETA: 1:11:52 - loss: 6.0753 - accuracy: 0.1241\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 613/1615 [==========>...................] - ETA: 1:11:42 - loss: 6.0760 - accuracy: 0.1240\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 615/1615 [==========>...................] - ETA: 1:11:33 - loss: 6.0765 - accuracy: 0.1239\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 617/1615 [==========>...................] - ETA: 1:11:26 - loss: 6.0764 - accuracy: 0.1238\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 619/1615 [==========>...................] - ETA: 1:11:16 - loss: 6.0762 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 621/1615 [==========>...................] - ETA: 1:11:08 - loss: 6.0765 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 623/1615 [==========>...................] - ETA: 1:11:01 - loss: 6.0765 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 625/1615 [==========>...................] - ETA: 1:10:51 - loss: 6.0777 - accuracy: 0.1235\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 627/1615 [==========>...................] - ETA: 1:10:42 - loss: 6.0794 - accuracy: 0.1235\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 629/1615 [==========>...................] - ETA: 1:10:33 - loss: 6.0791 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 631/1615 [==========>...................] - ETA: 1:10:25 - loss: 6.0792 - accuracy: 0.1235\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 633/1615 [==========>...................] - ETA: 1:10:16 - loss: 6.0775 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 635/1615 [==========>...................] - ETA: 1:10:08 - loss: 6.0775 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 637/1615 [==========>...................] - ETA: 1:10:02 - loss: 6.0779 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 639/1615 [==========>...................] - ETA: 1:09:51 - loss: 6.0780 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 641/1615 [==========>...................] - ETA: 1:09:41 - loss: 6.0780 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 643/1615 [==========>...................] - ETA: 1:09:33 - loss: 6.0784 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 645/1615 [==========>...................] - ETA: 1:09:25 - loss: 6.0783 - accuracy: 0.1235\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 647/1615 [===========>..................] - ETA: 1:09:16 - loss: 6.0792 - accuracy: 0.1234\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 649/1615 [===========>..................] - ETA: 1:09:07 - loss: 6.0782 - accuracy: 0.1235\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 651/1615 [===========>..................] - ETA: 1:09:01 - loss: 6.0779 - accuracy: 0.1234\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 653/1615 [===========>..................] - ETA: 1:08:51 - loss: 6.0783 - accuracy: 0.1233\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 655/1615 [===========>..................] - ETA: 1:08:43 - loss: 6.0781 - accuracy: 0.1233\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 657/1615 [===========>..................] - ETA: 1:08:33 - loss: 6.0787 - accuracy: 0.1233\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 659/1615 [===========>..................] - ETA: 1:08:25 - loss: 6.0778 - accuracy: 0.1234\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 661/1615 [===========>..................] - ETA: 1:08:16 - loss: 6.0788 - accuracy: 0.1233\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 663/1615 [===========>..................] - ETA: 1:08:10 - loss: 6.0788 - accuracy: 0.1233\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 665/1615 [===========>..................] - ETA: 1:08:00 - loss: 6.0792 - accuracy: 0.1233\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 667/1615 [===========>..................] - ETA: 1:07:52 - loss: 6.0795 - accuracy: 0.1233\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 669/1615 [===========>..................] - ETA: 1:07:42 - loss: 6.0804 - accuracy: 0.1232\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 671/1615 [===========>..................] - ETA: 1:07:33 - loss: 6.0809 - accuracy: 0.1232\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 673/1615 [===========>..................] - ETA: 1:07:24 - loss: 6.0802 - accuracy: 0.1232\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 675/1615 [===========>..................] - ETA: 1:07:16 - loss: 6.0812 - accuracy: 0.1231\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 677/1615 [===========>..................] - ETA: 1:07:11 - loss: 6.0804 - accuracy: 0.1231\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 679/1615 [===========>..................] - ETA: 1:07:01 - loss: 6.0814 - accuracy: 0.1230\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 681/1615 [===========>..................] - ETA: 1:06:51 - loss: 6.0815 - accuracy: 0.1230\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 683/1615 [===========>..................] - ETA: 1:06:42 - loss: 6.0815 - accuracy: 0.1231\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 685/1615 [===========>..................] - ETA: 1:06:33 - loss: 6.0807 - accuracy: 0.1231\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 687/1615 [===========>..................] - ETA: 1:06:25 - loss: 6.0806 - accuracy: 0.1231\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 689/1615 [===========>..................] - ETA: 1:06:16 - loss: 6.0807 - accuracy: 0.1232\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 691/1615 [===========>..................] - ETA: 1:06:10 - loss: 6.0809 - accuracy: 0.1231\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 693/1615 [===========>..................] - ETA: 1:06:00 - loss: 6.0806 - accuracy: 0.1231\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 695/1615 [===========>..................] - ETA: 1:05:51 - loss: 6.0799 - accuracy: 0.1232\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 697/1615 [===========>..................] - ETA: 1:05:42 - loss: 6.0800 - accuracy: 0.1232\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 699/1615 [===========>..................] - ETA: 1:05:33 - loss: 6.0802 - accuracy: 0.1233\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 701/1615 [============>.................] - ETA: 1:05:27 - loss: 6.0802 - accuracy: 0.1233\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 703/1615 [============>.................] - ETA: 1:05:17 - loss: 6.0804 - accuracy: 0.1233\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 705/1615 [============>.................] - ETA: 1:05:09 - loss: 6.0800 - accuracy: 0.1234\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 707/1615 [============>.................] - ETA: 1:04:59 - loss: 6.0806 - accuracy: 0.1233\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 709/1615 [============>.................] - ETA: 1:04:50 - loss: 6.0801 - accuracy: 0.1233\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 711/1615 [============>.................] - ETA: 1:04:42 - loss: 6.0809 - accuracy: 0.1232\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 713/1615 [============>.................] - ETA: 1:04:34 - loss: 6.0817 - accuracy: 0.1232\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 715/1615 [============>.................] - ETA: 1:04:25 - loss: 6.0803 - accuracy: 0.1234\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 717/1615 [============>.................] - ETA: 1:04:16 - loss: 6.0796 - accuracy: 0.1234\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 719/1615 [============>.................] - ETA: 1:04:09 - loss: 6.0786 - accuracy: 0.1235\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 721/1615 [============>.................] - ETA: 1:04:00 - loss: 6.0774 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 723/1615 [============>.................] - ETA: 1:03:52 - loss: 6.0786 - accuracy: 0.1235\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 725/1615 [============>.................] - ETA: 1:03:43 - loss: 6.0772 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 727/1615 [============>.................] - ETA: 1:03:34 - loss: 6.0774 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 729/1615 [============>.................] - ETA: 1:03:26 - loss: 6.0776 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 731/1615 [============>.................] - ETA: 1:03:17 - loss: 6.0775 - accuracy: 0.1236\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 733/1615 [============>.................] - ETA: 1:03:09 - loss: 6.0774 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 735/1615 [============>.................] - ETA: 1:03:00 - loss: 6.0765 - accuracy: 0.1237\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 737/1615 [============>.................] - ETA: 1:02:53 - loss: 6.0765 - accuracy: 0.1238\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 739/1615 [============>.................] - ETA: 1:02:43 - loss: 6.0746 - accuracy: 0.1239\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 741/1615 [============>.................] - ETA: 1:02:34 - loss: 6.0749 - accuracy: 0.1239\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 743/1615 [============>.................] - ETA: 1:02:25 - loss: 6.0739 - accuracy: 0.1240\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 745/1615 [============>.................] - ETA: 1:02:16 - loss: 6.0733 - accuracy: 0.1240\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 747/1615 [============>.................] - ETA: 1:02:09 - loss: 6.0724 - accuracy: 0.1240\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 749/1615 [============>.................] - ETA: 1:02:00 - loss: 6.0717 - accuracy: 0.1240\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 751/1615 [============>.................] - ETA: 1:01:52 - loss: 6.0719 - accuracy: 0.1242\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 753/1615 [============>.................] - ETA: 1:01:43 - loss: 6.0712 - accuracy: 0.1243\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 755/1615 [=============>................] - ETA: 1:01:34 - loss: 6.0715 - accuracy: 0.1243\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 757/1615 [=============>................] - ETA: 1:01:26 - loss: 6.0716 - accuracy: 0.1244\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 759/1615 [=============>................] - ETA: 1:01:17 - loss: 6.0711 - accuracy: 0.1245\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 761/1615 [=============>................] - ETA: 1:01:08 - loss: 6.0702 - accuracy: 0.1245\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 763/1615 [=============>................] - ETA: 1:00:59 - loss: 6.0703 - accuracy: 0.1245\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 765/1615 [=============>................] - ETA: 1:00:52 - loss: 6.0696 - accuracy: 0.1245\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 767/1615 [=============>................] - ETA: 1:00:43 - loss: 6.0690 - accuracy: 0.1245\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 769/1615 [=============>................] - ETA: 1:00:33 - loss: 6.0691 - accuracy: 0.1245\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 771/1615 [=============>................] - ETA: 1:00:27 - loss: 6.0687 - accuracy: 0.1245\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 773/1615 [=============>................] - ETA: 1:00:17 - loss: 6.0680 - accuracy: 0.1246\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 775/1615 [=============>................] - ETA: 1:00:08 - loss: 6.0679 - accuracy: 0.1246\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 777/1615 [=============>................] - ETA: 59:59 - loss: 6.0681 - accuracy: 0.1247  \n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 779/1615 [=============>................] - ETA: 59:52 - loss: 6.0671 - accuracy: 0.1248\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 781/1615 [=============>................] - ETA: 59:42 - loss: 6.0670 - accuracy: 0.1249\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 783/1615 [=============>................] - ETA: 59:33 - loss: 6.0668 - accuracy: 0.1249\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 785/1615 [=============>................] - ETA: 59:25 - loss: 6.0660 - accuracy: 0.1251\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 787/1615 [=============>................] - ETA: 59:16 - loss: 6.0660 - accuracy: 0.1250\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 789/1615 [=============>................] - ETA: 59:08 - loss: 6.0667 - accuracy: 0.1250\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 791/1615 [=============>................] - ETA: 59:01 - loss: 6.0669 - accuracy: 0.1250\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 793/1615 [=============>................] - ETA: 58:51 - loss: 6.0678 - accuracy: 0.1250\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 795/1615 [=============>................] - ETA: 58:42 - loss: 6.0677 - accuracy: 0.1250\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 797/1615 [=============>................] - ETA: 58:33 - loss: 6.0688 - accuracy: 0.1249\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 799/1615 [=============>................] - ETA: 58:25 - loss: 6.0692 - accuracy: 0.1249\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 801/1615 [=============>................] - ETA: 58:16 - loss: 6.0695 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 803/1615 [=============>................] - ETA: 58:08 - loss: 6.0691 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 805/1615 [=============>................] - ETA: 57:59 - loss: 6.0689 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 807/1615 [=============>................] - ETA: 57:51 - loss: 6.0682 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 809/1615 [==============>...............] - ETA: 57:42 - loss: 6.0685 - accuracy: 0.1248\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 811/1615 [==============>...............] - ETA: 57:33 - loss: 6.0686 - accuracy: 0.1248\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 813/1615 [==============>...............] - ETA: 57:25 - loss: 6.0687 - accuracy: 0.1248\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 815/1615 [==============>...............] - ETA: 57:16 - loss: 6.0677 - accuracy: 0.1249\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 817/1615 [==============>...............] - ETA: 57:08 - loss: 6.0685 - accuracy: 0.1248\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 819/1615 [==============>...............] - ETA: 56:59 - loss: 6.0680 - accuracy: 0.1248\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 821/1615 [==============>...............] - ETA: 56:51 - loss: 6.0682 - accuracy: 0.1248\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 823/1615 [==============>...............] - ETA: 56:42 - loss: 6.0685 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 825/1615 [==============>...............] - ETA: 56:33 - loss: 6.0692 - accuracy: 0.1246\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 827/1615 [==============>...............] - ETA: 56:25 - loss: 6.0690 - accuracy: 0.1246\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 829/1615 [==============>...............] - ETA: 56:18 - loss: 6.0699 - accuracy: 0.1246\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 831/1615 [==============>...............] - ETA: 56:08 - loss: 6.0703 - accuracy: 0.1245\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 833/1615 [==============>...............] - ETA: 55:59 - loss: 6.0703 - accuracy: 0.1246\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 835/1615 [==============>...............] - ETA: 55:50 - loss: 6.0700 - accuracy: 0.1246\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 837/1615 [==============>...............] - ETA: 55:42 - loss: 6.0698 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 839/1615 [==============>...............] - ETA: 55:33 - loss: 6.0695 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 841/1615 [==============>...............] - ETA: 55:25 - loss: 6.0694 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 843/1615 [==============>...............] - ETA: 55:18 - loss: 6.0682 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 845/1615 [==============>...............] - ETA: 55:08 - loss: 6.0693 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 847/1615 [==============>...............] - ETA: 54:59 - loss: 6.0689 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 849/1615 [==============>...............] - ETA: 54:52 - loss: 6.0695 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 851/1615 [==============>...............] - ETA: 54:42 - loss: 6.0696 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 853/1615 [==============>...............] - ETA: 54:33 - loss: 6.0698 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 855/1615 [==============>...............] - ETA: 54:24 - loss: 6.0700 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 857/1615 [==============>...............] - ETA: 54:17 - loss: 6.0701 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 859/1615 [==============>...............] - ETA: 54:08 - loss: 6.0701 - accuracy: 0.1248\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 861/1615 [==============>...............] - ETA: 53:59 - loss: 6.0701 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 863/1615 [===============>..............] - ETA: 53:52 - loss: 6.0705 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 865/1615 [===============>..............] - ETA: 53:43 - loss: 6.0715 - accuracy: 0.1246\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 867/1615 [===============>..............] - ETA: 53:34 - loss: 6.0711 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 869/1615 [===============>..............] - ETA: 53:25 - loss: 6.0705 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 871/1615 [===============>..............] - ETA: 53:17 - loss: 6.0702 - accuracy: 0.1248\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 873/1615 [===============>..............] - ETA: 53:08 - loss: 6.0708 - accuracy: 0.1248\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 875/1615 [===============>..............] - ETA: 52:59 - loss: 6.0708 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 877/1615 [===============>..............] - ETA: 52:50 - loss: 6.0715 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 879/1615 [===============>..............] - ETA: 52:42 - loss: 6.0717 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 881/1615 [===============>..............] - ETA: 52:34 - loss: 6.0720 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 883/1615 [===============>..............] - ETA: 52:25 - loss: 6.0720 - accuracy: 0.1246\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 885/1615 [===============>..............] - ETA: 52:16 - loss: 6.0718 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 887/1615 [===============>..............] - ETA: 52:07 - loss: 6.0717 - accuracy: 0.1246\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 889/1615 [===============>..............] - ETA: 51:59 - loss: 6.0718 - accuracy: 0.1246\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 891/1615 [===============>..............] - ETA: 51:50 - loss: 6.0713 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 893/1615 [===============>..............] - ETA: 51:41 - loss: 6.0705 - accuracy: 0.1248\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 895/1615 [===============>..............] - ETA: 51:34 - loss: 6.0703 - accuracy: 0.1248\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 897/1615 [===============>..............] - ETA: 51:25 - loss: 6.0705 - accuracy: 0.1247\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 899/1615 [===============>..............] - ETA: 51:16 - loss: 6.0701 - accuracy: 0.1248\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 901/1615 [===============>..............] - ETA: 51:07 - loss: 6.0704 - accuracy: 0.1249\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 903/1615 [===============>..............] - ETA: 50:59 - loss: 6.0703 - accuracy: 0.1249\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 905/1615 [===============>..............] - ETA: 50:51 - loss: 6.0703 - accuracy: 0.1250\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 907/1615 [===============>..............] - ETA: 50:43 - loss: 6.0697 - accuracy: 0.1251\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 909/1615 [===============>..............] - ETA: 50:33 - loss: 6.0697 - accuracy: 0.1251\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 911/1615 [===============>..............] - ETA: 50:24 - loss: 6.0699 - accuracy: 0.1251\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 913/1615 [===============>..............] - ETA: 50:16 - loss: 6.0699 - accuracy: 0.1252\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 915/1615 [===============>..............] - ETA: 50:07 - loss: 6.0696 - accuracy: 0.1251\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 917/1615 [================>.............] - ETA: 49:58 - loss: 6.0699 - accuracy: 0.1251\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 919/1615 [================>.............] - ETA: 49:51 - loss: 6.0698 - accuracy: 0.1251\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 921/1615 [================>.............] - ETA: 49:42 - loss: 6.0705 - accuracy: 0.1250\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 923/1615 [================>.............] - ETA: 49:33 - loss: 6.0700 - accuracy: 0.1250\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 925/1615 [================>.............] - ETA: 49:24 - loss: 6.0702 - accuracy: 0.1250\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 927/1615 [================>.............] - ETA: 49:16 - loss: 6.0698 - accuracy: 0.1250\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 929/1615 [================>.............] - ETA: 49:07 - loss: 6.0706 - accuracy: 0.1250\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 931/1615 [================>.............] - ETA: 48:58 - loss: 6.0705 - accuracy: 0.1251\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 933/1615 [================>.............] - ETA: 48:50 - loss: 6.0714 - accuracy: 0.1250\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 935/1615 [================>.............] - ETA: 48:42 - loss: 6.0707 - accuracy: 0.1250\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 937/1615 [================>.............] - ETA: 48:33 - loss: 6.0705 - accuracy: 0.1251\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 939/1615 [================>.............] - ETA: 48:24 - loss: 6.0708 - accuracy: 0.1250\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 941/1615 [================>.............] - ETA: 48:15 - loss: 6.0710 - accuracy: 0.1249\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 943/1615 [================>.............] - ETA: 48:07 - loss: 6.0712 - accuracy: 0.1249\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 945/1615 [================>.............] - ETA: 47:58 - loss: 6.0699 - accuracy: 0.1250\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 947/1615 [================>.............] - ETA: 47:50 - loss: 6.0698 - accuracy: 0.1250\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 949/1615 [================>.............] - ETA: 47:42 - loss: 6.0696 - accuracy: 0.1250\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 951/1615 [================>.............] - ETA: 47:33 - loss: 6.0695 - accuracy: 0.1250\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 953/1615 [================>.............] - ETA: 47:24 - loss: 6.0689 - accuracy: 0.1251\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 955/1615 [================>.............] - ETA: 47:15 - loss: 6.0685 - accuracy: 0.1251\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 957/1615 [================>.............] - ETA: 47:07 - loss: 6.0692 - accuracy: 0.1252\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 959/1615 [================>.............] - ETA: 46:58 - loss: 6.0704 - accuracy: 0.1251\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 961/1615 [================>.............] - ETA: 46:50 - loss: 6.0703 - accuracy: 0.1251\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 963/1615 [================>.............] - ETA: 46:42 - loss: 6.0697 - accuracy: 0.1252\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 965/1615 [================>.............] - ETA: 46:33 - loss: 6.0692 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 967/1615 [================>.............] - ETA: 46:24 - loss: 6.0686 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 969/1615 [=================>............] - ETA: 46:15 - loss: 6.0689 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 971/1615 [=================>............] - ETA: 46:07 - loss: 6.0694 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 973/1615 [=================>............] - ETA: 45:58 - loss: 6.0694 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 975/1615 [=================>............] - ETA: 45:50 - loss: 6.0691 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 977/1615 [=================>............] - ETA: 45:41 - loss: 6.0689 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 979/1615 [=================>............] - ETA: 45:32 - loss: 6.0691 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 981/1615 [=================>............] - ETA: 45:24 - loss: 6.0694 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 983/1615 [=================>............] - ETA: 45:15 - loss: 6.0698 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 985/1615 [=================>............] - ETA: 45:07 - loss: 6.0701 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 987/1615 [=================>............] - ETA: 44:58 - loss: 6.0712 - accuracy: 0.1252\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 989/1615 [=================>............] - ETA: 44:49 - loss: 6.0711 - accuracy: 0.1252\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 991/1615 [=================>............] - ETA: 44:42 - loss: 6.0711 - accuracy: 0.1252\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 993/1615 [=================>............] - ETA: 44:33 - loss: 6.0713 - accuracy: 0.1252\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 995/1615 [=================>............] - ETA: 44:25 - loss: 6.0708 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 997/1615 [=================>............] - ETA: 44:15 - loss: 6.0722 - accuracy: 0.1252\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            " 999/1615 [=================>............] - ETA: 44:07 - loss: 6.0720 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1001/1615 [=================>............] - ETA: 43:58 - loss: 6.0727 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1003/1615 [=================>............] - ETA: 43:49 - loss: 6.0723 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1005/1615 [=================>............] - ETA: 43:41 - loss: 6.0721 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1007/1615 [=================>............] - ETA: 43:32 - loss: 6.0724 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1009/1615 [=================>............] - ETA: 43:23 - loss: 6.0721 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1011/1615 [=================>............] - ETA: 43:15 - loss: 6.0722 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1013/1615 [=================>............] - ETA: 43:06 - loss: 6.0726 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1015/1615 [=================>............] - ETA: 42:58 - loss: 6.0732 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1017/1615 [=================>............] - ETA: 42:49 - loss: 6.0731 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1019/1615 [=================>............] - ETA: 42:41 - loss: 6.0725 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1021/1615 [=================>............] - ETA: 42:33 - loss: 6.0723 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1023/1615 [==================>...........] - ETA: 42:24 - loss: 6.0722 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1025/1615 [==================>...........] - ETA: 42:15 - loss: 6.0725 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1027/1615 [==================>...........] - ETA: 42:06 - loss: 6.0730 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1029/1615 [==================>...........] - ETA: 41:58 - loss: 6.0733 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1031/1615 [==================>...........] - ETA: 41:49 - loss: 6.0732 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1033/1615 [==================>...........] - ETA: 41:41 - loss: 6.0729 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1035/1615 [==================>...........] - ETA: 41:33 - loss: 6.0728 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1037/1615 [==================>...........] - ETA: 41:24 - loss: 6.0728 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1039/1615 [==================>...........] - ETA: 41:15 - loss: 6.0735 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1041/1615 [==================>...........] - ETA: 41:06 - loss: 6.0730 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1043/1615 [==================>...........] - ETA: 40:58 - loss: 6.0729 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1045/1615 [==================>...........] - ETA: 40:49 - loss: 6.0731 - accuracy: 0.1255\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1047/1615 [==================>...........] - ETA: 40:40 - loss: 6.0728 - accuracy: 0.1255\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1049/1615 [==================>...........] - ETA: 40:33 - loss: 6.0728 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1051/1615 [==================>...........] - ETA: 40:23 - loss: 6.0733 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1053/1615 [==================>...........] - ETA: 40:15 - loss: 6.0734 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1055/1615 [==================>...........] - ETA: 40:06 - loss: 6.0734 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1057/1615 [==================>...........] - ETA: 39:57 - loss: 6.0732 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1059/1615 [==================>...........] - ETA: 39:49 - loss: 6.0727 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1061/1615 [==================>...........] - ETA: 39:40 - loss: 6.0724 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1063/1615 [==================>...........] - ETA: 39:32 - loss: 6.0715 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1065/1615 [==================>...........] - ETA: 39:23 - loss: 6.0713 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1067/1615 [==================>...........] - ETA: 39:14 - loss: 6.0716 - accuracy: 0.1253\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1069/1615 [==================>...........] - ETA: 39:06 - loss: 6.0715 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1071/1615 [==================>...........] - ETA: 38:57 - loss: 6.0715 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1073/1615 [==================>...........] - ETA: 38:49 - loss: 6.0717 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1075/1615 [==================>...........] - ETA: 38:40 - loss: 6.0717 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1077/1615 [===================>..........] - ETA: 38:31 - loss: 6.0715 - accuracy: 0.1255\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1079/1615 [===================>..........] - ETA: 38:23 - loss: 6.0717 - accuracy: 0.1254\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1081/1615 [===================>..........] - ETA: 38:14 - loss: 6.0714 - accuracy: 0.1255\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1083/1615 [===================>..........] - ETA: 38:06 - loss: 6.0707 - accuracy: 0.1256\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1085/1615 [===================>..........] - ETA: 37:57 - loss: 6.0708 - accuracy: 0.1255\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1087/1615 [===================>..........] - ETA: 37:48 - loss: 6.0708 - accuracy: 0.1255\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1089/1615 [===================>..........] - ETA: 37:40 - loss: 6.0703 - accuracy: 0.1255\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1091/1615 [===================>..........] - ETA: 37:31 - loss: 6.0697 - accuracy: 0.1256\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1093/1615 [===================>..........] - ETA: 37:23 - loss: 6.0694 - accuracy: 0.1257\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1095/1615 [===================>..........] - ETA: 37:14 - loss: 6.0696 - accuracy: 0.1257\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1097/1615 [===================>..........] - ETA: 37:05 - loss: 6.0694 - accuracy: 0.1257\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1099/1615 [===================>..........] - ETA: 36:57 - loss: 6.0695 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1101/1615 [===================>..........] - ETA: 36:48 - loss: 6.0700 - accuracy: 0.1257\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1103/1615 [===================>..........] - ETA: 36:40 - loss: 6.0697 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1105/1615 [===================>..........] - ETA: 36:31 - loss: 6.0699 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1107/1615 [===================>..........] - ETA: 36:22 - loss: 6.0694 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1109/1615 [===================>..........] - ETA: 36:14 - loss: 6.0696 - accuracy: 0.1257\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1111/1615 [===================>..........] - ETA: 36:05 - loss: 6.0692 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1113/1615 [===================>..........] - ETA: 35:57 - loss: 6.0689 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1115/1615 [===================>..........] - ETA: 35:48 - loss: 6.0690 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1117/1615 [===================>..........] - ETA: 35:40 - loss: 6.0696 - accuracy: 0.1257\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1119/1615 [===================>..........] - ETA: 35:32 - loss: 6.0696 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1121/1615 [===================>..........] - ETA: 35:23 - loss: 6.0695 - accuracy: 0.1257\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1123/1615 [===================>..........] - ETA: 35:14 - loss: 6.0697 - accuracy: 0.1257\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1125/1615 [===================>..........] - ETA: 35:05 - loss: 6.0695 - accuracy: 0.1257\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1127/1615 [===================>..........] - ETA: 34:57 - loss: 6.0696 - accuracy: 0.1257\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1129/1615 [===================>..........] - ETA: 34:48 - loss: 6.0693 - accuracy: 0.1257\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1131/1615 [====================>.........] - ETA: 34:39 - loss: 6.0693 - accuracy: 0.1256\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1133/1615 [====================>.........] - ETA: 34:31 - loss: 6.0691 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1135/1615 [====================>.........] - ETA: 34:22 - loss: 6.0693 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1137/1615 [====================>.........] - ETA: 34:14 - loss: 6.0692 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1139/1615 [====================>.........] - ETA: 34:06 - loss: 6.0692 - accuracy: 0.1257\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1141/1615 [====================>.........] - ETA: 33:57 - loss: 6.0690 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1143/1615 [====================>.........] - ETA: 33:48 - loss: 6.0686 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1145/1615 [====================>.........] - ETA: 33:39 - loss: 6.0690 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1147/1615 [====================>.........] - ETA: 33:31 - loss: 6.0698 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1149/1615 [====================>.........] - ETA: 33:22 - loss: 6.0702 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1151/1615 [====================>.........] - ETA: 33:14 - loss: 6.0700 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1153/1615 [====================>.........] - ETA: 33:05 - loss: 6.0701 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1155/1615 [====================>.........] - ETA: 32:56 - loss: 6.0698 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1157/1615 [====================>.........] - ETA: 32:48 - loss: 6.0703 - accuracy: 0.1257\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1159/1615 [====================>.........] - ETA: 32:39 - loss: 6.0700 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1161/1615 [====================>.........] - ETA: 32:31 - loss: 6.0702 - accuracy: 0.1257\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1163/1615 [====================>.........] - ETA: 32:22 - loss: 6.0702 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1165/1615 [====================>.........] - ETA: 32:13 - loss: 6.0696 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1167/1615 [====================>.........] - ETA: 32:05 - loss: 6.0697 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1169/1615 [====================>.........] - ETA: 31:56 - loss: 6.0703 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1171/1615 [====================>.........] - ETA: 31:48 - loss: 6.0707 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1173/1615 [====================>.........] - ETA: 31:39 - loss: 6.0713 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1175/1615 [====================>.........] - ETA: 31:30 - loss: 6.0714 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1177/1615 [====================>.........] - ETA: 31:22 - loss: 6.0711 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1179/1615 [====================>.........] - ETA: 31:13 - loss: 6.0708 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1181/1615 [====================>.........] - ETA: 31:05 - loss: 6.0708 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1183/1615 [====================>.........] - ETA: 30:56 - loss: 6.0716 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1185/1615 [=====================>........] - ETA: 30:47 - loss: 6.0717 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1187/1615 [=====================>........] - ETA: 30:39 - loss: 6.0717 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1189/1615 [=====================>........] - ETA: 30:30 - loss: 6.0722 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1191/1615 [=====================>........] - ETA: 30:22 - loss: 6.0719 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1193/1615 [=====================>........] - ETA: 30:13 - loss: 6.0720 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1195/1615 [=====================>........] - ETA: 30:05 - loss: 6.0720 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1197/1615 [=====================>........] - ETA: 29:56 - loss: 6.0718 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1199/1615 [=====================>........] - ETA: 29:47 - loss: 6.0715 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1201/1615 [=====================>........] - ETA: 29:39 - loss: 6.0713 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1203/1615 [=====================>........] - ETA: 29:30 - loss: 6.0715 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1205/1615 [=====================>........] - ETA: 29:21 - loss: 6.0711 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1207/1615 [=====================>........] - ETA: 29:13 - loss: 6.0713 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1209/1615 [=====================>........] - ETA: 29:04 - loss: 6.0717 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1211/1615 [=====================>........] - ETA: 28:56 - loss: 6.0715 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1213/1615 [=====================>........] - ETA: 28:47 - loss: 6.0716 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1215/1615 [=====================>........] - ETA: 28:38 - loss: 6.0719 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1217/1615 [=====================>........] - ETA: 28:30 - loss: 6.0712 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1219/1615 [=====================>........] - ETA: 28:21 - loss: 6.0712 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1221/1615 [=====================>........] - ETA: 28:13 - loss: 6.0710 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1223/1615 [=====================>........] - ETA: 28:04 - loss: 6.0704 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1225/1615 [=====================>........] - ETA: 27:56 - loss: 6.0700 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1227/1615 [=====================>........] - ETA: 27:47 - loss: 6.0700 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1229/1615 [=====================>........] - ETA: 27:38 - loss: 6.0698 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1231/1615 [=====================>........] - ETA: 27:30 - loss: 6.0699 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1233/1615 [=====================>........] - ETA: 27:21 - loss: 6.0703 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1235/1615 [=====================>........] - ETA: 27:13 - loss: 6.0706 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1237/1615 [=====================>........] - ETA: 27:04 - loss: 6.0705 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1239/1615 [======================>.......] - ETA: 26:55 - loss: 6.0702 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1241/1615 [======================>.......] - ETA: 26:47 - loss: 6.0708 - accuracy: 0.1257\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1243/1615 [======================>.......] - ETA: 26:38 - loss: 6.0709 - accuracy: 0.1257\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1245/1615 [======================>.......] - ETA: 26:30 - loss: 6.0707 - accuracy: 0.1257\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1247/1615 [======================>.......] - ETA: 26:21 - loss: 6.0703 - accuracy: 0.1257\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1249/1615 [======================>.......] - ETA: 26:13 - loss: 6.0699 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1251/1615 [======================>.......] - ETA: 26:04 - loss: 6.0699 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1253/1615 [======================>.......] - ETA: 25:55 - loss: 6.0696 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1255/1615 [======================>.......] - ETA: 25:47 - loss: 6.0692 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1257/1615 [======================>.......] - ETA: 25:38 - loss: 6.0684 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1259/1615 [======================>.......] - ETA: 25:29 - loss: 6.0684 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1261/1615 [======================>.......] - ETA: 25:21 - loss: 6.0688 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1263/1615 [======================>.......] - ETA: 25:13 - loss: 6.0687 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1265/1615 [======================>.......] - ETA: 25:04 - loss: 6.0687 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1267/1615 [======================>.......] - ETA: 24:55 - loss: 6.0687 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1269/1615 [======================>.......] - ETA: 24:46 - loss: 6.0685 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1271/1615 [======================>.......] - ETA: 24:38 - loss: 6.0683 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1273/1615 [======================>.......] - ETA: 24:29 - loss: 6.0684 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1275/1615 [======================>.......] - ETA: 24:21 - loss: 6.0679 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1277/1615 [======================>.......] - ETA: 24:12 - loss: 6.0678 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1279/1615 [======================>.......] - ETA: 24:04 - loss: 6.0672 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1281/1615 [======================>.......] - ETA: 23:55 - loss: 6.0671 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1283/1615 [======================>.......] - ETA: 23:46 - loss: 6.0674 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1285/1615 [======================>.......] - ETA: 23:38 - loss: 6.0675 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1287/1615 [======================>.......] - ETA: 23:29 - loss: 6.0675 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1289/1615 [======================>.......] - ETA: 23:21 - loss: 6.0676 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1291/1615 [======================>.......] - ETA: 23:12 - loss: 6.0677 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1293/1615 [=======================>......] - ETA: 23:03 - loss: 6.0670 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1295/1615 [=======================>......] - ETA: 22:55 - loss: 6.0671 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1297/1615 [=======================>......] - ETA: 22:46 - loss: 6.0672 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1299/1615 [=======================>......] - ETA: 22:38 - loss: 6.0674 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1301/1615 [=======================>......] - ETA: 22:29 - loss: 6.0674 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1303/1615 [=======================>......] - ETA: 22:20 - loss: 6.0669 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1305/1615 [=======================>......] - ETA: 22:12 - loss: 6.0670 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1307/1615 [=======================>......] - ETA: 22:03 - loss: 6.0672 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1309/1615 [=======================>......] - ETA: 21:55 - loss: 6.0669 - accuracy: 0.1264\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1311/1615 [=======================>......] - ETA: 21:46 - loss: 6.0666 - accuracy: 0.1264\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1313/1615 [=======================>......] - ETA: 21:37 - loss: 6.0672 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1315/1615 [=======================>......] - ETA: 21:29 - loss: 6.0671 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1317/1615 [=======================>......] - ETA: 21:20 - loss: 6.0666 - accuracy: 0.1264\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1319/1615 [=======================>......] - ETA: 21:12 - loss: 6.0667 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1321/1615 [=======================>......] - ETA: 21:03 - loss: 6.0669 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1323/1615 [=======================>......] - ETA: 20:54 - loss: 6.0670 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1325/1615 [=======================>......] - ETA: 20:46 - loss: 6.0674 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1327/1615 [=======================>......] - ETA: 20:37 - loss: 6.0670 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1329/1615 [=======================>......] - ETA: 20:28 - loss: 6.0673 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1331/1615 [=======================>......] - ETA: 20:20 - loss: 6.0677 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1333/1615 [=======================>......] - ETA: 20:11 - loss: 6.0681 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1335/1615 [=======================>......] - ETA: 20:03 - loss: 6.0676 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1337/1615 [=======================>......] - ETA: 19:54 - loss: 6.0672 - accuracy: 0.1264\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1339/1615 [=======================>......] - ETA: 19:46 - loss: 6.0673 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1341/1615 [=======================>......] - ETA: 19:37 - loss: 6.0675 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1343/1615 [=======================>......] - ETA: 19:28 - loss: 6.0674 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1345/1615 [=======================>......] - ETA: 19:20 - loss: 6.0674 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1347/1615 [========================>.....] - ETA: 19:11 - loss: 6.0669 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1349/1615 [========================>.....] - ETA: 19:03 - loss: 6.0670 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1351/1615 [========================>.....] - ETA: 18:54 - loss: 6.0668 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1353/1615 [========================>.....] - ETA: 18:46 - loss: 6.0661 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1355/1615 [========================>.....] - ETA: 18:37 - loss: 6.0659 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1357/1615 [========================>.....] - ETA: 18:28 - loss: 6.0660 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1359/1615 [========================>.....] - ETA: 18:20 - loss: 6.0656 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1361/1615 [========================>.....] - ETA: 18:11 - loss: 6.0654 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1363/1615 [========================>.....] - ETA: 18:02 - loss: 6.0656 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1365/1615 [========================>.....] - ETA: 17:54 - loss: 6.0653 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1367/1615 [========================>.....] - ETA: 17:45 - loss: 6.0653 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1369/1615 [========================>.....] - ETA: 17:37 - loss: 6.0651 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1371/1615 [========================>.....] - ETA: 17:28 - loss: 6.0648 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1373/1615 [========================>.....] - ETA: 17:19 - loss: 6.0655 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1375/1615 [========================>.....] - ETA: 17:11 - loss: 6.0654 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1377/1615 [========================>.....] - ETA: 17:02 - loss: 6.0652 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1379/1615 [========================>.....] - ETA: 16:54 - loss: 6.0642 - accuracy: 0.1264\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1381/1615 [========================>.....] - ETA: 16:45 - loss: 6.0642 - accuracy: 0.1264\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1383/1615 [========================>.....] - ETA: 16:36 - loss: 6.0644 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1385/1615 [========================>.....] - ETA: 16:28 - loss: 6.0644 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1387/1615 [========================>.....] - ETA: 16:19 - loss: 6.0644 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1389/1615 [========================>.....] - ETA: 16:11 - loss: 6.0647 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1391/1615 [========================>.....] - ETA: 16:02 - loss: 6.0642 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1393/1615 [========================>.....] - ETA: 15:54 - loss: 6.0641 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1395/1615 [========================>.....] - ETA: 15:45 - loss: 6.0635 - accuracy: 0.1264\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1397/1615 [========================>.....] - ETA: 15:36 - loss: 6.0635 - accuracy: 0.1264\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1399/1615 [========================>.....] - ETA: 15:28 - loss: 6.0634 - accuracy: 0.1264\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1401/1615 [=========================>....] - ETA: 15:19 - loss: 6.0631 - accuracy: 0.1264\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1403/1615 [=========================>....] - ETA: 15:11 - loss: 6.0634 - accuracy: 0.1264\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1405/1615 [=========================>....] - ETA: 15:02 - loss: 6.0638 - accuracy: 0.1264\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1407/1615 [=========================>....] - ETA: 14:53 - loss: 6.0638 - accuracy: 0.1264\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1409/1615 [=========================>....] - ETA: 14:45 - loss: 6.0638 - accuracy: 0.1264\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1411/1615 [=========================>....] - ETA: 14:36 - loss: 6.0635 - accuracy: 0.1264\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1413/1615 [=========================>....] - ETA: 14:27 - loss: 6.0634 - accuracy: 0.1265\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1415/1615 [=========================>....] - ETA: 14:19 - loss: 6.0636 - accuracy: 0.1264\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1417/1615 [=========================>....] - ETA: 14:10 - loss: 6.0637 - accuracy: 0.1264\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1419/1615 [=========================>....] - ETA: 14:02 - loss: 6.0638 - accuracy: 0.1264\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1421/1615 [=========================>....] - ETA: 13:53 - loss: 6.0636 - accuracy: 0.1264\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1423/1615 [=========================>....] - ETA: 13:44 - loss: 6.0638 - accuracy: 0.1264\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1425/1615 [=========================>....] - ETA: 13:36 - loss: 6.0642 - accuracy: 0.1264\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1427/1615 [=========================>....] - ETA: 13:27 - loss: 6.0643 - accuracy: 0.1264\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1429/1615 [=========================>....] - ETA: 13:19 - loss: 6.0645 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1431/1615 [=========================>....] - ETA: 13:10 - loss: 6.0646 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1433/1615 [=========================>....] - ETA: 13:02 - loss: 6.0647 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1435/1615 [=========================>....] - ETA: 12:53 - loss: 6.0646 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1437/1615 [=========================>....] - ETA: 12:44 - loss: 6.0646 - accuracy: 0.1263\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1439/1615 [=========================>....] - ETA: 12:36 - loss: 6.0650 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1441/1615 [=========================>....] - ETA: 12:27 - loss: 6.0653 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1443/1615 [=========================>....] - ETA: 12:19 - loss: 6.0654 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1445/1615 [=========================>....] - ETA: 12:10 - loss: 6.0654 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1447/1615 [=========================>....] - ETA: 12:01 - loss: 6.0657 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1449/1615 [=========================>....] - ETA: 11:53 - loss: 6.0660 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1451/1615 [=========================>....] - ETA: 11:44 - loss: 6.0658 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1453/1615 [=========================>....] - ETA: 11:36 - loss: 6.0661 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1455/1615 [==========================>...] - ETA: 11:27 - loss: 6.0666 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1457/1615 [==========================>...] - ETA: 11:18 - loss: 6.0670 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1459/1615 [==========================>...] - ETA: 11:10 - loss: 6.0671 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1461/1615 [==========================>...] - ETA: 11:01 - loss: 6.0671 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1463/1615 [==========================>...] - ETA: 10:53 - loss: 6.0670 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1465/1615 [==========================>...] - ETA: 10:44 - loss: 6.0674 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1467/1615 [==========================>...] - ETA: 10:35 - loss: 6.0671 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1469/1615 [==========================>...] - ETA: 10:27 - loss: 6.0670 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1471/1615 [==========================>...] - ETA: 10:18 - loss: 6.0668 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1473/1615 [==========================>...] - ETA: 10:10 - loss: 6.0669 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1475/1615 [==========================>...] - ETA: 10:01 - loss: 6.0666 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1477/1615 [==========================>...] - ETA: 9:53 - loss: 6.0664 - accuracy: 0.1262\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1479/1615 [==========================>...] - ETA: 9:44 - loss: 6.0665 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1481/1615 [==========================>...] - ETA: 9:35 - loss: 6.0666 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1483/1615 [==========================>...] - ETA: 9:27 - loss: 6.0666 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1485/1615 [==========================>...] - ETA: 9:18 - loss: 6.0663 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1487/1615 [==========================>...] - ETA: 9:10 - loss: 6.0663 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1489/1615 [==========================>...] - ETA: 9:01 - loss: 6.0664 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1491/1615 [==========================>...] - ETA: 8:52 - loss: 6.0668 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1493/1615 [==========================>...] - ETA: 8:44 - loss: 6.0675 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1495/1615 [==========================>...] - ETA: 8:35 - loss: 6.0672 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1497/1615 [==========================>...] - ETA: 8:27 - loss: 6.0670 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1499/1615 [==========================>...] - ETA: 8:18 - loss: 6.0674 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1501/1615 [==========================>...] - ETA: 8:09 - loss: 6.0676 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1503/1615 [==========================>...] - ETA: 8:01 - loss: 6.0677 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1505/1615 [==========================>...] - ETA: 7:52 - loss: 6.0672 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1507/1615 [==========================>...] - ETA: 7:44 - loss: 6.0671 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1509/1615 [===========================>..] - ETA: 7:35 - loss: 6.0671 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1511/1615 [===========================>..] - ETA: 7:26 - loss: 6.0668 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1513/1615 [===========================>..] - ETA: 7:18 - loss: 6.0663 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1515/1615 [===========================>..] - ETA: 7:09 - loss: 6.0662 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1517/1615 [===========================>..] - ETA: 7:01 - loss: 6.0661 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1519/1615 [===========================>..] - ETA: 6:52 - loss: 6.0664 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1521/1615 [===========================>..] - ETA: 6:43 - loss: 6.0661 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1523/1615 [===========================>..] - ETA: 6:35 - loss: 6.0661 - accuracy: 0.1261\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1525/1615 [===========================>..] - ETA: 6:26 - loss: 6.0665 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1527/1615 [===========================>..] - ETA: 6:18 - loss: 6.0662 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1529/1615 [===========================>..] - ETA: 6:09 - loss: 6.0666 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1531/1615 [===========================>..] - ETA: 6:00 - loss: 6.0663 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1533/1615 [===========================>..] - ETA: 5:52 - loss: 6.0665 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1535/1615 [===========================>..] - ETA: 5:43 - loss: 6.0659 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1537/1615 [===========================>..] - ETA: 5:35 - loss: 6.0660 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1539/1615 [===========================>..] - ETA: 5:26 - loss: 6.0663 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1541/1615 [===========================>..] - ETA: 5:17 - loss: 6.0658 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1543/1615 [===========================>..] - ETA: 5:09 - loss: 6.0661 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1545/1615 [===========================>..] - ETA: 5:00 - loss: 6.0663 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1547/1615 [===========================>..] - ETA: 4:52 - loss: 6.0665 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1549/1615 [===========================>..] - ETA: 4:43 - loss: 6.0666 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1551/1615 [===========================>..] - ETA: 4:34 - loss: 6.0668 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1553/1615 [===========================>..] - ETA: 4:26 - loss: 6.0666 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1555/1615 [===========================>..] - ETA: 4:17 - loss: 6.0665 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1557/1615 [===========================>..] - ETA: 4:09 - loss: 6.0668 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1559/1615 [===========================>..] - ETA: 4:00 - loss: 6.0668 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1561/1615 [===========================>..] - ETA: 3:52 - loss: 6.0670 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1563/1615 [============================>.] - ETA: 3:43 - loss: 6.0666 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1565/1615 [============================>.] - ETA: 3:34 - loss: 6.0666 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1567/1615 [============================>.] - ETA: 3:26 - loss: 6.0664 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1569/1615 [============================>.] - ETA: 3:17 - loss: 6.0664 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1571/1615 [============================>.] - ETA: 3:09 - loss: 6.0662 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1573/1615 [============================>.] - ETA: 3:00 - loss: 6.0661 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1575/1615 [============================>.] - ETA: 2:51 - loss: 6.0661 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1577/1615 [============================>.] - ETA: 2:43 - loss: 6.0656 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1579/1615 [============================>.] - ETA: 2:34 - loss: 6.0660 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1581/1615 [============================>.] - ETA: 2:26 - loss: 6.0662 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1583/1615 [============================>.] - ETA: 2:17 - loss: 6.0664 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1585/1615 [============================>.] - ETA: 2:08 - loss: 6.0661 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1587/1615 [============================>.] - ETA: 2:00 - loss: 6.0663 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1589/1615 [============================>.] - ETA: 1:51 - loss: 6.0664 - accuracy: 0.1258\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1591/1615 [============================>.] - ETA: 1:43 - loss: 6.0664 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1593/1615 [============================>.] - ETA: 1:34 - loss: 6.0662 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1595/1615 [============================>.] - ETA: 1:25 - loss: 6.0662 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1597/1615 [============================>.] - ETA: 1:17 - loss: 6.0660 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1599/1615 [============================>.] - ETA: 1:08 - loss: 6.0659 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1601/1615 [============================>.] - ETA: 1:00 - loss: 6.0658 - accuracy: 0.1259\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1603/1615 [============================>.] - ETA: 51s - loss: 6.0659 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1605/1615 [============================>.] - ETA: 42s - loss: 6.0659 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1607/1615 [============================>.] - ETA: 34s - loss: 6.0659 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1609/1615 [============================>.] - ETA: 25s - loss: 6.0658 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1611/1615 [============================>.] - ETA: 17s - loss: 6.0657 - accuracy: 0.1260\n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1613/1615 [============================>.] - ETA: 8s - loss: 6.0659 - accuracy: 0.1260 \n",
            "Epoch 5: saving model to ./train_ckpt/cp.ckpt\n",
            "1615/1615 [==============================] - 6943s 4s/step - loss: 6.0657 - accuracy: 0.1260 - val_loss: 7.4972 - val_accuracy: 0.1170\n",
            "Epoch 6/10\n",
            "\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "   2/1615 [..............................] - ETA: 55:04 - loss: 5.8791 - accuracy: 0.1400  \n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "   4/1615 [..............................] - ETA: 1:24:21 - loss: 5.8893 - accuracy: 0.1350\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "   6/1615 [..............................] - ETA: 1:32:14 - loss: 5.8854 - accuracy: 0.1283\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "   8/1615 [..............................] - ETA: 1:34:23 - loss: 5.8976 - accuracy: 0.1250\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  10/1615 [..............................] - ETA: 1:34:49 - loss: 5.9045 - accuracy: 0.1350\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  12/1615 [..............................] - ETA: 1:36:59 - loss: 5.9666 - accuracy: 0.1300\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  14/1615 [..............................] - ETA: 1:39:06 - loss: 5.9650 - accuracy: 0.1343\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  16/1615 [..............................] - ETA: 1:44:35 - loss: 5.9905 - accuracy: 0.1338\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  18/1615 [..............................] - ETA: 1:45:14 - loss: 5.9972 - accuracy: 0.1339\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  20/1615 [..............................] - ETA: 1:45:36 - loss: 5.9881 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  22/1615 [..............................] - ETA: 1:45:17 - loss: 6.0074 - accuracy: 0.1282\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  24/1615 [..............................] - ETA: 1:45:15 - loss: 6.0144 - accuracy: 0.1275\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  26/1615 [..............................] - ETA: 1:45:49 - loss: 6.0208 - accuracy: 0.1273\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  28/1615 [..............................] - ETA: 1:47:44 - loss: 6.0383 - accuracy: 0.1250\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  30/1615 [..............................] - ETA: 1:47:09 - loss: 6.0589 - accuracy: 0.1250\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  32/1615 [..............................] - ETA: 1:46:59 - loss: 6.0393 - accuracy: 0.1259\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  34/1615 [..............................] - ETA: 1:48:56 - loss: 6.0376 - accuracy: 0.1229\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  36/1615 [..............................] - ETA: 1:48:05 - loss: 6.0465 - accuracy: 0.1228\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  38/1615 [..............................] - ETA: 1:47:40 - loss: 6.0434 - accuracy: 0.1232\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  40/1615 [..............................] - ETA: 1:47:42 - loss: 6.0522 - accuracy: 0.1227\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  42/1615 [..............................] - ETA: 1:47:46 - loss: 6.0634 - accuracy: 0.1221\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  44/1615 [..............................] - ETA: 1:48:49 - loss: 6.0691 - accuracy: 0.1193\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  46/1615 [..............................] - ETA: 1:48:04 - loss: 6.0727 - accuracy: 0.1187\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  48/1615 [..............................] - ETA: 1:49:12 - loss: 6.0624 - accuracy: 0.1196\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  50/1615 [..............................] - ETA: 1:48:35 - loss: 6.0648 - accuracy: 0.1196\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  52/1615 [..............................] - ETA: 1:48:04 - loss: 6.0594 - accuracy: 0.1196\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  54/1615 [>.............................] - ETA: 1:48:06 - loss: 6.0558 - accuracy: 0.1202\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  56/1615 [>.............................] - ETA: 1:48:03 - loss: 6.0586 - accuracy: 0.1213\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  58/1615 [>.............................] - ETA: 1:48:04 - loss: 6.0476 - accuracy: 0.1212\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  60/1615 [>.............................] - ETA: 1:48:00 - loss: 6.0376 - accuracy: 0.1217\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  62/1615 [>.............................] - ETA: 1:48:47 - loss: 6.0357 - accuracy: 0.1215\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  64/1615 [>.............................] - ETA: 1:48:10 - loss: 6.0328 - accuracy: 0.1209\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  66/1615 [>.............................] - ETA: 1:47:55 - loss: 6.0382 - accuracy: 0.1206\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  68/1615 [>.............................] - ETA: 1:47:50 - loss: 6.0352 - accuracy: 0.1204\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  70/1615 [>.............................] - ETA: 1:47:45 - loss: 6.0207 - accuracy: 0.1219\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  72/1615 [>.............................] - ETA: 1:47:40 - loss: 6.0128 - accuracy: 0.1217\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  74/1615 [>.............................] - ETA: 1:48:23 - loss: 6.0115 - accuracy: 0.1226\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  76/1615 [>.............................] - ETA: 1:47:46 - loss: 6.0035 - accuracy: 0.1228\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  78/1615 [>.............................] - ETA: 1:47:31 - loss: 6.0058 - accuracy: 0.1228\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  80/1615 [>.............................] - ETA: 1:47:27 - loss: 5.9997 - accuracy: 0.1222\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  82/1615 [>.............................] - ETA: 1:47:19 - loss: 5.9933 - accuracy: 0.1229\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  84/1615 [>.............................] - ETA: 1:47:15 - loss: 5.9951 - accuracy: 0.1227\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  86/1615 [>.............................] - ETA: 1:47:15 - loss: 5.9984 - accuracy: 0.1227\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  88/1615 [>.............................] - ETA: 1:47:42 - loss: 5.9978 - accuracy: 0.1226\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  90/1615 [>.............................] - ETA: 1:47:12 - loss: 5.9985 - accuracy: 0.1221\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  92/1615 [>.............................] - ETA: 1:46:58 - loss: 6.0081 - accuracy: 0.1209\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  94/1615 [>.............................] - ETA: 1:46:51 - loss: 6.0050 - accuracy: 0.1211\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  96/1615 [>.............................] - ETA: 1:46:46 - loss: 6.0069 - accuracy: 0.1213\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "  98/1615 [>.............................] - ETA: 1:46:37 - loss: 6.0068 - accuracy: 0.1216\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 100/1615 [>.............................] - ETA: 1:46:29 - loss: 6.0055 - accuracy: 0.1219\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 102/1615 [>.............................] - ETA: 1:46:51 - loss: 6.0052 - accuracy: 0.1222\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 104/1615 [>.............................] - ETA: 1:46:22 - loss: 6.0036 - accuracy: 0.1224\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 106/1615 [>.............................] - ETA: 1:46:14 - loss: 6.0065 - accuracy: 0.1226\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 108/1615 [=>............................] - ETA: 1:46:24 - loss: 6.0077 - accuracy: 0.1224\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 110/1615 [=>............................] - ETA: 1:45:59 - loss: 6.0143 - accuracy: 0.1223\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 112/1615 [=>............................] - ETA: 1:45:52 - loss: 6.0138 - accuracy: 0.1224\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 114/1615 [=>............................] - ETA: 1:45:57 - loss: 6.0144 - accuracy: 0.1223\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 116/1615 [=>............................] - ETA: 1:45:59 - loss: 6.0178 - accuracy: 0.1228\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 118/1615 [=>............................] - ETA: 1:45:35 - loss: 6.0191 - accuracy: 0.1223\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 120/1615 [=>............................] - ETA: 1:45:23 - loss: 6.0200 - accuracy: 0.1219\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 122/1615 [=>............................] - ETA: 1:45:17 - loss: 6.0215 - accuracy: 0.1219\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 124/1615 [=>............................] - ETA: 1:45:17 - loss: 6.0217 - accuracy: 0.1220\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 126/1615 [=>............................] - ETA: 1:45:03 - loss: 6.0214 - accuracy: 0.1219\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 128/1615 [=>............................] - ETA: 1:45:07 - loss: 6.0269 - accuracy: 0.1216\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 130/1615 [=>............................] - ETA: 1:45:11 - loss: 6.0249 - accuracy: 0.1221\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 132/1615 [=>............................] - ETA: 1:44:47 - loss: 6.0265 - accuracy: 0.1219\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 134/1615 [=>............................] - ETA: 1:44:36 - loss: 6.0261 - accuracy: 0.1220\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 136/1615 [=>............................] - ETA: 1:44:28 - loss: 6.0222 - accuracy: 0.1224\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 138/1615 [=>............................] - ETA: 1:44:24 - loss: 6.0195 - accuracy: 0.1223\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 140/1615 [=>............................] - ETA: 1:44:15 - loss: 6.0124 - accuracy: 0.1229\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 142/1615 [=>............................] - ETA: 1:44:14 - loss: 6.0111 - accuracy: 0.1229\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 144/1615 [=>............................] - ETA: 1:44:10 - loss: 6.0027 - accuracy: 0.1234\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 146/1615 [=>............................] - ETA: 1:43:50 - loss: 5.9982 - accuracy: 0.1238\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 148/1615 [=>............................] - ETA: 1:43:42 - loss: 5.9944 - accuracy: 0.1246\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 150/1615 [=>............................] - ETA: 1:43:36 - loss: 5.9922 - accuracy: 0.1250\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 152/1615 [=>............................] - ETA: 1:43:30 - loss: 5.9898 - accuracy: 0.1252\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 154/1615 [=>............................] - ETA: 1:43:22 - loss: 5.9913 - accuracy: 0.1250\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 156/1615 [=>............................] - ETA: 1:43:15 - loss: 5.9868 - accuracy: 0.1252\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 158/1615 [=>............................] - ETA: 1:43:23 - loss: 5.9853 - accuracy: 0.1254\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 160/1615 [=>............................] - ETA: 1:43:03 - loss: 5.9855 - accuracy: 0.1256\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 162/1615 [==>...........................] - ETA: 1:42:51 - loss: 5.9854 - accuracy: 0.1256\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 164/1615 [==>...........................] - ETA: 1:42:44 - loss: 5.9853 - accuracy: 0.1255\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 166/1615 [==>...........................] - ETA: 1:42:36 - loss: 5.9826 - accuracy: 0.1259\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 168/1615 [==>...........................] - ETA: 1:42:44 - loss: 5.9871 - accuracy: 0.1257\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 170/1615 [==>...........................] - ETA: 1:42:24 - loss: 5.9903 - accuracy: 0.1258\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 172/1615 [==>...........................] - ETA: 1:42:26 - loss: 5.9862 - accuracy: 0.1259\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 174/1615 [==>...........................] - ETA: 1:42:04 - loss: 5.9839 - accuracy: 0.1264\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 176/1615 [==>...........................] - ETA: 1:41:56 - loss: 5.9834 - accuracy: 0.1262\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 178/1615 [==>...........................] - ETA: 1:41:48 - loss: 5.9843 - accuracy: 0.1264\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 180/1615 [==>...........................] - ETA: 1:41:40 - loss: 5.9847 - accuracy: 0.1264\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 182/1615 [==>...........................] - ETA: 1:41:32 - loss: 5.9834 - accuracy: 0.1265\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 184/1615 [==>...........................] - ETA: 1:41:24 - loss: 5.9803 - accuracy: 0.1268\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 186/1615 [==>...........................] - ETA: 1:41:26 - loss: 5.9783 - accuracy: 0.1269\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 188/1615 [==>...........................] - ETA: 1:41:10 - loss: 5.9797 - accuracy: 0.1268\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 190/1615 [==>...........................] - ETA: 1:41:01 - loss: 5.9799 - accuracy: 0.1266\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 192/1615 [==>...........................] - ETA: 1:40:54 - loss: 5.9783 - accuracy: 0.1270\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 194/1615 [==>...........................] - ETA: 1:40:47 - loss: 5.9799 - accuracy: 0.1273\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 196/1615 [==>...........................] - ETA: 1:40:38 - loss: 5.9815 - accuracy: 0.1270\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 198/1615 [==>...........................] - ETA: 1:40:30 - loss: 5.9846 - accuracy: 0.1271\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 200/1615 [==>...........................] - ETA: 1:40:35 - loss: 5.9830 - accuracy: 0.1271\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 202/1615 [==>...........................] - ETA: 1:40:18 - loss: 5.9783 - accuracy: 0.1277\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 204/1615 [==>...........................] - ETA: 1:40:06 - loss: 5.9770 - accuracy: 0.1279\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 206/1615 [==>...........................] - ETA: 1:40:04 - loss: 5.9773 - accuracy: 0.1282\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 208/1615 [==>...........................] - ETA: 1:39:51 - loss: 5.9800 - accuracy: 0.1281\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 210/1615 [==>...........................] - ETA: 1:39:42 - loss: 5.9800 - accuracy: 0.1280\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 212/1615 [==>...........................] - ETA: 1:39:36 - loss: 5.9824 - accuracy: 0.1278\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 214/1615 [==>...........................] - ETA: 1:39:37 - loss: 5.9831 - accuracy: 0.1275\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 216/1615 [===>..........................] - ETA: 1:39:18 - loss: 5.9819 - accuracy: 0.1273\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 218/1615 [===>..........................] - ETA: 1:39:10 - loss: 5.9802 - accuracy: 0.1275\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 220/1615 [===>..........................] - ETA: 1:39:04 - loss: 5.9792 - accuracy: 0.1276\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 222/1615 [===>..........................] - ETA: 1:38:55 - loss: 5.9787 - accuracy: 0.1277\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 224/1615 [===>..........................] - ETA: 1:38:46 - loss: 5.9784 - accuracy: 0.1278\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 226/1615 [===>..........................] - ETA: 1:38:39 - loss: 5.9786 - accuracy: 0.1275\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 228/1615 [===>..........................] - ETA: 1:38:32 - loss: 5.9800 - accuracy: 0.1276\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 230/1615 [===>..........................] - ETA: 1:38:22 - loss: 5.9806 - accuracy: 0.1277\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 232/1615 [===>..........................] - ETA: 1:38:15 - loss: 5.9799 - accuracy: 0.1276\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 234/1615 [===>..........................] - ETA: 1:38:04 - loss: 5.9816 - accuracy: 0.1274\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 236/1615 [===>..........................] - ETA: 1:37:56 - loss: 5.9794 - accuracy: 0.1278\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 238/1615 [===>..........................] - ETA: 1:37:48 - loss: 5.9820 - accuracy: 0.1276\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 240/1615 [===>..........................] - ETA: 1:37:41 - loss: 5.9812 - accuracy: 0.1278\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 242/1615 [===>..........................] - ETA: 1:37:40 - loss: 5.9855 - accuracy: 0.1277\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 244/1615 [===>..........................] - ETA: 1:37:24 - loss: 5.9842 - accuracy: 0.1280\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 246/1615 [===>..........................] - ETA: 1:37:17 - loss: 5.9838 - accuracy: 0.1278\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 248/1615 [===>..........................] - ETA: 1:37:08 - loss: 5.9850 - accuracy: 0.1277\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 250/1615 [===>..........................] - ETA: 1:36:59 - loss: 5.9853 - accuracy: 0.1277\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 252/1615 [===>..........................] - ETA: 1:36:52 - loss: 5.9887 - accuracy: 0.1276\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 254/1615 [===>..........................] - ETA: 1:36:43 - loss: 5.9908 - accuracy: 0.1277\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 256/1615 [===>..........................] - ETA: 1:36:38 - loss: 5.9897 - accuracy: 0.1279\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 258/1615 [===>..........................] - ETA: 1:36:27 - loss: 5.9884 - accuracy: 0.1281\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 260/1615 [===>..........................] - ETA: 1:36:18 - loss: 5.9918 - accuracy: 0.1275\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 262/1615 [===>..........................] - ETA: 1:36:10 - loss: 5.9892 - accuracy: 0.1277\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 264/1615 [===>..........................] - ETA: 1:36:03 - loss: 5.9884 - accuracy: 0.1278\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 266/1615 [===>..........................] - ETA: 1:35:53 - loss: 5.9912 - accuracy: 0.1276\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 268/1615 [===>..........................] - ETA: 1:35:45 - loss: 5.9901 - accuracy: 0.1278\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 270/1615 [====>.........................] - ETA: 1:35:43 - loss: 5.9909 - accuracy: 0.1279\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 272/1615 [====>.........................] - ETA: 1:35:30 - loss: 5.9899 - accuracy: 0.1281\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 274/1615 [====>.........................] - ETA: 1:35:20 - loss: 5.9913 - accuracy: 0.1281\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 276/1615 [====>.........................] - ETA: 1:35:11 - loss: 5.9904 - accuracy: 0.1283\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 278/1615 [====>.........................] - ETA: 1:35:03 - loss: 5.9889 - accuracy: 0.1284\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 280/1615 [====>.........................] - ETA: 1:34:56 - loss: 5.9900 - accuracy: 0.1284\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 282/1615 [====>.........................] - ETA: 1:34:47 - loss: 5.9882 - accuracy: 0.1286\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 284/1615 [====>.........................] - ETA: 1:34:41 - loss: 5.9887 - accuracy: 0.1286\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 286/1615 [====>.........................] - ETA: 1:34:29 - loss: 5.9891 - accuracy: 0.1286\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 288/1615 [====>.........................] - ETA: 1:34:22 - loss: 5.9888 - accuracy: 0.1286\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 290/1615 [====>.........................] - ETA: 1:34:14 - loss: 5.9873 - accuracy: 0.1288\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 292/1615 [====>.........................] - ETA: 1:34:06 - loss: 5.9881 - accuracy: 0.1286\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 294/1615 [====>.........................] - ETA: 1:33:57 - loss: 5.9888 - accuracy: 0.1284\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 296/1615 [====>.........................] - ETA: 1:33:49 - loss: 5.9917 - accuracy: 0.1282\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 298/1615 [====>.........................] - ETA: 1:33:42 - loss: 5.9927 - accuracy: 0.1282\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 300/1615 [====>.........................] - ETA: 1:33:33 - loss: 5.9917 - accuracy: 0.1282\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 302/1615 [====>.........................] - ETA: 1:33:24 - loss: 5.9914 - accuracy: 0.1283\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 304/1615 [====>.........................] - ETA: 1:33:15 - loss: 5.9899 - accuracy: 0.1285\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 306/1615 [====>.........................] - ETA: 1:33:08 - loss: 5.9886 - accuracy: 0.1284\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 308/1615 [====>.........................] - ETA: 1:33:00 - loss: 5.9882 - accuracy: 0.1286\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 310/1615 [====>.........................] - ETA: 1:32:52 - loss: 5.9873 - accuracy: 0.1286\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 312/1615 [====>.........................] - ETA: 1:32:43 - loss: 5.9860 - accuracy: 0.1287\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 314/1615 [====>.........................] - ETA: 1:32:34 - loss: 5.9826 - accuracy: 0.1290\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 316/1615 [====>.........................] - ETA: 1:32:26 - loss: 5.9829 - accuracy: 0.1292\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 318/1615 [====>.........................] - ETA: 1:32:16 - loss: 5.9828 - accuracy: 0.1293\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 320/1615 [====>.........................] - ETA: 1:32:09 - loss: 5.9807 - accuracy: 0.1295\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 322/1615 [====>.........................] - ETA: 1:32:01 - loss: 5.9805 - accuracy: 0.1296\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 324/1615 [=====>........................] - ETA: 1:31:53 - loss: 5.9807 - accuracy: 0.1297\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 326/1615 [=====>........................] - ETA: 1:31:45 - loss: 5.9806 - accuracy: 0.1296\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 328/1615 [=====>........................] - ETA: 1:31:41 - loss: 5.9794 - accuracy: 0.1295\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 330/1615 [=====>........................] - ETA: 1:31:30 - loss: 5.9803 - accuracy: 0.1294\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 332/1615 [=====>........................] - ETA: 1:31:19 - loss: 5.9799 - accuracy: 0.1292\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 334/1615 [=====>........................] - ETA: 1:31:12 - loss: 5.9781 - accuracy: 0.1292\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 336/1615 [=====>........................] - ETA: 1:31:09 - loss: 5.9769 - accuracy: 0.1291\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 338/1615 [=====>........................] - ETA: 1:30:58 - loss: 5.9761 - accuracy: 0.1293\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 340/1615 [=====>........................] - ETA: 1:30:46 - loss: 5.9756 - accuracy: 0.1294\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 342/1615 [=====>........................] - ETA: 1:30:37 - loss: 5.9746 - accuracy: 0.1295\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 344/1615 [=====>........................] - ETA: 1:30:29 - loss: 5.9767 - accuracy: 0.1293\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 346/1615 [=====>........................] - ETA: 1:30:20 - loss: 5.9772 - accuracy: 0.1292\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 348/1615 [=====>........................] - ETA: 1:30:12 - loss: 5.9754 - accuracy: 0.1294\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 350/1615 [=====>........................] - ETA: 1:30:05 - loss: 5.9752 - accuracy: 0.1292\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 352/1615 [=====>........................] - ETA: 1:29:56 - loss: 5.9745 - accuracy: 0.1292\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 354/1615 [=====>........................] - ETA: 1:29:47 - loss: 5.9746 - accuracy: 0.1290\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 356/1615 [=====>........................] - ETA: 1:29:38 - loss: 5.9747 - accuracy: 0.1290\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 358/1615 [=====>........................] - ETA: 1:29:35 - loss: 5.9739 - accuracy: 0.1291\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 360/1615 [=====>........................] - ETA: 1:29:23 - loss: 5.9744 - accuracy: 0.1291\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 362/1615 [=====>........................] - ETA: 1:29:19 - loss: 5.9730 - accuracy: 0.1290\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 364/1615 [=====>........................] - ETA: 1:29:06 - loss: 5.9721 - accuracy: 0.1292\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 366/1615 [=====>........................] - ETA: 1:28:57 - loss: 5.9729 - accuracy: 0.1293\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 368/1615 [=====>........................] - ETA: 1:28:49 - loss: 5.9736 - accuracy: 0.1293\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 370/1615 [=====>........................] - ETA: 1:28:46 - loss: 5.9739 - accuracy: 0.1294\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 372/1615 [=====>........................] - ETA: 1:28:35 - loss: 5.9722 - accuracy: 0.1295\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 374/1615 [=====>........................] - ETA: 1:28:24 - loss: 5.9720 - accuracy: 0.1295\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 376/1615 [=====>........................] - ETA: 1:28:15 - loss: 5.9703 - accuracy: 0.1295\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 378/1615 [======>.......................] - ETA: 1:28:10 - loss: 5.9700 - accuracy: 0.1295\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 380/1615 [======>.......................] - ETA: 1:27:57 - loss: 5.9711 - accuracy: 0.1295\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 382/1615 [======>.......................] - ETA: 1:27:49 - loss: 5.9716 - accuracy: 0.1293\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 384/1615 [======>.......................] - ETA: 1:27:40 - loss: 5.9719 - accuracy: 0.1293\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 386/1615 [======>.......................] - ETA: 1:27:38 - loss: 5.9734 - accuracy: 0.1292\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 388/1615 [======>.......................] - ETA: 1:27:27 - loss: 5.9729 - accuracy: 0.1291\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 390/1615 [======>.......................] - ETA: 1:27:16 - loss: 5.9726 - accuracy: 0.1290\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 392/1615 [======>.......................] - ETA: 1:27:10 - loss: 5.9738 - accuracy: 0.1289\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 394/1615 [======>.......................] - ETA: 1:26:59 - loss: 5.9739 - accuracy: 0.1288\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 396/1615 [======>.......................] - ETA: 1:26:51 - loss: 5.9744 - accuracy: 0.1288\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 398/1615 [======>.......................] - ETA: 1:26:47 - loss: 5.9707 - accuracy: 0.1292\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 400/1615 [======>.......................] - ETA: 1:26:35 - loss: 5.9699 - accuracy: 0.1292\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 402/1615 [======>.......................] - ETA: 1:26:25 - loss: 5.9710 - accuracy: 0.1292\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 404/1615 [======>.......................] - ETA: 1:26:16 - loss: 5.9706 - accuracy: 0.1292\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 406/1615 [======>.......................] - ETA: 1:26:09 - loss: 5.9695 - accuracy: 0.1291\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 408/1615 [======>.......................] - ETA: 1:26:00 - loss: 5.9702 - accuracy: 0.1291\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 410/1615 [======>.......................] - ETA: 1:25:50 - loss: 5.9695 - accuracy: 0.1292\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 412/1615 [======>.......................] - ETA: 1:25:43 - loss: 5.9681 - accuracy: 0.1294\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 414/1615 [======>.......................] - ETA: 1:25:38 - loss: 5.9686 - accuracy: 0.1293\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 416/1615 [======>.......................] - ETA: 1:25:26 - loss: 5.9692 - accuracy: 0.1292\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 418/1615 [======>.......................] - ETA: 1:25:18 - loss: 5.9699 - accuracy: 0.1290\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 420/1615 [======>.......................] - ETA: 1:25:09 - loss: 5.9707 - accuracy: 0.1290\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 422/1615 [======>.......................] - ETA: 1:25:00 - loss: 5.9705 - accuracy: 0.1288\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 424/1615 [======>.......................] - ETA: 1:24:52 - loss: 5.9705 - accuracy: 0.1288\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 426/1615 [======>.......................] - ETA: 1:24:44 - loss: 5.9708 - accuracy: 0.1288\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 428/1615 [======>.......................] - ETA: 1:24:35 - loss: 5.9708 - accuracy: 0.1289\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 430/1615 [======>.......................] - ETA: 1:24:27 - loss: 5.9697 - accuracy: 0.1290\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 432/1615 [=======>......................] - ETA: 1:24:19 - loss: 5.9693 - accuracy: 0.1291\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 434/1615 [=======>......................] - ETA: 1:24:10 - loss: 5.9677 - accuracy: 0.1290\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 436/1615 [=======>......................] - ETA: 1:24:01 - loss: 5.9686 - accuracy: 0.1291\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 438/1615 [=======>......................] - ETA: 1:23:53 - loss: 5.9681 - accuracy: 0.1291\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 440/1615 [=======>......................] - ETA: 1:23:44 - loss: 5.9672 - accuracy: 0.1290\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 442/1615 [=======>......................] - ETA: 1:23:39 - loss: 5.9663 - accuracy: 0.1292\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 444/1615 [=======>......................] - ETA: 1:23:28 - loss: 5.9667 - accuracy: 0.1290\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 446/1615 [=======>......................] - ETA: 1:23:19 - loss: 5.9672 - accuracy: 0.1289\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 448/1615 [=======>......................] - ETA: 1:23:12 - loss: 5.9665 - accuracy: 0.1291\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 450/1615 [=======>......................] - ETA: 1:23:02 - loss: 5.9654 - accuracy: 0.1290\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 452/1615 [=======>......................] - ETA: 1:22:53 - loss: 5.9652 - accuracy: 0.1290\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 454/1615 [=======>......................] - ETA: 1:22:48 - loss: 5.9660 - accuracy: 0.1289\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 456/1615 [=======>......................] - ETA: 1:22:37 - loss: 5.9665 - accuracy: 0.1289\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 458/1615 [=======>......................] - ETA: 1:22:28 - loss: 5.9661 - accuracy: 0.1290\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 460/1615 [=======>......................] - ETA: 1:22:20 - loss: 5.9667 - accuracy: 0.1290\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 462/1615 [=======>......................] - ETA: 1:22:12 - loss: 5.9658 - accuracy: 0.1289\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 464/1615 [=======>......................] - ETA: 1:22:03 - loss: 5.9670 - accuracy: 0.1288\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 466/1615 [=======>......................] - ETA: 1:21:55 - loss: 5.9679 - accuracy: 0.1287\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 468/1615 [=======>......................] - ETA: 1:21:49 - loss: 5.9684 - accuracy: 0.1286\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 470/1615 [=======>......................] - ETA: 1:21:39 - loss: 5.9697 - accuracy: 0.1286\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 472/1615 [=======>......................] - ETA: 1:21:29 - loss: 5.9704 - accuracy: 0.1284\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 474/1615 [=======>......................] - ETA: 1:21:24 - loss: 5.9694 - accuracy: 0.1286\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 476/1615 [=======>......................] - ETA: 1:21:14 - loss: 5.9682 - accuracy: 0.1289\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 478/1615 [=======>......................] - ETA: 1:21:04 - loss: 5.9685 - accuracy: 0.1288\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 480/1615 [=======>......................] - ETA: 1:20:55 - loss: 5.9690 - accuracy: 0.1286\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 482/1615 [=======>......................] - ETA: 1:20:49 - loss: 5.9674 - accuracy: 0.1289\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 484/1615 [=======>......................] - ETA: 1:20:39 - loss: 5.9680 - accuracy: 0.1289\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 486/1615 [========>.....................] - ETA: 1:20:30 - loss: 5.9692 - accuracy: 0.1288\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 488/1615 [========>.....................] - ETA: 1:20:22 - loss: 5.9694 - accuracy: 0.1287\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 490/1615 [========>.....................] - ETA: 1:20:13 - loss: 5.9701 - accuracy: 0.1287\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 492/1615 [========>.....................] - ETA: 1:20:05 - loss: 5.9701 - accuracy: 0.1288\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 494/1615 [========>.....................] - ETA: 1:19:56 - loss: 5.9693 - accuracy: 0.1289\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 496/1615 [========>.....................] - ETA: 1:19:49 - loss: 5.9692 - accuracy: 0.1290\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 498/1615 [========>.....................] - ETA: 1:19:39 - loss: 5.9699 - accuracy: 0.1289\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 500/1615 [========>.....................] - ETA: 1:19:31 - loss: 5.9702 - accuracy: 0.1289\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 502/1615 [========>.....................] - ETA: 1:19:22 - loss: 5.9704 - accuracy: 0.1289\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 504/1615 [========>.....................] - ETA: 1:19:13 - loss: 5.9721 - accuracy: 0.1288\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 506/1615 [========>.....................] - ETA: 1:19:05 - loss: 5.9725 - accuracy: 0.1288\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 508/1615 [========>.....................] - ETA: 1:18:57 - loss: 5.9725 - accuracy: 0.1287\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 510/1615 [========>.....................] - ETA: 1:18:48 - loss: 5.9728 - accuracy: 0.1286\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 512/1615 [========>.....................] - ETA: 1:18:40 - loss: 5.9722 - accuracy: 0.1285\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 514/1615 [========>.....................] - ETA: 1:18:31 - loss: 5.9723 - accuracy: 0.1284\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 516/1615 [========>.....................] - ETA: 1:18:23 - loss: 5.9726 - accuracy: 0.1284\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 518/1615 [========>.....................] - ETA: 1:18:14 - loss: 5.9727 - accuracy: 0.1283\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 520/1615 [========>.....................] - ETA: 1:18:07 - loss: 5.9732 - accuracy: 0.1283\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 522/1615 [========>.....................] - ETA: 1:17:57 - loss: 5.9744 - accuracy: 0.1284\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 524/1615 [========>.....................] - ETA: 1:17:49 - loss: 5.9742 - accuracy: 0.1286\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 526/1615 [========>.....................] - ETA: 1:17:40 - loss: 5.9748 - accuracy: 0.1285\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 528/1615 [========>.....................] - ETA: 1:17:31 - loss: 5.9740 - accuracy: 0.1285\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 530/1615 [========>.....................] - ETA: 1:17:23 - loss: 5.9742 - accuracy: 0.1285\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 532/1615 [========>.....................] - ETA: 1:17:15 - loss: 5.9743 - accuracy: 0.1285\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 534/1615 [========>.....................] - ETA: 1:17:06 - loss: 5.9732 - accuracy: 0.1285\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 536/1615 [========>.....................] - ETA: 1:16:58 - loss: 5.9721 - accuracy: 0.1286\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 538/1615 [========>.....................] - ETA: 1:16:49 - loss: 5.9721 - accuracy: 0.1284\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 540/1615 [=========>....................] - ETA: 1:16:40 - loss: 5.9720 - accuracy: 0.1283\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 542/1615 [=========>....................] - ETA: 1:16:34 - loss: 5.9718 - accuracy: 0.1283\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 544/1615 [=========>....................] - ETA: 1:16:26 - loss: 5.9709 - accuracy: 0.1284\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 546/1615 [=========>....................] - ETA: 1:16:16 - loss: 5.9718 - accuracy: 0.1284\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 548/1615 [=========>....................] - ETA: 1:16:07 - loss: 5.9725 - accuracy: 0.1284\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 550/1615 [=========>....................] - ETA: 1:15:58 - loss: 5.9733 - accuracy: 0.1284\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 552/1615 [=========>....................] - ETA: 1:15:50 - loss: 5.9725 - accuracy: 0.1284\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 554/1615 [=========>....................] - ETA: 1:15:41 - loss: 5.9721 - accuracy: 0.1285\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 556/1615 [=========>....................] - ETA: 1:15:32 - loss: 5.9703 - accuracy: 0.1287\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 558/1615 [=========>....................] - ETA: 1:15:27 - loss: 5.9710 - accuracy: 0.1286\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 560/1615 [=========>....................] - ETA: 1:15:16 - loss: 5.9699 - accuracy: 0.1288\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 562/1615 [=========>....................] - ETA: 1:15:07 - loss: 5.9690 - accuracy: 0.1287\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 564/1615 [=========>....................] - ETA: 1:15:01 - loss: 5.9687 - accuracy: 0.1288\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 566/1615 [=========>....................] - ETA: 1:14:50 - loss: 5.9681 - accuracy: 0.1289\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 568/1615 [=========>....................] - ETA: 1:14:42 - loss: 5.9675 - accuracy: 0.1290\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 570/1615 [=========>....................] - ETA: 1:14:36 - loss: 5.9679 - accuracy: 0.1289\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 572/1615 [=========>....................] - ETA: 1:14:26 - loss: 5.9672 - accuracy: 0.1288\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 574/1615 [=========>....................] - ETA: 1:14:16 - loss: 5.9667 - accuracy: 0.1290\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 576/1615 [=========>....................] - ETA: 1:14:07 - loss: 5.9673 - accuracy: 0.1289\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 578/1615 [=========>....................] - ETA: 1:13:58 - loss: 5.9668 - accuracy: 0.1289\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 580/1615 [=========>....................] - ETA: 1:13:50 - loss: 5.9678 - accuracy: 0.1287\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 582/1615 [=========>....................] - ETA: 1:13:42 - loss: 5.9685 - accuracy: 0.1287\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 584/1615 [=========>....................] - ETA: 1:13:33 - loss: 5.9687 - accuracy: 0.1287\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 586/1615 [=========>....................] - ETA: 1:13:28 - loss: 5.9687 - accuracy: 0.1287\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 588/1615 [=========>....................] - ETA: 1:13:18 - loss: 5.9682 - accuracy: 0.1287\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 590/1615 [=========>....................] - ETA: 1:13:08 - loss: 5.9684 - accuracy: 0.1286\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 592/1615 [=========>....................] - ETA: 1:12:59 - loss: 5.9686 - accuracy: 0.1285\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 594/1615 [==========>...................] - ETA: 1:12:51 - loss: 5.9677 - accuracy: 0.1286\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 596/1615 [==========>...................] - ETA: 1:12:42 - loss: 5.9693 - accuracy: 0.1285\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 598/1615 [==========>...................] - ETA: 1:12:33 - loss: 5.9695 - accuracy: 0.1285\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 600/1615 [==========>...................] - ETA: 1:12:25 - loss: 5.9702 - accuracy: 0.1285\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 602/1615 [==========>...................] - ETA: 1:12:17 - loss: 5.9700 - accuracy: 0.1285\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 604/1615 [==========>...................] - ETA: 1:12:08 - loss: 5.9698 - accuracy: 0.1285\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 606/1615 [==========>...................] - ETA: 1:12:00 - loss: 5.9700 - accuracy: 0.1285\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 608/1615 [==========>...................] - ETA: 1:11:51 - loss: 5.9716 - accuracy: 0.1285\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 610/1615 [==========>...................] - ETA: 1:11:43 - loss: 5.9722 - accuracy: 0.1283\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 612/1615 [==========>...................] - ETA: 1:11:34 - loss: 5.9718 - accuracy: 0.1282\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 614/1615 [==========>...................] - ETA: 1:11:29 - loss: 5.9718 - accuracy: 0.1281\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 616/1615 [==========>...................] - ETA: 1:11:20 - loss: 5.9721 - accuracy: 0.1281\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 618/1615 [==========>...................] - ETA: 1:11:09 - loss: 5.9732 - accuracy: 0.1281\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 620/1615 [==========>...................] - ETA: 1:11:00 - loss: 5.9728 - accuracy: 0.1280\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 622/1615 [==========>...................] - ETA: 1:10:52 - loss: 5.9726 - accuracy: 0.1281\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 624/1615 [==========>...................] - ETA: 1:10:43 - loss: 5.9720 - accuracy: 0.1281\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 626/1615 [==========>...................] - ETA: 1:10:34 - loss: 5.9713 - accuracy: 0.1281\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 628/1615 [==========>...................] - ETA: 1:10:29 - loss: 5.9695 - accuracy: 0.1282\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 630/1615 [==========>...................] - ETA: 1:10:19 - loss: 5.9693 - accuracy: 0.1283\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 632/1615 [==========>...................] - ETA: 1:10:09 - loss: 5.9695 - accuracy: 0.1283\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 634/1615 [==========>...................] - ETA: 1:10:00 - loss: 5.9696 - accuracy: 0.1283\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 636/1615 [==========>...................] - ETA: 1:09:52 - loss: 5.9698 - accuracy: 0.1282\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 638/1615 [==========>...................] - ETA: 1:09:43 - loss: 5.9706 - accuracy: 0.1282\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 640/1615 [==========>...................] - ETA: 1:09:38 - loss: 5.9698 - accuracy: 0.1282\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 642/1615 [==========>...................] - ETA: 1:09:28 - loss: 5.9701 - accuracy: 0.1283\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 644/1615 [==========>...................] - ETA: 1:09:19 - loss: 5.9702 - accuracy: 0.1283\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 646/1615 [===========>..................] - ETA: 1:09:09 - loss: 5.9709 - accuracy: 0.1283\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 648/1615 [===========>..................] - ETA: 1:09:01 - loss: 5.9714 - accuracy: 0.1282\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 650/1615 [===========>..................] - ETA: 1:08:52 - loss: 5.9717 - accuracy: 0.1282\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 652/1615 [===========>..................] - ETA: 1:08:43 - loss: 5.9713 - accuracy: 0.1281\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 654/1615 [===========>..................] - ETA: 1:08:35 - loss: 5.9712 - accuracy: 0.1283\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 656/1615 [===========>..................] - ETA: 1:08:28 - loss: 5.9715 - accuracy: 0.1283\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 658/1615 [===========>..................] - ETA: 1:08:18 - loss: 5.9707 - accuracy: 0.1284\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 660/1615 [===========>..................] - ETA: 1:08:09 - loss: 5.9720 - accuracy: 0.1284\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 662/1615 [===========>..................] - ETA: 1:08:01 - loss: 5.9711 - accuracy: 0.1285\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 664/1615 [===========>..................] - ETA: 1:07:52 - loss: 5.9712 - accuracy: 0.1284\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 666/1615 [===========>..................] - ETA: 1:07:44 - loss: 5.9712 - accuracy: 0.1283\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 668/1615 [===========>..................] - ETA: 1:07:38 - loss: 5.9706 - accuracy: 0.1284\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 670/1615 [===========>..................] - ETA: 1:07:28 - loss: 5.9707 - accuracy: 0.1285\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 672/1615 [===========>..................] - ETA: 1:07:18 - loss: 5.9706 - accuracy: 0.1286\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 674/1615 [===========>..................] - ETA: 1:07:10 - loss: 5.9708 - accuracy: 0.1288\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 676/1615 [===========>..................] - ETA: 1:07:01 - loss: 5.9703 - accuracy: 0.1289\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 678/1615 [===========>..................] - ETA: 1:06:52 - loss: 5.9703 - accuracy: 0.1288\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 680/1615 [===========>..................] - ETA: 1:06:44 - loss: 5.9702 - accuracy: 0.1288\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 682/1615 [===========>..................] - ETA: 1:06:38 - loss: 5.9698 - accuracy: 0.1289\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 684/1615 [===========>..................] - ETA: 1:06:28 - loss: 5.9685 - accuracy: 0.1291\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 686/1615 [===========>..................] - ETA: 1:06:19 - loss: 5.9680 - accuracy: 0.1291\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 688/1615 [===========>..................] - ETA: 1:06:10 - loss: 5.9682 - accuracy: 0.1291\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 690/1615 [===========>..................] - ETA: 1:06:01 - loss: 5.9690 - accuracy: 0.1291\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 692/1615 [===========>..................] - ETA: 1:05:52 - loss: 5.9687 - accuracy: 0.1292\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 694/1615 [===========>..................] - ETA: 1:05:44 - loss: 5.9681 - accuracy: 0.1293\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 696/1615 [===========>..................] - ETA: 1:05:36 - loss: 5.9681 - accuracy: 0.1293\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 698/1615 [===========>..................] - ETA: 1:05:27 - loss: 5.9686 - accuracy: 0.1293\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 700/1615 [============>.................] - ETA: 1:05:18 - loss: 5.9687 - accuracy: 0.1292\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 702/1615 [============>.................] - ETA: 1:05:10 - loss: 5.9682 - accuracy: 0.1293\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 704/1615 [============>.................] - ETA: 1:05:02 - loss: 5.9685 - accuracy: 0.1292\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 706/1615 [============>.................] - ETA: 1:04:54 - loss: 5.9683 - accuracy: 0.1292\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 708/1615 [============>.................] - ETA: 1:04:45 - loss: 5.9679 - accuracy: 0.1292\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 710/1615 [============>.................] - ETA: 1:04:38 - loss: 5.9669 - accuracy: 0.1293\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 712/1615 [============>.................] - ETA: 1:04:29 - loss: 5.9666 - accuracy: 0.1293\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 714/1615 [============>.................] - ETA: 1:04:20 - loss: 5.9663 - accuracy: 0.1292\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 716/1615 [============>.................] - ETA: 1:04:11 - loss: 5.9654 - accuracy: 0.1293\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 718/1615 [============>.................] - ETA: 1:04:02 - loss: 5.9644 - accuracy: 0.1295\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 720/1615 [============>.................] - ETA: 1:03:53 - loss: 5.9645 - accuracy: 0.1295\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 722/1615 [============>.................] - ETA: 1:03:45 - loss: 5.9641 - accuracy: 0.1295\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 724/1615 [============>.................] - ETA: 1:03:39 - loss: 5.9630 - accuracy: 0.1295\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 726/1615 [============>.................] - ETA: 1:03:29 - loss: 5.9624 - accuracy: 0.1295\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 728/1615 [============>.................] - ETA: 1:03:20 - loss: 5.9629 - accuracy: 0.1295\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 730/1615 [============>.................] - ETA: 1:03:11 - loss: 5.9635 - accuracy: 0.1294\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 732/1615 [============>.................] - ETA: 1:03:02 - loss: 5.9635 - accuracy: 0.1294\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 734/1615 [============>.................] - ETA: 1:02:54 - loss: 5.9629 - accuracy: 0.1296\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 736/1615 [============>.................] - ETA: 1:02:45 - loss: 5.9620 - accuracy: 0.1296\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 738/1615 [============>.................] - ETA: 1:02:38 - loss: 5.9618 - accuracy: 0.1296\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 740/1615 [============>.................] - ETA: 1:02:29 - loss: 5.9604 - accuracy: 0.1297\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 742/1615 [============>.................] - ETA: 1:02:20 - loss: 5.9599 - accuracy: 0.1298\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 744/1615 [============>.................] - ETA: 1:02:11 - loss: 5.9600 - accuracy: 0.1298\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 746/1615 [============>.................] - ETA: 1:02:02 - loss: 5.9596 - accuracy: 0.1298\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 748/1615 [============>.................] - ETA: 1:01:55 - loss: 5.9602 - accuracy: 0.1297\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 750/1615 [============>.................] - ETA: 1:01:45 - loss: 5.9611 - accuracy: 0.1297\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 752/1615 [============>.................] - ETA: 1:01:38 - loss: 5.9615 - accuracy: 0.1295\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 754/1615 [=============>................] - ETA: 1:01:29 - loss: 5.9616 - accuracy: 0.1296\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 756/1615 [=============>................] - ETA: 1:01:19 - loss: 5.9624 - accuracy: 0.1295\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 758/1615 [=============>................] - ETA: 1:01:11 - loss: 5.9629 - accuracy: 0.1296\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 760/1615 [=============>................] - ETA: 1:01:02 - loss: 5.9628 - accuracy: 0.1297\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 762/1615 [=============>................] - ETA: 1:00:54 - loss: 5.9626 - accuracy: 0.1297\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 764/1615 [=============>................] - ETA: 1:00:47 - loss: 5.9618 - accuracy: 0.1299\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 766/1615 [=============>................] - ETA: 1:00:37 - loss: 5.9625 - accuracy: 0.1299\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 768/1615 [=============>................] - ETA: 1:00:28 - loss: 5.9614 - accuracy: 0.1300\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 770/1615 [=============>................] - ETA: 1:00:20 - loss: 5.9615 - accuracy: 0.1300\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 772/1615 [=============>................] - ETA: 1:00:11 - loss: 5.9614 - accuracy: 0.1300\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 774/1615 [=============>................] - ETA: 1:00:03 - loss: 5.9608 - accuracy: 0.1301\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 776/1615 [=============>................] - ETA: 59:54 - loss: 5.9610 - accuracy: 0.1301  \n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 778/1615 [=============>................] - ETA: 59:46 - loss: 5.9606 - accuracy: 0.1301\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 780/1615 [=============>................] - ETA: 59:39 - loss: 5.9609 - accuracy: 0.1301\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 782/1615 [=============>................] - ETA: 59:29 - loss: 5.9608 - accuracy: 0.1301\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 784/1615 [=============>................] - ETA: 59:21 - loss: 5.9609 - accuracy: 0.1301\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 786/1615 [=============>................] - ETA: 59:12 - loss: 5.9604 - accuracy: 0.1301\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 788/1615 [=============>................] - ETA: 59:03 - loss: 5.9612 - accuracy: 0.1301\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 790/1615 [=============>................] - ETA: 58:54 - loss: 5.9607 - accuracy: 0.1302\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 792/1615 [=============>................] - ETA: 58:46 - loss: 5.9603 - accuracy: 0.1303\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 794/1615 [=============>................] - ETA: 58:37 - loss: 5.9603 - accuracy: 0.1303\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 796/1615 [=============>................] - ETA: 58:28 - loss: 5.9613 - accuracy: 0.1302\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 798/1615 [=============>................] - ETA: 58:20 - loss: 5.9609 - accuracy: 0.1302\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 800/1615 [=============>................] - ETA: 58:11 - loss: 5.9609 - accuracy: 0.1302\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 802/1615 [=============>................] - ETA: 58:03 - loss: 5.9609 - accuracy: 0.1303\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 804/1615 [=============>................] - ETA: 57:55 - loss: 5.9605 - accuracy: 0.1303\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 806/1615 [=============>................] - ETA: 57:46 - loss: 5.9600 - accuracy: 0.1303\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 808/1615 [==============>...............] - ETA: 57:38 - loss: 5.9597 - accuracy: 0.1304\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 810/1615 [==============>...............] - ETA: 57:28 - loss: 5.9590 - accuracy: 0.1304\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 812/1615 [==============>...............] - ETA: 57:20 - loss: 5.9585 - accuracy: 0.1305\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 814/1615 [==============>...............] - ETA: 57:11 - loss: 5.9581 - accuracy: 0.1305\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 816/1615 [==============>...............] - ETA: 57:03 - loss: 5.9571 - accuracy: 0.1306\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 818/1615 [==============>...............] - ETA: 56:54 - loss: 5.9573 - accuracy: 0.1307\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 820/1615 [==============>...............] - ETA: 56:46 - loss: 5.9569 - accuracy: 0.1307\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 822/1615 [==============>...............] - ETA: 56:38 - loss: 5.9569 - accuracy: 0.1307\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 824/1615 [==============>...............] - ETA: 56:29 - loss: 5.9568 - accuracy: 0.1307\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 826/1615 [==============>...............] - ETA: 56:21 - loss: 5.9575 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 828/1615 [==============>...............] - ETA: 56:12 - loss: 5.9567 - accuracy: 0.1307\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 830/1615 [==============>...............] - ETA: 56:03 - loss: 5.9568 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 832/1615 [==============>...............] - ETA: 55:55 - loss: 5.9570 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 834/1615 [==============>...............] - ETA: 55:46 - loss: 5.9564 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 836/1615 [==============>...............] - ETA: 55:38 - loss: 5.9569 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 838/1615 [==============>...............] - ETA: 55:29 - loss: 5.9568 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 840/1615 [==============>...............] - ETA: 55:20 - loss: 5.9572 - accuracy: 0.1307\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 842/1615 [==============>...............] - ETA: 55:12 - loss: 5.9573 - accuracy: 0.1307\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 844/1615 [==============>...............] - ETA: 55:03 - loss: 5.9571 - accuracy: 0.1307\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 846/1615 [==============>...............] - ETA: 54:54 - loss: 5.9559 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 848/1615 [==============>...............] - ETA: 54:46 - loss: 5.9554 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 850/1615 [==============>...............] - ETA: 54:38 - loss: 5.9555 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 852/1615 [==============>...............] - ETA: 54:29 - loss: 5.9554 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 854/1615 [==============>...............] - ETA: 54:20 - loss: 5.9559 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 856/1615 [==============>...............] - ETA: 54:12 - loss: 5.9562 - accuracy: 0.1307\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 858/1615 [==============>...............] - ETA: 54:03 - loss: 5.9560 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 860/1615 [==============>...............] - ETA: 53:56 - loss: 5.9567 - accuracy: 0.1307\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 862/1615 [===============>..............] - ETA: 53:47 - loss: 5.9561 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 864/1615 [===============>..............] - ETA: 53:38 - loss: 5.9563 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 866/1615 [===============>..............] - ETA: 53:29 - loss: 5.9565 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 868/1615 [===============>..............] - ETA: 53:21 - loss: 5.9567 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 870/1615 [===============>..............] - ETA: 53:12 - loss: 5.9577 - accuracy: 0.1307\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 872/1615 [===============>..............] - ETA: 53:03 - loss: 5.9571 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 874/1615 [===============>..............] - ETA: 52:55 - loss: 5.9575 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 876/1615 [===============>..............] - ETA: 52:46 - loss: 5.9578 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 878/1615 [===============>..............] - ETA: 52:38 - loss: 5.9581 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 880/1615 [===============>..............] - ETA: 52:29 - loss: 5.9576 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 882/1615 [===============>..............] - ETA: 52:22 - loss: 5.9578 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 884/1615 [===============>..............] - ETA: 52:12 - loss: 5.9582 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 886/1615 [===============>..............] - ETA: 52:03 - loss: 5.9569 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 888/1615 [===============>..............] - ETA: 51:55 - loss: 5.9571 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 890/1615 [===============>..............] - ETA: 51:46 - loss: 5.9567 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 892/1615 [===============>..............] - ETA: 51:38 - loss: 5.9562 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 894/1615 [===============>..............] - ETA: 51:29 - loss: 5.9561 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 896/1615 [===============>..............] - ETA: 51:22 - loss: 5.9564 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 898/1615 [===============>..............] - ETA: 51:12 - loss: 5.9559 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 900/1615 [===============>..............] - ETA: 51:03 - loss: 5.9567 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 902/1615 [===============>..............] - ETA: 50:55 - loss: 5.9566 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 904/1615 [===============>..............] - ETA: 50:46 - loss: 5.9559 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 906/1615 [===============>..............] - ETA: 50:38 - loss: 5.9558 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 908/1615 [===============>..............] - ETA: 50:29 - loss: 5.9560 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 910/1615 [===============>..............] - ETA: 50:22 - loss: 5.9558 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 912/1615 [===============>..............] - ETA: 50:12 - loss: 5.9561 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 914/1615 [===============>..............] - ETA: 50:04 - loss: 5.9562 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 916/1615 [================>.............] - ETA: 49:56 - loss: 5.9559 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 918/1615 [================>.............] - ETA: 49:46 - loss: 5.9556 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 920/1615 [================>.............] - ETA: 49:38 - loss: 5.9557 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 922/1615 [================>.............] - ETA: 49:29 - loss: 5.9558 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 924/1615 [================>.............] - ETA: 49:22 - loss: 5.9555 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 926/1615 [================>.............] - ETA: 49:13 - loss: 5.9553 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 928/1615 [================>.............] - ETA: 49:04 - loss: 5.9567 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 930/1615 [================>.............] - ETA: 48:55 - loss: 5.9565 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 932/1615 [================>.............] - ETA: 48:47 - loss: 5.9563 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 934/1615 [================>.............] - ETA: 48:38 - loss: 5.9570 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 936/1615 [================>.............] - ETA: 48:30 - loss: 5.9572 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 938/1615 [================>.............] - ETA: 48:22 - loss: 5.9570 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 940/1615 [================>.............] - ETA: 48:13 - loss: 5.9567 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 942/1615 [================>.............] - ETA: 48:04 - loss: 5.9572 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 944/1615 [================>.............] - ETA: 47:55 - loss: 5.9571 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 946/1615 [================>.............] - ETA: 47:47 - loss: 5.9570 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 948/1615 [================>.............] - ETA: 47:38 - loss: 5.9570 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 950/1615 [================>.............] - ETA: 47:30 - loss: 5.9572 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 952/1615 [================>.............] - ETA: 47:22 - loss: 5.9573 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 954/1615 [================>.............] - ETA: 47:13 - loss: 5.9565 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 956/1615 [================>.............] - ETA: 47:04 - loss: 5.9566 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 958/1615 [================>.............] - ETA: 46:55 - loss: 5.9569 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 960/1615 [================>.............] - ETA: 46:47 - loss: 5.9575 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 962/1615 [================>.............] - ETA: 46:39 - loss: 5.9579 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 964/1615 [================>.............] - ETA: 46:30 - loss: 5.9573 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 966/1615 [================>.............] - ETA: 46:22 - loss: 5.9570 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 968/1615 [================>.............] - ETA: 46:13 - loss: 5.9572 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 970/1615 [=================>............] - ETA: 46:05 - loss: 5.9575 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 972/1615 [=================>............] - ETA: 45:56 - loss: 5.9583 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 974/1615 [=================>............] - ETA: 45:47 - loss: 5.9581 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 976/1615 [=================>............] - ETA: 45:39 - loss: 5.9586 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 978/1615 [=================>............] - ETA: 45:30 - loss: 5.9588 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 980/1615 [=================>............] - ETA: 45:21 - loss: 5.9588 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 982/1615 [=================>............] - ETA: 45:13 - loss: 5.9582 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 984/1615 [=================>............] - ETA: 45:05 - loss: 5.9584 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 986/1615 [=================>............] - ETA: 44:56 - loss: 5.9579 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 988/1615 [=================>............] - ETA: 44:47 - loss: 5.9580 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 990/1615 [=================>............] - ETA: 44:38 - loss: 5.9579 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 992/1615 [=================>............] - ETA: 44:31 - loss: 5.9576 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 994/1615 [=================>............] - ETA: 44:22 - loss: 5.9579 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 996/1615 [=================>............] - ETA: 44:13 - loss: 5.9583 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            " 998/1615 [=================>............] - ETA: 44:04 - loss: 5.9585 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1000/1615 [=================>............] - ETA: 43:56 - loss: 5.9589 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1002/1615 [=================>............] - ETA: 43:47 - loss: 5.9591 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1004/1615 [=================>............] - ETA: 43:39 - loss: 5.9595 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1006/1615 [=================>............] - ETA: 43:30 - loss: 5.9596 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1008/1615 [=================>............] - ETA: 43:22 - loss: 5.9592 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1010/1615 [=================>............] - ETA: 43:13 - loss: 5.9601 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1012/1615 [=================>............] - ETA: 43:04 - loss: 5.9601 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1014/1615 [=================>............] - ETA: 42:56 - loss: 5.9604 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1016/1615 [=================>............] - ETA: 42:47 - loss: 5.9604 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1018/1615 [=================>............] - ETA: 42:39 - loss: 5.9603 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1020/1615 [=================>............] - ETA: 42:30 - loss: 5.9606 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1022/1615 [=================>............] - ETA: 42:21 - loss: 5.9603 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1024/1615 [==================>...........] - ETA: 42:13 - loss: 5.9609 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1026/1615 [==================>...........] - ETA: 42:04 - loss: 5.9610 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1028/1615 [==================>...........] - ETA: 41:56 - loss: 5.9613 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1030/1615 [==================>...........] - ETA: 41:47 - loss: 5.9616 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1032/1615 [==================>...........] - ETA: 41:39 - loss: 5.9620 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1034/1615 [==================>...........] - ETA: 41:30 - loss: 5.9621 - accuracy: 0.1307\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1036/1615 [==================>...........] - ETA: 41:22 - loss: 5.9619 - accuracy: 0.1307\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1038/1615 [==================>...........] - ETA: 41:13 - loss: 5.9617 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1040/1615 [==================>...........] - ETA: 41:06 - loss: 5.9618 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1042/1615 [==================>...........] - ETA: 40:57 - loss: 5.9621 - accuracy: 0.1307\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1044/1615 [==================>...........] - ETA: 40:48 - loss: 5.9618 - accuracy: 0.1307\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1046/1615 [==================>...........] - ETA: 40:39 - loss: 5.9613 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1048/1615 [==================>...........] - ETA: 40:30 - loss: 5.9611 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1050/1615 [==================>...........] - ETA: 40:22 - loss: 5.9612 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1052/1615 [==================>...........] - ETA: 40:13 - loss: 5.9613 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1054/1615 [==================>...........] - ETA: 40:05 - loss: 5.9619 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1056/1615 [==================>...........] - ETA: 39:56 - loss: 5.9624 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1058/1615 [==================>...........] - ETA: 39:48 - loss: 5.9626 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1060/1615 [==================>...........] - ETA: 39:39 - loss: 5.9629 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1062/1615 [==================>...........] - ETA: 39:30 - loss: 5.9633 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1064/1615 [==================>...........] - ETA: 39:22 - loss: 5.9632 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1066/1615 [==================>...........] - ETA: 39:13 - loss: 5.9636 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1068/1615 [==================>...........] - ETA: 39:05 - loss: 5.9637 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1070/1615 [==================>...........] - ETA: 38:56 - loss: 5.9637 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1072/1615 [==================>...........] - ETA: 38:47 - loss: 5.9637 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1074/1615 [==================>...........] - ETA: 38:39 - loss: 5.9635 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1076/1615 [==================>...........] - ETA: 38:30 - loss: 5.9634 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1078/1615 [===================>..........] - ETA: 38:23 - loss: 5.9638 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1080/1615 [===================>..........] - ETA: 38:14 - loss: 5.9639 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1082/1615 [===================>..........] - ETA: 38:05 - loss: 5.9639 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1084/1615 [===================>..........] - ETA: 37:56 - loss: 5.9641 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1086/1615 [===================>..........] - ETA: 37:48 - loss: 5.9644 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1088/1615 [===================>..........] - ETA: 37:40 - loss: 5.9641 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1090/1615 [===================>..........] - ETA: 37:30 - loss: 5.9641 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1092/1615 [===================>..........] - ETA: 37:22 - loss: 5.9642 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1094/1615 [===================>..........] - ETA: 37:14 - loss: 5.9638 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1096/1615 [===================>..........] - ETA: 37:05 - loss: 5.9632 - accuracy: 0.1308\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1098/1615 [===================>..........] - ETA: 36:56 - loss: 5.9630 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1100/1615 [===================>..........] - ETA: 36:48 - loss: 5.9626 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1102/1615 [===================>..........] - ETA: 36:39 - loss: 5.9623 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1104/1615 [===================>..........] - ETA: 36:30 - loss: 5.9621 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1106/1615 [===================>..........] - ETA: 36:23 - loss: 5.9614 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1108/1615 [===================>..........] - ETA: 36:14 - loss: 5.9616 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1110/1615 [===================>..........] - ETA: 36:05 - loss: 5.9613 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1112/1615 [===================>..........] - ETA: 35:56 - loss: 5.9614 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1114/1615 [===================>..........] - ETA: 35:48 - loss: 5.9617 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1116/1615 [===================>..........] - ETA: 35:39 - loss: 5.9616 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1118/1615 [===================>..........] - ETA: 35:31 - loss: 5.9615 - accuracy: 0.1313\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1120/1615 [===================>..........] - ETA: 35:22 - loss: 5.9616 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1122/1615 [===================>..........] - ETA: 35:14 - loss: 5.9619 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1124/1615 [===================>..........] - ETA: 35:05 - loss: 5.9620 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1126/1615 [===================>..........] - ETA: 34:56 - loss: 5.9621 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1128/1615 [===================>..........] - ETA: 34:48 - loss: 5.9627 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1130/1615 [===================>..........] - ETA: 34:39 - loss: 5.9630 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1132/1615 [====================>.........] - ETA: 34:31 - loss: 5.9633 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1134/1615 [====================>.........] - ETA: 34:22 - loss: 5.9635 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1136/1615 [====================>.........] - ETA: 34:14 - loss: 5.9635 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1138/1615 [====================>.........] - ETA: 34:05 - loss: 5.9634 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1140/1615 [====================>.........] - ETA: 33:56 - loss: 5.9635 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1142/1615 [====================>.........] - ETA: 33:48 - loss: 5.9634 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1144/1615 [====================>.........] - ETA: 33:39 - loss: 5.9630 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1146/1615 [====================>.........] - ETA: 33:31 - loss: 5.9626 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1148/1615 [====================>.........] - ETA: 33:22 - loss: 5.9625 - accuracy: 0.1313\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1150/1615 [====================>.........] - ETA: 33:14 - loss: 5.9627 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1152/1615 [====================>.........] - ETA: 33:05 - loss: 5.9621 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1154/1615 [====================>.........] - ETA: 32:56 - loss: 5.9623 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1156/1615 [====================>.........] - ETA: 32:48 - loss: 5.9623 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1158/1615 [====================>.........] - ETA: 32:39 - loss: 5.9625 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1160/1615 [====================>.........] - ETA: 32:31 - loss: 5.9627 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1162/1615 [====================>.........] - ETA: 32:22 - loss: 5.9629 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1164/1615 [====================>.........] - ETA: 32:14 - loss: 5.9631 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1166/1615 [====================>.........] - ETA: 32:05 - loss: 5.9629 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1168/1615 [====================>.........] - ETA: 31:57 - loss: 5.9623 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1170/1615 [====================>.........] - ETA: 31:48 - loss: 5.9613 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1172/1615 [====================>.........] - ETA: 31:39 - loss: 5.9608 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1174/1615 [====================>.........] - ETA: 31:31 - loss: 5.9602 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1176/1615 [====================>.........] - ETA: 31:22 - loss: 5.9601 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1178/1615 [====================>.........] - ETA: 31:14 - loss: 5.9600 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1180/1615 [====================>.........] - ETA: 31:05 - loss: 5.9601 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1182/1615 [====================>.........] - ETA: 30:56 - loss: 5.9601 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1184/1615 [====================>.........] - ETA: 30:48 - loss: 5.9601 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1186/1615 [=====================>........] - ETA: 30:39 - loss: 5.9601 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1188/1615 [=====================>........] - ETA: 30:31 - loss: 5.9604 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1190/1615 [=====================>........] - ETA: 30:22 - loss: 5.9604 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1192/1615 [=====================>........] - ETA: 30:14 - loss: 5.9606 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1194/1615 [=====================>........] - ETA: 30:05 - loss: 5.9611 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1196/1615 [=====================>........] - ETA: 29:56 - loss: 5.9615 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1198/1615 [=====================>........] - ETA: 29:48 - loss: 5.9612 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1200/1615 [=====================>........] - ETA: 29:39 - loss: 5.9611 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1202/1615 [=====================>........] - ETA: 29:31 - loss: 5.9611 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1204/1615 [=====================>........] - ETA: 29:22 - loss: 5.9611 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1206/1615 [=====================>........] - ETA: 29:14 - loss: 5.9615 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1208/1615 [=====================>........] - ETA: 29:05 - loss: 5.9620 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1210/1615 [=====================>........] - ETA: 28:56 - loss: 5.9621 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1212/1615 [=====================>........] - ETA: 28:48 - loss: 5.9624 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1214/1615 [=====================>........] - ETA: 28:39 - loss: 5.9620 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1216/1615 [=====================>........] - ETA: 28:31 - loss: 5.9619 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1218/1615 [=====================>........] - ETA: 28:22 - loss: 5.9617 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1220/1615 [=====================>........] - ETA: 28:14 - loss: 5.9620 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1222/1615 [=====================>........] - ETA: 28:05 - loss: 5.9623 - accuracy: 0.1309\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1224/1615 [=====================>........] - ETA: 27:56 - loss: 5.9624 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1226/1615 [=====================>........] - ETA: 27:48 - loss: 5.9623 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1228/1615 [=====================>........] - ETA: 27:39 - loss: 5.9620 - accuracy: 0.1310\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1230/1615 [=====================>........] - ETA: 27:31 - loss: 5.9618 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1232/1615 [=====================>........] - ETA: 27:22 - loss: 5.9613 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1234/1615 [=====================>........] - ETA: 27:14 - loss: 5.9613 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1236/1615 [=====================>........] - ETA: 27:05 - loss: 5.9605 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1238/1615 [=====================>........] - ETA: 26:56 - loss: 5.9606 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1240/1615 [======================>.......] - ETA: 26:48 - loss: 5.9609 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1242/1615 [======================>.......] - ETA: 26:39 - loss: 5.9606 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1244/1615 [======================>.......] - ETA: 26:31 - loss: 5.9610 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1246/1615 [======================>.......] - ETA: 26:22 - loss: 5.9617 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1248/1615 [======================>.......] - ETA: 26:13 - loss: 5.9617 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1250/1615 [======================>.......] - ETA: 26:05 - loss: 5.9618 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1252/1615 [======================>.......] - ETA: 25:57 - loss: 5.9618 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1254/1615 [======================>.......] - ETA: 25:48 - loss: 5.9619 - accuracy: 0.1311\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1256/1615 [======================>.......] - ETA: 25:39 - loss: 5.9615 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1258/1615 [======================>.......] - ETA: 25:31 - loss: 5.9615 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1260/1615 [======================>.......] - ETA: 25:22 - loss: 5.9617 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1262/1615 [======================>.......] - ETA: 25:13 - loss: 5.9612 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1264/1615 [======================>.......] - ETA: 25:05 - loss: 5.9614 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1266/1615 [======================>.......] - ETA: 24:56 - loss: 5.9612 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1268/1615 [======================>.......] - ETA: 24:48 - loss: 5.9612 - accuracy: 0.1312\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1270/1615 [======================>.......] - ETA: 24:39 - loss: 5.9605 - accuracy: 0.1313\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1272/1615 [======================>.......] - ETA: 24:31 - loss: 5.9604 - accuracy: 0.1313\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1274/1615 [======================>.......] - ETA: 24:22 - loss: 5.9605 - accuracy: 0.1313\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1276/1615 [======================>.......] - ETA: 24:14 - loss: 5.9607 - accuracy: 0.1313\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1278/1615 [======================>.......] - ETA: 24:05 - loss: 5.9602 - accuracy: 0.1314\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1280/1615 [======================>.......] - ETA: 23:56 - loss: 5.9604 - accuracy: 0.1314\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1282/1615 [======================>.......] - ETA: 23:48 - loss: 5.9613 - accuracy: 0.1313\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1284/1615 [======================>.......] - ETA: 23:39 - loss: 5.9614 - accuracy: 0.1314\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1286/1615 [======================>.......] - ETA: 23:31 - loss: 5.9614 - accuracy: 0.1313\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1288/1615 [======================>.......] - ETA: 23:22 - loss: 5.9616 - accuracy: 0.1313\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1290/1615 [======================>.......] - ETA: 23:13 - loss: 5.9615 - accuracy: 0.1313\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1292/1615 [=======================>......] - ETA: 23:05 - loss: 5.9617 - accuracy: 0.1313\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1294/1615 [=======================>......] - ETA: 22:57 - loss: 5.9617 - accuracy: 0.1313\n",
            "Epoch 6: saving model to ./train_ckpt/cp.ckpt\n",
            "1296/1615 [=======================>......] - ETA: 22:48 - loss: 5.9617 - accuracy: 0.1313"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d7dabab77c2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0msave_weights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     save_freq=2)\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mmodel_ckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_ckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mval_loss\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mmodel_ckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"./train_ckpt/cp.ckpt\"\n",
        "model_ckpt2 = create_model()\n",
        "model_ckpt2.load_weights(checkpoint_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "e8lTDsogO7ic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_en = open('eng_dataset.txt','r')\n",
        "en_iter = iter(file_en)\n",
        "data_test=[]\n",
        "count = 0\n",
        "for line in en_iter:\n",
        "  \n",
        "    if count >=0 and count <10000:\n",
        "      data_test.append(line)\n",
        "      count=count+1\n",
        "print(len(data_test))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ta603YEzCbOV",
        "outputId": "7da370af-4912-4870-e978-1a24ed8b2b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data1.append(\"I don't have all the answers, but you can make a difference in a child's life by sending a gift to The Salvation Army\")\n",
        "file_ouput = open('./output_eng.txt','w')\n",
        "for sentence in data_test:\n",
        "    tok = tokenizer.texts_to_sequences([sentence])[0]\n",
        "    \n",
        "    x_test, y_test = prepare_sentence(tok, maxlen)\n",
        "    x_test = np.array(x_test)\n",
        "    y_test = np.array(y_test) - 1  # The word <PAD> does not constitute a class\n",
        "    p_pred = model.predict(x_test)  # array of conditional probabilities\n",
        "    #print(p_pred)\n",
        "    vocab_inv = {v: k for k, v in vocab.items()}\n",
        "\n",
        "    # Compute product\n",
        "    # Efficient version: np.exp(np.sum(np.log(np.diag(p_pred[:, y_test]))))\n",
        "    log_p_sentence = 0\n",
        "    for i, prob in enumerate(p_pred):\n",
        "        word = vocab_inv[y_test[i]+1]  # Index 0 from vocab is reserved to <PAD>\n",
        "        history = ' '.join([vocab_inv[w] for w in x_test[i, :] if w != 0])\n",
        "        prob_word = prob[y_test[i]]\n",
        "        log_p_sentence += np.log(prob_word)\n",
        "        #print('P(w={}|h={})={}'.format(word, history, prob_word))\n",
        "    #print('Prob. sentence: {}'.format(np.exp(log_p_sentence)))\n",
        "    final_p=np.exp(log_p_sentence)\n",
        "    perp = 1 / final_p\n",
        "    \n",
        "    perp=perp**(float(1/len(tok)))\n",
        "    file_ouput.write(str(perp))\n",
        "    file_ouput.write(\"\\n\")\n",
        "    "
      ],
      "metadata": {
        "id": "iJJ3IRw0jZfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "R45e7fO6jZhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_en = open('eng_dataset.txt','r')\n",
        "en_iter = iter(file_en)\n",
        "data_test=[]\n",
        "count = 0\n",
        "for line in en_iter:\n",
        "  print(line)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7uQ3pPZBdxc",
        "outputId": "ab724a57-2f73-448b-c313-b25af6ce17a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "\n",
            "Perkins does say he's sorry by offering apologies and solicitating future comments.\n",
            "\n",
            "Perkins does apologize: \"Please accept our sincerest apologies, as we hope you keep giving us thoughts as our site grows.\"\n",
            "\n",
            "Perkins offered his sincerest apologies and his hope that you will continue to offer comments. \n",
            "\n",
            "Sometimes committee chairmen do modify hearing transcripts but that is not so in this case because it was checked with a videotape.\n",
            "\n",
            "Committee chairmen do sometimes modify hearing transcripts, but not this time: I checked the transcript against a videotape.\n",
            "\n",
            "Committee chairmen and witnesses do modify transcripts, but not in this case: The hearing transcript was checked against a videotape.\n",
            "\n",
            "Jonathan Rauch replies: Committee chairmen sometimes modify hearing transcripts, but not here: I checked the transcript against a videotape.\n",
            "\n",
            "There are national quotas to ensure that no country can take up more than 7 percent of the annual green-card allocation except for some family-reunification categories. \n",
            "\n",
            "These categories have quotas to ensure that no country can use more than 7% of the annual green-card allocation (with some family exemptions).\n",
            "\n",
            "There are national quotas to ensure that no country can take up more than 7% of the annual green-card allocation (though family-reunification categories are exempted.\n",
            "\n",
            "Within these categories, there are national quotas to ensure that no country can use more than 7 percent of the annual green-card allocation.\n",
            "\n",
            "In these categories, there are to ensure that country can take up more than 7 percent of the green-card allocation (though some family categories are exempted from this).\n",
            "\n",
            "A. A nude granddad on a Honda was arrested on a Thai golf course Sunday.\n",
            "\n",
            "A nude grandpa was arrested on a Thai golf course, in an act the was inspired by an Irish movie about puckish, beer-swilling people.\n",
            "\n",
            "A nude granddad on a Honda was arrested on a Thai golf course Sunday. He inspired by an Irish movie.\n",
            "\n",
            "A nude granddad was arrested on a Thai golf course Sunday, the police say was inspired by a movie about beer-swilling stereotypes.\n",
            "\n",
            "A nude granddad on a Honda was arrested on a golf course Sunday. Police say it was inspired by adorable Irish movie stereotypes.\n",
            "\n",
            "Lagers are the lightly colored and flavored brews that are consumed the most in the U.S.\n",
            "\n",
            "Lagers are light-colored, light flavored brews that make up  most vattage of beer consumption in the US.\n",
            "\n",
            " \"Lagers are light-colored, lightly flavored brews that make up most beer consumed in the United States.\"\n",
            "\n",
            "The LAT, NYT, and WP fronts carry the news that the federal government has decided to try to block the Lockheed-Northrop merger.\n",
            "\n",
            "The LAT, NYT,and WP report that the federal government, as hinted, has decided to try to block the Lockheed-Northrop merger.\n",
            "\n",
            "The federal government has indeed, as it first hinted over a week ago, decided to try to block the Lockheed-Northrop merger.\n",
            "\n",
            "The LAT, NYT, and WP carry the news that the federal government has indeed decided to try to block the Lockheed-Northrop merger.\n",
            "\n",
            "The LAT , NYT , and WP report that the federal government has, as previously hinted, decided to block the Lockheed-Northrop merger\n",
            "\n",
            "UPS losing $30-$50 million a day, and the dispute \"is on its way to becoming the biggest and costliest strike in a generation.\"\n",
            "\n",
            "NYT reports that UPS is losing between $30-$50 million a day, and claims a dispute \"is on its way.\"\n",
            "\n",
            "It's now being reported that the UPS strike could be the biggest and most costliest in a generation.\n",
            "\n",
            "The NYT says UPS is losing $30-$50 million a day, and the LAT says the dispute \"is becoming the costliest strike in years.\"\n",
            "\n",
            "There was none of the corruption immoralities and security risks of Lyndon Johnson's or John F. Kennedy's White Houses.\n",
            "\n",
            "There was none of the corruption like Lyndon Johnson, or gross immoralities and security risks of John F. Kennedy's White House.\n",
            "\n",
            "There was none of the personal corruption which had marked the rule of Lyndon Johnson.\n",
            "\n",
            "Personal corruption during the rule of Lyndon Johnson and the gross immoralities and security risk of JFKs White House were absent.\n",
            "\n",
            "There was no personal corruption like LBJ, let alone the gross immoralities and security risks of JFK's tenure.\n",
            "\n",
            "Ironically, while on hold, Ticketmaster finishes with \"Buying tickets has never been easier\".\n",
            "\n",
            "While on hold, Ticketmaster plugged its online system, finishing with, 'Buying tickets has never been easier.\n",
            "\n",
            "While waiting on hold Ticketmaster plugs its online system with, 'Buying tickets has never been easier.\n",
            "\n",
            "A. writes: \"Ironically, while on hold, Ticketmaster plugged its system, saying 'Buying has never been easier.'\"\n",
            "\n",
            "Comical misogyny comes in a variety of forms, none more impressive than The Man Show , a bikini-clad exercise in frat-boy reassurance that debuts on Comedy Central.\n",
            "\n",
            "Comical misogyny, comes in a variety of forms, none more impressive than The Man Show, a beer-fueled exercise in frat-boy reassurance that debuts on Comedy Central. \n",
            "\n",
            "Comical misogyny, comes in a variety of forms, none more impressive than The Man Show that debuts this week on Comedy Central. \n",
            "\n",
            "Comical misogyny comes in a variety of forms, none more impressive than The Man Show, an exercise in frat-boy reassurance that debuts this week on Comedy Central.\n",
            "\n",
            "Comedy Central's The Man Show is a beer-fueled, bikini-clad frat-boy exercise in comical misogyny that debuts this week.\n",
            "\n",
            "I was born on this side of the Pale, speak the colony's language & am in the 1st winter night in Dublin. I imagine.\n",
            "\n",
            "Born on this side of the Pale, I speak with a forked tongue. But I stand in a winter night in Dublin and imagine\n",
            "\n",
            "I was born on this side of pale, speak with a forked tongue, but I stand in the Dublin dark and frost of night.\n",
            "\n",
            "I was born on this side of the Pale and speak with forked tongue. I stand in a winter night in Dublin and imagine\n",
            "\n",
            "I was born on this side of Pale, I talk with a forked tongue of colony, but I stand in frost of a Dublin night.\n",
            "\n",
            "I'm less genial than other Oklahomans. I trust you won't take the remarks as a reflection on their general temperament.\n",
            "\n",
            "I'm less genial than most Oklahomans. Don't take these remarks as a reflection upon their general temperament.\n",
            "\n",
            "I am sometimes less genial than fellow Oklahomans & trust you wouldnt make remarks as reflection on general temperament\n",
            "\n",
            "I'm sometimes less genial than my fellow Oklahomans, so don't take my remarks as a reflection upon general temperament.\n",
            "\n",
            "Im at times less genial than my fellow citizens, so I hope you wont take the remarks as such a reflection. as contrary\n",
            "\n",
            "Chides Mayor Giuliani for taking months to deny parade permits to his foes and granting permits to his friends.\n",
            "\n",
            "Mayor Giuliani to deny parade permits to his foes while granting permits to those whose views he endorses. \n",
            "\n",
            "Chides New York Mayor Giuliani for taking months to deny foes parade permits while granting permits to his friends.\n",
            "\n",
            "Chides Giuliani for taking months to deny permits to his foes while swiftly granting permits to those he endorses.\n",
            "\n",
            "Chides Giuliani for taking months to deny permits to foes while granting permits to those whose views he endorses.\n",
            "\n",
            "Prudie thinks that if this is the boy's only negative, you should learn to deal with it and hope that his maturing will ameliorate your problem.\n",
            "\n",
            "Prudie thinks that if this is the young lad's only negative, you should learn to roll with the punches and hope that his maturing will help.\n",
            "\n",
            "Prudie thinks that if this is the young lad's only negative, he should learn to roll with the punches. Maturing will ameliorate his problems.\n",
            "\n",
            "Prudie thinks that if this is the lad's only negative, you should roll with the punches and hope that his maturing will ameliorate your problem.\n",
            "\n",
            "Prudie thinks, overall, that if this is the young lad's only negative, you should learn to roll with the punches (or burgers, in your case).\n",
            "\n",
            "The Wall Street Journal reports that of 1000 surveyed, 46% would move next to their in-laws for a 50% pay raise.\n",
            "\n",
            "The Wall Street Journal reports that adults would move near their in-laws for a pay raise according to a survey.\n",
            "\n",
            "The \"Work Week\" reports, \"In a survey of 1,000 adults, 46% said they would move to their in-laws for a 50% raise.\"\n",
            "\n",
            "The Wall Street Journal \"Work Week\" column said 46% of people would move next to their in-laws for a %50 pay raise.\n",
            "\n",
            "Wall Street Journal: \"In a survey of 1,000, 46% said they would move next to their in-laws for a 50% pay raise.\"\n",
            "\n",
            "'Mannesmann, Under Attack, Looks to France.' Praying that the grandson of Petain is running some French telecom giant.\"\n",
            "\n",
            "Headline: 'Mannesmann, Under Attack, Looks to France.' Presumably praying that Petain's grandson is running a telecom.\n",
            "\n",
            "4. \"Best headline: 'Mannesmann, Under Attack, Looks to France.' A pray that the grandson runs a French telecom giant.\"\n",
            "\n",
            "Headline of the week: 'Mannesmann, Under Attack, Looks to France.'\n",
            "\n",
            "The newest columns are here: posted Tuesday, Oct.27, and Friday, Oct. 23.\n",
            "\n",
            "If you missed the recent portions of this column, here they are: posted Oct. 27 and 23\n",
            "\n",
            "If you missed the recent column installments, here they are: posted Oct. 27 and Oct. 23.\n",
            "\n",
            "The column's most recent installment was posted on Friday Oct 23 and Tuesday Oct 27.\n",
            "\n",
            "Here are the recent installments of this column: posted Tues, Oct. 27, and Fri, Oct. 23.\n",
            "\n",
            "let's assume FBI tests show there is DNA on the dress: Should Starr tell the president before Aug. 17?\n",
            "\n",
            "What if FBI tests show there is DNA on the dress: Should Starr tell the president this before Aug. 17?\n",
            "\n",
            "Let's assume FBI tests show DNA on the dress: Should Starr tell the president before Aug. 17?\n",
            "\n",
            "Let's assume FBI tests show there is DNA on the dress: Should Starr tell the president this?\n",
            "\n",
            "Assume FBI tests show DNA on the dress: Should Starr tell the president before Aug. 17?\n",
            "\n",
            "Carl Reiner thought he was praising the late Lucille Kallen, a writer, who died last Monday at 76.\n",
            "\n",
            "Carl Reiner was praising Lucille Kallen, a Sid Caesar's Your Show of Shows writer, who died at 76.\n",
            "\n",
            "Reiner thought he was praising Lucille Kallen, a writer for Your Show of Shows, who died Monday.\n",
            "\n",
            "Carl Reiner thought he was praising the late Lucille Kallen who died last Monday at 76.\n",
            "\n",
            "c) Clint assumed Wiley and Lewinsky would stay silent, and be found, because his women usually do.\n",
            "\n",
            "c) Clinton knew they would find Willey and Lewinsky but that they would stay silent.\n",
            "\n",
            "Clinton assumed they would find Willey and Lewinsky but also assumed the two would stay silent.\n",
            "\n",
            "Clinton assumed they'd find Willey & Lewinsky but assumed they would stay silent because they usually do.\n",
            "\n",
            "Farewell to you, my wonted waking dreams;Farewell, sometimes enjoyed, eclipsed are thy beams;Farewell, thoughts which quietness brings forth; and farewell, friends league.\n",
            "\n",
            "Farewell to you, my hopes; Farewell, self-pleasing thoughts which quietness brings forth; And farewell, friendship's sacred league, uniting minds of worth. \n",
            "\n",
            "Farewell my hopes, my dreams; sometimes enjoyed joy, eclipsed are thy beams; thoughts which quietness brings forth; friendship's sacred league, uniting minds of worth.\n",
            "\n",
            "Farewell, sometimes enjoyed joy, eclipsed are thy beams;Farewell, self-pleasing thoughts which quietness brings forth\n",
            "\n",
            "Farewell my hopes, my waking dreams, my eclipsed joy and self-pleasing thoughts, which brings quietness forth. And farwell my uniting friendship's sacred league.\n",
            "\n",
            "UPN's potential hit, Shasta McCrackhead, is tamed into the dull Shasta McNasty; just look at the ratings. \n",
            "\n",
            "Shasta McCrackhead, is tamed into dull Shasta McNasty. Look where it is in the ratings now.\n",
            "\n",
            "In 1999 UPN's breakout hit, Shasta McCrackhead is tamed into dull Shasta McNasty resulting in drop in ratings.\n",
            "\n",
            "1999: UPN's possible breakout hit Shasta McCrackhead is tamed into dull Shasta McNasty. Look where it is now.\n",
            "\n",
            "1999: UPN's hit, Shasta McCrackhead, is tamed into the disastrously dull Shasta McNasty. Look at the ratings.\n",
            "\n",
            "The evidence also includes strongly corroborative statements made to me by two of Jones' friends.\n",
            "\n",
            "The evidence also includes strongly corroborative statements from two of Jones' friends, complete with specifics consistent with her allegations.\n",
            "\n",
            "The evidence includes corroborative statements made to me by two of Jones' friends, complete with detailed, specifics consistent with Jones.\n",
            "\n",
            "The evidence includes statements made to me by two of Jones' friends, complete with specifics remarkably consistent with Jones' allegations.\n",
            "\n",
            "The evidence includes strongly corroborative statements made by two of Jones' friends, complete with specifics consistent with Jones' allegations.\n",
            "\n",
            "Businesses spend money on TV commercials: The Lewinsky picture is an input into the provision of ad services that corporations will pay for.\n",
            "\n",
            "Businesses spend money to show commercials on network tv: The picture of Lewinsky is just an input of advertising that corporations will pay for.\n",
            "\n",
            "Businesses spend money to show commercials on television. Lewinsky's pictures show how much corporations are willing to pay for advertising.\n",
            "\n",
            "Businesses spend money to show commercials on TV: The picture of Lewinsky is just an input in the provision of advertising that corps will pay for.\n",
            "\n",
            "Businesses spend money to show commercials on television: The picture of Lewinsky is just an input that corporations are willing to pay for.\n",
            "\n",
            "I miss the headlines in the Post, but I think I have to leave the reasons for that.\n",
            "\n",
            "I miss the Post headlines, but I will leave the reasons for that until the Tylenol works.\n",
            "\n",
            "I miss the headlines in the Post, but I have to wait until the Tylenol kick in to explain.\n",
            "\n",
            "I miss the Post's headlines, but I have no reasons for that until the Tylenol kick in.\n",
            "\n",
            "I miss the headlines, but I have to leave the reasons for that until the Tylenol kick in. \n",
            "\n",
            "George W. Bush endured a dark night when his father's approval rating fell to 38.\n",
            "\n",
            "George W. Bush was disturbed when his father's approval rating fell from 92 to 38.\n",
            "\n",
            "Bush endured a dark night as he watched his father's ratings fall from 92 to 38.\n",
            "\n",
            "George W. Bush was upset when his father's approval rating fell from 92 to 38.\n",
            "\n",
            "George W. Bush was saddened by his father's approval rating fall from 92 to 38.\n",
            "\n",
            "I'm as guilty an anyone overhyping The Sopranos. I just wrote that it's the best TV show.\n",
            "\n",
            "I'm also guilty of overhyping The Sopranos. I recently wrote that it is the best show ever.\n",
            "\n",
            "I am just as guilty of overhyping The Sopranos by writing it's the best TV show ever.\n",
            "\n",
            "I know I'm guilty for overhyping The Sopranos. I recently wrote that it is the best TV show.\n",
            "\n",
            "I'm guilty of overhyping The Sopranos. I just wrote that The Sopranos is the best TV show ever.\n",
            "\n",
            "Why did our emperor get up so early in state, wearing the crown?\n",
            "\n",
            "Why did our emperor get up so early, and is he sitting enthroned at the city's main gate?\n",
            "\n",
            "Why did our emperor get up, and why is he sitting at the city's gate wearing the crown?\n",
            "\n",
            "Why did our emperor get up early and why does he sit at the city's gate with the crown?\n",
            "\n",
            "According to the USAT \"Snapshot,\" California expects half of its home phone traffic be PC not voice by 2001.\n",
            "\n",
            "California expects to have half of its home phone traffic be PC rather than voice by 2001.\n",
            "\n",
            "By 2001, USAT \"Snapshot\" predicts that California expects half of home phone traffic to be PC rather than voice \n",
            "\n",
            "The USAT \"Snapshot\" reports California expects 50% of its home phone usage to be PC rather than voice by 2001.\n",
            "\n",
            "According to the USAT \"Snapshot,\" California expects PC to be half of its home phone traffic by 2001.\n",
            "\n",
            "The questions illustrate the inadequacy of the budget program not with the president.\n",
            "\n",
            "I raise these questions not to disagree with the president's program, but to illustrate the inadequacy.\n",
            "\n",
            "I raise these questions to illustrate the inadequacy of the budget, not to disagree with the president's program.\n",
            "\n",
            "I raise these questions to illustrate the inadequacy of the budget as an explanation of it. \n",
            "\n",
            "Anew version of the annoying yet popular toy, and a candidate from the awkward political family are courting acclaim.\n",
            "\n",
            "A new version of the annoying, popular toy and a new presidential candidate are courting acclaim.\n",
            "\n",
            "A version of the annoying toy and new candidate for president from a strange but enduring family are courting acclaim.\n",
            "\n",
            "A new version of the annoying yet popular toy and a new presidential candidate are aggressively courting acclaim.\n",
            "\n",
            "The evolutionary process will favor moral intuitions that best spread the genes responsible--independent of behavior that is Good.\n",
            "\n",
            "The evolutionary process will favor those that best spread genes-independent of whether they induce behavior that is Good.\n",
            "\n",
            "The evolution process will favor those moral intuitions, whether they induce behavior that is objectively Good.\n",
            "\n",
            "Evolution will favor moral intuitions that best spread their genes, whether or not they induce behavior that is objectively Good.\n",
            "\n",
            "The evolutionary process favors moral intuitions spreading the best genes responsible free of inducing behavior that is objectively good.\n",
            "\n",
            "Capitalism fueled Seattle's renaissance, while it's former lull was caused by poor economic policies of its other tenants: Indians, Scandinavians, and hippies.\n",
            "\n",
            "Seattle's renaissance is fueled by aggressive capitalists, its previous stagnation was caused by the economic policies of its other tenants. \n",
            "\n",
            "Seattle's previous stagnation was caused by the sloth and poor economic policies of the Indians, scandinavians, and hippies.\n",
            "\n",
            "Seattle's renaissance is fueled by capitalists, its previous stagnation was caused by the sloth and bad policies of Indians, Scandinavians, and hippies.\n",
            "\n",
            "So taken are the papers with millennial matters and other pressing stories, that none put on their front news of the major indexes ending the millennium high.\n",
            "\n",
            "The papers with millennial matters and the other stories, that none makes room for the news that all the major indexes ended in nosebleed territory. \n",
            "\n",
            "Papers with millennial matters, that none makes room on the front for news that all major indexes ended the year in nosebleed territory.\n",
            "\n",
            "Papers so taken with millennial matters and other pressing stories, that none front page room for the news that major indexes ended the year poorly.\n",
            "\n",
            "The papers with millennial matters and the other pressing stories, none make room on their front for the news that ended the year/century/millennium.\n",
            "\n",
            "Since the Times started publishing these poems, they has been much comment tending to exonerate Hughes of the blame.\n",
            "\n",
            "There has been much comment tending to exonerate Hughes of the blame often attributed him for Plath's suicide.\n",
            "\n",
            "Since the Times started publishing poems, there has been much comment to exonerate Hughes of the blame for Plath's suicide.\n",
            "\n",
            "Since the Times published these poems, comments tend to exonerate Hughes often attribute him for Plath's suicide.\n",
            "\n",
            "Jazmes Levine ushered a CD by Mozart. It was performed by Placid Domingo and the Metro Opera Orchestra Chorus.\n",
            "\n",
            "Idomeneo by Mozart, performed by Placido Domingo and the Met Opera Orchestra and Chorus; James Levine conductor;\n",
            "\n",
            "Idomeneo performed by Placido Domingo and the Metropolitan Opera Orchestra and Chorus, conducted by James Levine\n",
            "\n",
            "Idomeneo, by Mozart, performed by  Domingo and the Metropolitan Opera Orchestra and Chorus, conducted by Levine.\n",
            "\n",
            "Mozart's Idomeneo, performed by Domingo and the Metropolitan Opera Orchestra and Chorus, conducted by Levine\n",
            "\n",
            "The most ambitious of ending theories is the one of the end of history, advanced by Francis Fukuyama.\n",
            "\n",
            "The most ambitious of the recent ending theories is the theory of the end of history, by Francis Fukuyama.\n",
            "\n",
            "The most ambitious of the ending theories is the theory of the end of history, advanced by Francis Fukuyama.\n",
            "\n",
            "The end of history is the most ambitious theory advanced by Francis Fukuyama, a member of the panel this week.\n",
            "\n",
            "The theory of the end of history, advanced by Francis Fukuyama is most ambitious.\n",
            "\n",
            "Sports are getting crazy when the Olympics look tainted by wretched excess and the Super Bowl is the story of the week. \n",
            "\n",
            "Sports get crazy when the Olympic movement looks tainted by wretched excess and Super Bowl is providing the story of the week.\n",
            "\n",
            "You know sports are crazy when the Olympic movement looks tainted and the Super Bowl is providing the story of the week.\n",
            "\n",
            "A. \"A codger was killed near Bangkok when his motorcycle collided with a bird that police say was 'hurled by a vengeful god.\n",
            "\n",
            "A bare-assed codger was killed near Bangkok this morning, when his motorcycle collided with a bird.\n",
            "\n",
            "A naked codger was killed near Bangkok when his motorcycle collided with a game bird that police say was hurled in his path by god.\n",
            "\n",
            "A bare-assed msn was killed near Bangkok this morning when his motorcycle hit a low-flying bird that police say was thrown by God.\n",
            "\n",
            "The column in Newsweek on the Helsinki summit was barely newsworthy since Russia is so weak.\n",
            "\n",
            "A Helsinki summit column concludes that it had success but not importance, since Russia is weak.\n",
            "\n",
            "Also in Newsweek, a column on the Helsinki summit: it was successful, but Russia is weak.\n",
            "\n",
            "A column on the Helsinki summit concludes that it was successful, since Russia is so weak.\n",
            "\n",
            "Newsweek column on Helsinki's summit says it's successful but, since Russia's weak, not newsworthy\n",
            "\n",
            "The 12-foot Rainmaker kneels with a bow aimed at the heavens to bring down rain.\n",
            "\n",
            "The figure of the Rainmaker kneels with bow aimed at the heavens\n",
            "\n",
            "The Rainmaker kneels with bow and arrow aimed at the heavens bring rain \n",
            "\n",
            "The 12ft figure of the Rainmaker kneels with bow and arrow aimed at heavens.\n",
            "\n",
            "6. \"The figure of the Rainmaker has an arrow aimed at the heavens to bring rain\"\n",
            "\n",
            "Bruce Bagemihl said \"We shouldn't have to look to __________ to see what's normal or ethical.\"\n",
            "\n",
            "Finish quote from Bruce Bagemihl: \"We shouldn't have to look to __________ to see what's normal or ethical.\"\n",
            "\n",
            "Fill in the blank in this quote: \"We shouldn't have to look to __________ to see what's normal or ethical.\"\n",
            "\n",
            "Fill in the blank for Bruce Bagemihl's quote: \"We shouldn't look to __________ to see what's ethical.\"\n",
            "\n",
            "Note: Bob's sobriety is important to us, so please respect our wishes and keep this entire event ALCOHOL-FREE.\n",
            "\n",
            "Bob's sobriety is really important to us, so please respect our wishes and keep this entire event ALCOHOL-FREE.\n",
            "\n",
            "Bob's sobriety is important to us, please respect our wishes, and keep this event alcohol free.\n",
            "\n",
            "Bob's sobriety is something that is important to us. Please respect our wishes and keep this entire event ALCOHOL-FREE.\n",
            "\n",
            "As you know, Bob's sobriety is important to us as a couple, please respect our wishes and keep the event ALCOHOL FREE.\n",
            "\n",
            "The mayor said he was one of the real hopes the Republicans had for regaining control of the United States.\n",
            "\n",
            "He is one of the real hopes that the Republican's have of regaining control of the United States, said the mayor. \n",
            "\n",
            "He is one of the real hopes that [the GOP] has of regaining control of the United States, said the mayor.\n",
            "\n",
            "Mayor in Characteristics military style stated he is real hopes that republican pary has of regaining control of US.\n",
            "\n",
            "He is one of the real hopes the Republican Party has of regaining control of the U.S. said the mayor.\n",
            "\n",
            "The potato-famine campaign, and the historical interpretation has more to do with the present.\n",
            "\n",
            "The potato famine, and it's historical interpretation has more to do with the present than the past.\n",
            "\n",
            "The potato-famine campaign has more to do with the present than the past. \n",
            "\n",
            "The potato-famine campaign, and the interpretation it aims to canonize, has to do with the present.\n",
            "\n",
            "The campaign and the interpretation it aims to canonize, has  to do with the present than the past. \n",
            "\n",
            "Michael Duffy on Washington Week in Review : \"Ken Starr was investigating the White House for investigating him.\"\n",
            "\n",
            "Ken Starr was investigating the White House for investigating Ken Starr for investigating the White House.\n",
            "\n",
            "Michael Duffy on Washington Week stated Ken Starr was investigating white house for investigating him for investigating white house\n",
            "\n",
            "Michael Duffy stated,\" Ken Starr was investigating the White House for investing Ken Starr for investigating the White House.\"\n",
            "\n",
            "Customers that want fast access can replace their modems with high-bandwidth ISDN, T1, and cable modems.\n",
            "\n",
            "Customers who want fast access can replace their modems with ISDN lines, T1 lines, cable modems, and so on.\n",
            "\n",
            "2. Customers who want fast access can replace their modems with ISDN lines, T1 lines, cable modems, etc.\n",
            "\n",
            "Customers who want fast access can replace their modems with ISDN lines, T1 lines, cable modems, etc.\n",
            "\n",
            "Customers who want to ensure fast access can replace their modems with pricey,ISDN, T1 lines, cable modems.\n",
            "\n",
            "A test to determine your comfort level about this matter is to imagine receiving a thank-you note on the Net.\n",
            "\n",
            "A good test for you is to imagine how you would respond to receiving a thank-you note on the Net.\n",
            "\n",
            "Test your comfort level by imagining how you would respond to receiving a thank you note on the Net.\n",
            "\n",
            "A good test for you is to imagine how to respond to receiving a thank you note on the Net.\n",
            "\n",
            "One way to figure out your comfort level is to imagine how you would respond to a thank-you note on the Net.\n",
            "\n",
            "The answer, from Richard Clarke: \"To extort us, to intimidate us, to get us to abandon our foreign policy.\"\n",
            "\n",
            "To extort us, to intimidate us, to get us to abandon our foreign policy. Richard Clarke.\n",
            "\n",
            "The answer from Richard Clarke is: \"To extort us, to intimidate us, to get us to abandon our foreign policy.\"\n",
            "\n",
            "The answer, from Richard Clarke, is: \"To extort us, to intimidate us, to get us to abandon our foreign policy.\"\n",
            "\n",
            "The answer from counterterrorism coordinator Clarke is to extort, intimidate, and get us to abandon our foreign policy\n",
            "\n",
            "If you want officials who put principle ahead of power, voting for women gives better odds.\n",
            "\n",
            "If you want elected officials who put principle ahead of power, voting for women is better. \n",
            "\n",
            "For officials who will put principle ahead of power, voting for women gives better odds.\n",
            "\n",
            "If you want officials who put principle ahead of power, voting for women gives you better odds. \n",
            "\n",
            "If you want elected officials who put principle ahead of power, vote for a women.\n",
            "\n",
            "Andrew Shuman has no idea what he is talking about when question of Java.\n",
            "\n",
            "Shuman has no idea what he is talking about when it comes to the question of Java. \n",
            "\n",
            "The NY and LA Times lead with the sum of years of debate - an agreement to transform American banking laws.\n",
            "\n",
            "The NY and the LA Times lead with the product of much discussion--an agreement to transform American banking laws.\n",
            "\n",
            "The NY Times and the LA Times lead with an agreement to transform American banking laws.\n",
            "\n",
            "The New York Times and the Los Angeles Times lead with an agreement to transform American banking laws.\n",
            "\n",
            "The New York Times and the Los Angeles Times lead with the product of decades and intensive lobbying.\n",
            "\n",
            "I haven't been able to entertain you very often in the past, McCain shot back, giggling.\n",
            "\n",
            "I haven't been able to entertain you very often, McCain said rolling his eyes & giggling.\n",
            "\n",
            "I haven't been able to entertain you very often in the past, McCain giggled.\n",
            "\n",
            "I haven't been able to entertain you very often in the past, McCain shot back.\n",
            "\n",
            "The Shopping Avenger will return to the sorry state at U-Haul, but now on to this month's airline debacle.\n",
            "\n",
            "Shopping Avenger will return to the affairs at U-Haul in the next episode.\n",
            "\n",
            "The Shopping Avenger will return to the state of affairs at U-Haul, but now on to this month's airline debacle.\n",
            "\n",
            "Monopoly Shopping, Mr. Landsburg notes that Windows 95 is $90 and says what would happen if they tried to raise the price.\n",
            "\n",
            "Steven Landsburg notes in \"Monopoly Shopping\" that Windows 95 cost $90 and predicts what would happen with a price increase.\n",
            "\n",
            "In \"Monopoly Shopping,\" Steven Landsburg notes the cost of Windows 95 and what would happen to Microsoft if it raised prices.\n",
            "\n",
            "Steven Landsburg notes that Windows 95 costs about $90 and suggests what would happen to Microsoft if it raised the price.\n",
            "\n",
            "In \"Monopoly Shopping,\" Landsburg says Windows 95 is $90 and suggests what would happen if it tried to raise the price.\n",
            "\n",
            "I hope you don't find this too personal, but I have a dilemma with a relationship.\n",
            "\n",
            "I hope you don't this isn't personal a subject for the public, but I am in a relationship dilemma.\n",
            "\n",
            "Hope this isn't too personal a subject for public consumption, but I have a relationship dilemma.\n",
            "\n",
            "I hope you don't find this too personal or indelicate, but I am in a dilemma about a relationship.\n",
            "\n",
            "Today's Papers wonders when one of Clinton's critics complains that he apologizes for things he didn't do, instead of apologizing for things he did.\n",
            "\n",
            "Due to the slavery speech, \"Today's Papers\" wonders when Clinton's critics complains that he apologizes for what he didn't do, rather than what he did. \n",
            "\n",
            "After the slavery speech, \"Today's Papers\" wonders how long it'll be before one of Clinton's critics complains that he apologizes for the wrong things..\n",
            "\n",
            "This is comforting when listening to advocates describe what will follow if their policies are not adopted.\n",
            "\n",
            "This is a comfort when hearing politicians or editorialists describe pet policies.\n",
            "\n",
            "This is a comfort when listening to people describing the ruin that follows if their policies are not adopted.\n",
            "\n",
            "It's a comfort when you listen to politicians describe what will follow if their pet policies are not adopted.\n",
            "\n",
            "This is comforting when listening to discussion of potential ruin that will follow failure to adopt policies.\n",
            "\n",
            "Moviegoers are told little about why Naboo was invaded, albeit to test with the criteria for wars. \n",
            "\n",
            "Moviegoers are told little why Naboo was invaded, but the few facts we get are credible\n",
            "\n",
            "We don't know why Naboo was invaded, but the facts are credible, but too sparse to test with the criteria for wars.\n",
            "\n",
            "Moviegoers are told little about why Naboo was invaded.  The facts we get are credible, but too sparse for just wars.\n",
            "\n",
            "Our office has been charged by the attorney general with grave responsibilty of determining if there are any wrongdoing by the president of U.S or his people.\n",
            "\n",
            "The attorney general appointed our office to investigate criminal activities by the president of the United States or those assisting him.\n",
            "\n",
            "Our office has been charged by the attorney general with determining if there has been any crime committed by the President or those acting at his direction.\n",
            "\n",
            "Our office has been hired by the attorney general to determine if there has been any criminal wrongdoing by the president or those acting at his direction.\n",
            "\n",
            "Like the waxwings in the juniper, passing the berries back and forth, and by nightfall, wounded with joy.\n",
            "\n",
            "Like the waxwings, 12 at a time, divided, paired, passing the berries around, and at night, wobbling, piping, joyous.\n",
            "\n",
            "Like the waxwings, a dozen at a time, divided, passing the berries back and forth, by nightfall, wounded with joy.\n",
            "\n",
            "Like waxwings in juniper, divided, passing berries back and forth. By nightfall, wobbling and wounded with joy.\n",
            "\n",
            "Like the waxwings in the juniper,  passing berries back and both, and by nightfall, wobbling with joy.\n",
            "\n",
            "While Lindbergh's crossing certainly captured the public imagination, it did little to advance the technology of aviation.\n",
            "\n",
            "While Lindbergh's crossing capture public imagination, it did little to advance the technology of aviation.\n",
            "\n",
            "While Lindbergh's crossing captured the public imagination, it did little to advance the technology of aviation.\n",
            "\n",
            "Lindbergh's crossing captured the public's imagination, but it did little to advance aviation technology.\n",
            "\n",
            "My Victorian grandmama taught me the abbreviation \"messrs\" only when addressing two men with the same surname and address--A Victorian situation.\n",
            "\n",
            "My Victorian grandmama taught me that the abbreviation \"messrs\" is only used when addressing two men with the same surname residing at the same address.\n",
            "\n",
            "My Victorian grandmamma taught me that one uses \"messrs\" (plural of mister) only when addressing two men with the same surname residing at the same address.\n",
            "\n",
            "I was taught that the abbreviation \"messrs\" was only used to address two men with the same surname.\n",
            "\n",
            "At my grandmama's knee I was taught that one uses \"messrs\" (plural of mister) only when addressing two men with the same surname residing at the same address.\n",
            "\n",
            "The characterization of the Oval Office is common only among White house staffers.\n",
            "\n",
            "Spin Cycle, is Howard Kurtz's new book that characterizes the Oval Office.\n",
            "\n",
            "In Spin Cycle, Kurtz says this Oval Office description is common only among White House staffers.\n",
            "\n",
            "According to Spin Cycle, this view of the Oval Office is only among White House staff.\n",
            "\n",
            "Spin Cycle says this characterization of the Oval Office is common among White House staffers.\n",
            "\n",
            "Opening with a female shadow walking away from a \"personnel\" sign, and following her down stairs using a staccato colloquy, the injustice is dramatized.\n",
            "\n",
            "A female silhouette walking away from a \"personnel\" sign, it follows her progress down stairs and uses a staccato colloquy between her colleagues.\n",
            "\n",
            "Opening with a female silhouette walking away from a sign, it follows her progress down a flight of stairs and is a staccato colloquy to show injustice.\n",
            "\n",
            "Opening with a female walking away from a \"personnel\" sign, it follows her downstairs with a staccato colloquy among colleagues to dramatize the injustice\n",
            "\n",
            "Opening with a silhouette walking away from a sign, it follows her progress down stairs and uses a colloquy between her colleagues to dramatize the injustice. \n",
            "\n",
            "In a bureaucratic nonresponse, a political appointee replied, \"I believe that the enclosed memo concerning the study adequately addresses your concerns.\"\n",
            "\n",
            "The enclosed memo concerning the study adequately addresses your concerns a political appointee replied along with a defense prepared by Sedlak.\n",
            "\n",
            "A political appointee responded in a typical bureaucratic manner by enclosing a defense of Sedlak's study and stating that it \"adequately addresses concerns.\"\n",
            "\n",
            "A political appointee replied by sending a defense of the study and stating, \"I believe that the enclosed memo concerning the study addresses your concerns.\"\n",
            "\n",
            "A political appointee replied by enclosing a defense of the study stating, \"I believe that the enclosed memo concerning the study addresses your concerns.\"\n",
            "\n",
            "The the campaign conceals one flaw: The message--that all drug use leads to disaster--is a lie.\n",
            "\n",
            "The slick, pervasive campaign has one flaw: The idea that all drug use leads to disaster is lie.\n",
            "\n",
            "The campaign conceals one flaw: The message--that all drug use leads to disaster--is a baldfaced lie.\n",
            "\n",
            "The slick and pervasive campaign's message, that all drug use leads to disaster, is a baldfaced lie.\n",
            "\n",
            "The slickness of the campaign hides one flaw: \"All drug use leads to disaster\" is a boldfaced lie.\n",
            "\n",
            "As recompense, I am setting down a few quotations that have resonated with me and are not included in that book.\n",
            "\n",
            "As recompense for the pleasure I have got from Bartlett, I am setting down quotations that have resonated with me and are not included in that book.\n",
            "\n",
            "As recompense for the pleasure I got from Barlett, I'm setting down a few quotes that have resonated with  me that aren't included in that book.\n",
            "\n",
            "The Today's Papers asks what it says about Clinton that she won't comment for a story on her partnership with Albright.\n",
            "\n",
            "Today's Papers asks what it says about Mrs. Clinton that she refused to talk about her union with Mrs. Albright.\n",
            "\n",
            "Today's Papers asks about Hillary Clinton's refusal to comment for a story on her Madeleine Albright partnership.\n",
            "\n",
            "Hillary Clinton refused to comment of her partnership with Medeleine Albright in USA Today story July 16.\n",
            "\n",
            "Hillary Clinton refused to comment for USAT on her partnership with Madeleine Albright.\n",
            "\n",
            "The \"Work Week\" column notes a simple position that could encourage high school students to take their classes more seriously. \n",
            "\n",
            "The \"Work Week\" column notes that using high school transcripts in hiring could encourage students to take their classes more seriously.\n",
            "\n",
            "In the WSJ \"Work Week\", the National Association of Manufacturers state that using high-school transcripts in hiring could encourage students.\n",
            "\n",
            "Work Week notes position taken by the National Association of Manufacturers that encourages students to take their classes seriously: use transcripts more in hiring.\n",
            "\n",
            "the WSJ \"Work Week\" column notes a simple position taken by the NAOM that could encourage high school students to take their classes more seriously.\n",
            "\n",
            "The Cardinal turns 80 in January, says spokesman Joseph Zwilling,\"and I think the Cardinal expect this will mark the end of his Archbishop.\"\n",
            "\n",
            "The Cardinal turns 80 in January, says spokesman Joseph Zwilling, \"and many including the Cardinal expect it will mark his archbishopric's end.\"\n",
            "\n",
            "The Cardinal turns 80 in January, says Joseph Zwilling, \"and I think many people including the Cardinal expect that will end his term.\"\n",
            "\n",
            "The Cardinal turns 80 in January, says archdiocese spokesman Joseph Zwilling, \"...many people...expect that will...mark the end of his term...\"\n",
            "\n",
            "And in Case Readme fails to appear for a couple week, best  holiday wishes and thanks to our readers from all of us.\n",
            "\n",
            "In case Readme succumbs to the holiday spirit, best holiday wishes & thanks to our readers from all of us at Slate .\n",
            "\n",
            "In case Readme does not appear for a couple of weeks, best holiday wishes and thanks to our readers from all at Slate.\n",
            "\n",
            "In case Readme succumbs to the holiday spirit and takes a break, best holiday wishes to our readers from Slate .\n",
            "\n",
            "Readme succumbs to holiday spirit and fails to appear for a couple of weeks.\n",
            "\n",
            "Newsweek explains the Titanic phenomenon: Women love di Caprio and the strong, freed heroine; men like the action and glory.\n",
            "\n",
            "Newsweek explains Titanic: Women love Leo and strong, heroines; guys like action and the idea of gentlemen going down with the ship.\n",
            "\n",
            "Women love di Caprio and the liberated heroine; guys like the action and the gentleman going down with the ship.\n",
            "\n",
            "Newsweek explains the Titanic phenomenon: Women love  Leonardo di Caprio; guys like the idea of gentlemen going down with the ship.\n",
            "\n",
            "Newsweek explains the Titanic phenomenon: Women love Leonardo di Caprio & the heroine; guys like action & the idea of noble heroism.\n",
            "\n",
            "Frosh (German for frog) was the 19th century nickname for members of an entering class of German university students.\n",
            "\n",
            "Frosh seems to have come from the German for \"frog\", members of an entering class of German university students.\n",
            "\n",
            "Frosh, from the German for \"frog, was a 19th century nickname for members of an entering class of German university students.\n",
            "\n",
            "Frosh was a 19th century nickname for members of an entering class of German university students.\n",
            "\n",
            "News Quiz seen as lively alternative to canceled NBA season.\n",
            "\n",
            "News Quiz seen as alternative to canceled NBA season, and Pat Ewing mishandles punch line.\n",
            "\n",
            "News quiz is a alternative to canceled NBA season, little risk of Ewing misusing punch line.\n",
            "\n",
            "Patrick Ewing stars in News Quiz, a lively alternative to canceled NBA season.\n",
            "\n",
            "News Quiz was seen with little risk of Patrick Ewing mishandling a key punch line.\n",
            "\n",
            "He refused to leave the group, saying it was merely an advocate for causes such as displaying the Confederate flag and playing \"Dixie\".\n",
            "\n",
            "In January, he refused to leave saying it wasn't racist to display the Confederate battle flag and playing \"Dixie\" at public events.\n",
            "\n",
            "In January, he refused to leave, saying it wasn't racist but an advocate for causes like displaying the Confederate flag and playing \"Dixie\".\n",
            "\n",
            "In January, he had refused to leave the group, saying it was an advocate for causes such as displaying the Confederate battle flag.\n",
            "\n",
            "One truth about Flytrap is that presidential secretary Betty Currie was an honest, loyal civil servant dragooned into a scandal she had nothing to do with.\n",
            "\n",
            "One of the truths about Flytrap is that Betty Currie deserves sympathy: an honest, loyal civil servant dragooned into a scandal she had nothing to do with.\n",
            "\n",
            "A rare widely acknowledged truth about Flytrap is that Betty Currie deserves sympathy: honest, loyal and dragged into a scandal she had nothing to do with.\n",
            "\n",
            "One of the universally acknowledged facts about Flytrap is that Betty Currie deserves our sympathy: an honest, loyal civil servant dragged into a scandal.\n",
            "\n",
            "Betty Currie deserves our sympathy: an honest civil servant wrapped up in something she had nothing to do with.\n",
            "\n",
            "Here is a suggestion: Look at the global picture and stop judgmental postures onto the plane of common sense and compassion.\n",
            "\n",
            "Look at the global picture and step down from ideological and judgmental postures onto the plane of common sense and compassion.\n",
            "\n",
            "I have no answers, only a suggestion: step from judgmental, ideological postures onto the plane of common sense and compassion.\n",
            "\n",
            "I have only a  suggestion: Look at the global picture and step down from ideological postures onto the plane of compassion.\n",
            "\n",
            "Hopefully, your music criticism won't be so pedantic or derisive. To imply that\"Gangsta's Paradise\" is celebrating violence is to admit that you haven't listened to the song.\n",
            "\n",
            "Hopefully your music criticism won't be simple:  To imply that Coolio's \"Gangsta's Paradise\" is celebrating violence.\n",
            "\n",
            "To imply that Coolio's \"Gangsta's Paradise\" is celebrating violence is to admit that you haven't actually listened to the song.\n",
            "\n",
            "You're coming to music criticism wont be derisive or so simplistic that it implies Coolio's Gangsta Paradise is celebrating violence means you have not heard the song.\n",
            "\n",
            "For technical information, answers to questions, and solutions to problems with receiving Slate (or, perchance, to thank our technical staff), e-mail help@slate.com.\n",
            "\n",
            "For technical information, answers to questions, and solutions to problems with receiving Slate  e-mail help@slate.com. \n",
            "\n",
            "For information, answers, and solutions to problems  receiving Slate (or to thank our technical staff for the flawless performance of the site and its products), email help@slate.com.\n",
            "\n",
            "For technical information, answers to questions, and solutions to problems with receiving Slate (or to thank our technical staff), e-mail help@slate.com.\n",
            "\n",
            "The law limits refugees' rights to appeal persecution, and hastens the ejection of those lacking papers.\n",
            "\n",
            "The new law limits refugees' rights and it speeds up the process of ejecting those without papers. \n",
            "\n",
            "The new law limits refugees' rights to appeal, and it speeds up the process of ejecting.\n",
            "\n",
            "The new law limits refugees' rights to appeal individual persecution.\n",
            "\n",
            "The new law limits refugee rights to appeal persecution, and speeds up ejecting those without proper ID.\n",
            "\n",
            "when I received Krugman's letter, I was puzzled: He was complaining that I hadn't referenced others in the increasing-returns field although I had explicitly done so.\n",
            "\n",
            "When I received Krugman's letter after Complexity came out, I was puzzled. He complained that I hadn't referenced others in the increasing-returns field even though I had.\n",
            "\n",
            "When I received Krugman's letter after Complexity came out I was puzzled: He complained that I hadn't referenced others in the increasing-returns field although I had done so.\n",
            "\n",
            "When I received Krugman's letter, I was puzzled: He was complaining that I hadn't referenced others in the increasing-returns field although I had explicitly done so.\n",
            "\n",
            "c) When I received Krugman's letter after Complexity released, I was puzzled: He complained that I hadn't referenced others in the returns field although I had done so.\n",
            "\n",
            "Newsweek previews blockbusters: The Lost World, Men in Black, and Hercules should do well.\n",
            "\n",
            "Newsweek previews the blockbusters: The Lost World , Men in Black, Hercules, and Titanic.\n",
            "\n",
            "Newsweek: blockbusters Lost World, Men in Black, Hercules should do well; Titanic may not.\n",
            "\n",
            "Newsweek previews the summer blockbusters: The Lost World , Men in Black\n",
            "\n",
            "Newsweek reviews movies: The Lost World, MIB, & Hercules should do well; Titanic may sink.\n",
            "\n",
            "The Wall Street Journal 's reports that White House aides are very unhappy that reporters devoted much of a news conference to Clinton's campaign-finance woes.\n",
            "\n",
            "The WSJ'S \"Washington Wire\" reports that White House aides are unhappy that U.S. reporters devoted a Clinton conference with Brazil's president to financing.\n",
            "\n",
            "The \"Washington Wire\" reports that White House aides are unhappy most of a news conference with Brazil's president was devoted to Clinton's campaign finances.\n",
            "\n",
            "The \"Washington Wire\" reports White House aides are unhappy reporters devoted much of a Clinton news conference with Brazil's president to campaign-finance woes.\n",
            "\n",
            "Reminded of Dilbert's boss, outraged to find 40% of company sick days taken on Mondays or Fridays.\n",
            "\n",
            "I'm reminded of Dibert's boss, who was upset that 40% of sick days were taken on Monday or Friday.\n",
            "\n",
            "I'm reminded of Dilbert's boss, who found that 40% of sick days were taken on Mondays or Fridays\n",
            "\n",
            "Dilbert's boss was outraged to find that 40 percent of sick days were taken on Mondays or Fridays.\n",
            "\n",
            "Dilbert's boss was outraged to find that 40% of sick days were being taken on Mondays or Fridays.\n",
            "\n",
            "The Four Statesmen, Gerald Ford, Valery Giscard d'Estaing, James Callaghan and Helmut Schmidt make the strongest argument for the return of the National Endowment.\n",
            "\n",
            "Making the argument for the return of the National Endowment is The Four Statesmen: Gerald Ford, Valery Giscard d'Estaing, James Callaghan, and Helmut Schmidt.\n",
            "\n",
            "Return of National Endowment, the appeal made by the 4 statesmen by 70's political hacks: Gerald Ford, Valery Giscard d'Estaing, James Callaghan & Helmut Schmidt.\n",
            "\n",
            "The Four Statesmen depicted everybody's favorite 70s political hacks by making a strong argument for the return of the National Endowment.\n",
            "\n",
            "The strongest proponents for the return of the National Endowment are The Four Statesmen: Gerald Ford, Valery Giscard d'Estaing, James Callaghan, and Helmut Schmidt.\n",
            "\n",
            "I think you got it, but I'm not sure and I would like to be clear.\n",
            "\n",
            "I think you got it, not sure, and I appreciate your advice I wanted clarity.\n",
            "\n",
            "I think you got it and since I appreciate your advice I wanted to be clear. \n",
            "\n",
            "I wanted to be sure you got it, since I appreciate your weekly advice.\n",
            "\n",
            "I'm not sure you got it but, I appreciate your advice I wanted to be clear.\n",
            "\n",
            "The First Family's visit to Bosnia-Herzogovina leads at the New York Times and is Washington Post's top story.\n",
            "\n",
            "The First Family's visit to Bosnia-Herzogovina tops the New York Times, Los Angeles Times, USA Today and the Washington Post.\n",
            "\n",
            "The First Family's visit to Bosnia-Herzogovina leads in several well-known newspapers.\n",
            "\n",
            "The First Family's visit to Bosnia-Herzogovina  is the top national story at the Washington Post.  \n",
            "\n",
            "The First Family's visit to Bosnia-Herzogovina, leads New York Times, Los Angles Times, USA Today, and Washington Post. \n",
            "\n",
            "Dukakis conceded that the Massachusetts furlough program for murderers sentenced to life imprisonment had been canceled .\n",
            "\n",
            "Dukakis, after reciting statistics, conceded that the furlough program for murderers sentenced to life imprisonment had been canceled \n",
            "\n",
            "Dukakis, after stating statistics, conceded that the Massachusetts furlough program for murderers with life sentences was canceled.\n",
            "\n",
            "Dukakis conceded that the Massachusetts furlough program for murderers sentenced to life imprisonment had been canceled.\n",
            "\n",
            "An uncomfortable Dukakis conceded that the Massachusetts furlough program for murderers sentenced to life imprisonment had been canceled.\n",
            "\n",
            "Participants are invited to submit a domain name that is taken and an amusing alternative.\n",
            "\n",
            "Participants are invited to submit a pair-a domain that is taken along with an available alternative.\n",
            "\n",
            "Participants are invited to submit a taken domain name and an amusing available alternative. \n",
            "\n",
            "Participants are invited to submit a domain name and available alternative.\n",
            "\n",
            "Novak Outs Source: Robert Novak breaks a journalistic commandment by revealing that Watergate special prosecutor Archibald Cox leaked information about his investigations 25 years ago.\n",
            "\n",
            "Robert Novak breaks a journalistic commandment on Capital Gang by revealing that Watergate special prosecutor Archibald Cox leaked information to Novak and other reporters 25 years ago.\n",
            "\n",
            "Robert Novak reveals that Watergate prosecutor Archibald Cox leaked information about his investigations to Novak and other reporters 25 years ago.\n",
            "\n",
            "Robert Novak breaks a journalistic commandment on Capital Gang by revealing that Watergate Archibald Cox leaked information about his investigations to Novak and other reporters.\n",
            "\n",
            "Robert Novak reveiled that Archibald Cox was leaking information to Novak about his investigation and reporters in his background brief 25 years ago.\n",
            "\n",
            "USAT and the NYT report that Newt Gingrich said the Clinton's action was \"petty politics\" even though he promotes line-item veto.\n",
            "\n",
            "Gingrich said that Clinton's action was \"petty politics\" even though he's been a promoter of the line-item veto\n",
            "\n",
            "USAT & NYT reported Newt Gingrich spokeswoman said that Clinton's action was petty politics discussing promotion of line-tem veto.\n",
            "\n",
            "USAT and NYT report that Newt Gingrich said that Clinton's action was \"petty politics\" though he is a promoter of the line-item veto.\n",
            "\n",
            "(Note: \"Life and Art\" is a column that compares fiction with real-life facts on which it is based.)\n",
            "\n",
            "Life and Art is a column that compares fiction with the real-life facts on which it is ostensibly based.\n",
            "\n",
            "The column, \"life and Art,\" compares fiction with real-life facts.\n",
            "\n",
            "(Note: \"Life and Art\" is a column that compares fiction, with real-life facts on which is ostensibly based.\n",
            "\n",
            "(Note: \"Life and Art\", an occasional column, compares fiction with the real-life facts.)\n",
            "\n",
            "Chance that O'Connor could stop by Cinco de Mayo party on way over andmake crude pass at Charlie Rose.\n",
            "\n",
            "O'Connor can stop by Cinco de Mayo, drinking margaritas, passing Charlie Rose.\n",
            "\n",
            "Downside: Chance the O'Connor would party, get intoxicated, and make a pass at Charlie Rose.\n",
            "\n",
            "Downside: O'Connor stops by Cinco de Mayo party, gets tanked on margaritas, make pass at Charlie Rose.\n",
            "\n",
            "In my opinion Patrick Quigley's \"Server Time Out\", shows that he is ignorant of the facts of rural life.\n",
            "\n",
            "Patrick Quigley's 07/23 article, \"Server Time Out,\" illustrates his ignorance of the facts of rural life.\n",
            "\n",
            "Patrick Quigley is simply ignorant of the facts of rural life in his article.\n",
            "\n",
            "The best I can say about Quigley's article, \"Server Time Out,\" is that he is simply ignorant of the facts of rural life.\n",
            "\n",
            "Explaining waht led to her resignation, Schenk said, \"The trouble with Mrs. Grossman is she believed she personally was ____.\" \n",
            "\n",
            "Karl-Heinz Schenk said, \"The trouble with Mrs. Grossmann is, at some point, she began to believe that she personally was _______.\"\n",
            "\n",
            "What led to her resignation, Schenk said, \"The trouble with Mrs. Grossmann is she began to believe that she was _______.\" \n",
            "\n",
            "Explaining what led to her leaving, Karl-Hienz Schenk said, \"The trouble with Mrs. Grossman man was that she believed she was___\n",
            "\n",
            "Karl-Heinz said,\" The trouble with Mrs. Grossman is that she personally was ______.\"\n",
            "\n",
            "Vacco admitted that he was virtually guilty of murdering Barnett Slepian,\"just as if I'd pulled the trigger myself\".\n",
            "\n",
            "Another admission: Vacco said he was guilty of murdering Barnett Slepian, \"just as if I'd pulled the trigger myself.\"\n",
            "\n",
            "Vacco admitted he was virtually guilty of murdering doctor Barnett Slepian, \"just like I'd pulled the trigger myself.\"\n",
            "\n",
            " Vacco acknowledged that he was guilty of murdering Barnett Slepian, \"just as if I'd pulled the trigger myself.\" \n",
            "\n",
            "Vacco acknowledged that he was  completely guilt of the  killing of Buffalo doctor Barnett Slepian.\n",
            "\n",
            "A table with a radio link to the airline's database is being tested in San Francisco and will soon be deployed at three major airports.\n",
            "\n",
            "This table with a radio link to the airline's database will be deployed at LAX, O'Hare, and La Guardia airports after field-testing.\n",
            "\n",
            "This table with link to the airline's database is currently being tested in San Francisco and will soon be used at LAX, ODR, and LGA.\n",
            "\n",
            "This table with a radio link to the database is being tested in San Francisco. It'll soon be deployed at LAX, O'Hare, and La Guardia.\n",
            "\n",
            "This table with a link to the airline's database is being tested and will soon be deployed at LAX, O'Hare, and La Guardia airports.\n",
            "\n",
            "Women on Norplant may be at risk of getting and spreading AIDS as they are less likely to demand their partners use condoms.\n",
            "\n",
            "Women on Norplant may be at greater risk of AIDS, because they will be less likely to demand that their partners use condoms.\n",
            "\n",
            "Girls and women on Norplant are at a greater risk of getting AIDS, because they will be less likely to use condoms.\n",
            "\n",
            "Women on Norplant may be at risk of contracting AIDS, as they will be less likely to demand that their partners use condoms.\n",
            "\n",
            "Hotel Ballroom, produced by Paul Wolfe, Jeff Iorillo, Corey Stolberg, and Robert Gondell.\n",
            "\n",
            "Hotel Ballroom, produced by Wolfe, Iorillo, Stolberg, and Gondell, Cone & Belding in San Francisco.\n",
            "\n",
            "Hotel Ballroom was produced by Paul Wolfe, Jeff Iorillo, Corey Stolberg, and Robert Gondell.\n",
            "\n",
            "Hotel Ballroom, produces by Paul W., Jeff L., Corey S., and Robert G. in San Francisco.\n",
            "\n",
            "Sarah Kerr's questioning of the \"reader-friendliness\" of the Library of America's Gertrude Stein volumes is the most gratuitous grouse.  \n",
            "\n",
            "I can't recall a more gratuitous grouse than Sarah Kerr's questioning, in an estimable piece, of the \"reader-friendliness\" of the Library of America's Gertrude Stein volumes.\n",
            "\n",
            "Sarah Kerr questioned the \"reader-friendliness\" of the Library of America's Gertrude Stein volumes.\n",
            "\n",
            "I cannot recall a more gratuitous grouse than Sarah Kerr's questioning of the \"reader-friendliness\" of the Gertrude Stein volumes (What We Have Is a Failure to Communicate.\n",
            "\n",
            "In its promotional letter, Slate wrote, \"Dear Reader, Monica's dress resurfaced, and Slate is talking.\"\n",
            "\n",
            "In its letter, Slate wrote, \"Dear Reader, Monica's sex dress has resurfaced, and we can't stop talking.\"\n",
            "\n",
            "Slater stated, \"Dear Reader, Monica's sex dress has resurfaced, and Slate can't stop talking about it.\"\n",
            "\n",
            "Slate wrote, \"Dear Reader, Monica's sex dress has resurfaces, and Slate can't stop talking about it.\"\n",
            "\n",
            "The letter read, \"Dear Reader, Monica's sex dress has resurfaced, and Slate can't stop talking about it\"\n",
            "\n",
            "Survivor and spousal benefits under federal programs apply only to a legal spouse?\n",
            "\n",
            "Social Security survivor benefits, and other federal spousal benefits,apply only to a legal spouse, not to an unmarried partner.\n",
            "\n",
            "SS survivor benefits--and spousal benefits under programs like veterans' pensions--apply to the legal spouse, not a partner.\n",
            "\n",
            "Social Security survivor benefits, and spousal benefits under other federal programs, do not apply to an unmarried partner.\n",
            "\n",
            "I didn't watch the Open, if by \"Open\" you mean this tennis thing in Queens; I don't watch sports.\n",
            "\n",
            "I didn't watch the Open in Queens; I don't watch sports, except the very occasional Knicks playoff or World Series Games 4, 5, 6, or 7.\n",
            "\n",
            "I didn't watch this big tennis thing in Queens; I don't watch sports, except the occasional Knicks playoff or World Series Games 4-7.\n",
            "\n",
            "I didn't watch the Open; I don't watch sports, except the very occasional Knicks playoff or World Series Games 4, 5, 6, or 7.\n",
            "\n",
            "I didn't watch the Open, if you mean the tennis thing in Queens; other than Knicks playoffs or World Series 4-7, I don't watch sports.\n",
            "\n",
            "The total number of calories consumed is \"substantially up\" in South Asia, but Africa remains \"a basket case.\"\n",
            "\n",
            "Bailey said the calories are \"substantially up\" in South Asia and the Middle East, but said Africa remains crazy. \n",
            "\n",
            "the total number of calories consumed is \"substantially up\" in South Asia and the Middle East\n",
            "\n",
            "Bailey said South Asia and the Middle East are consuming more calories, while Africa is a \"basket case\". \n",
            "\n",
            "Bailey said the number of calories consumed is up substantially in Asia, but admitted Africa remains a basket case.\n",
            "\n",
            "If my ire at forced part in the SS program is self-pity, then sign me up, if that somehow allows me to get out.\n",
            "\n",
            "Sign me up if my IRE forced participation in the Social Security Program is self pity!\n",
            "\n",
            "If my ire at forced participation in the Social Security program is self-pity, sign me up.\n",
            "\n",
            "I will forgive your East Coast obsessions if you will indulge me in the San Francisco media sport de jour.\n",
            "\n",
            "I'll forgive your East Coast obsessions if you permit me in the current media fad-writing your own obituary.\n",
            "\n",
            "I'll forgive your East Coast obsessions if you indulge me in San Francisco media's craze--writing your obit.\n",
            "\n",
            "I will forgive your East Coast obsession if you indulge me in writing your own obituary.\n",
            "\n",
            "With the eclipse behind us, I'm glad to see you are finding other outlets for your nature appreciation in NYC, even it is limited.\n",
            "\n",
            "I'm glad to see that you are finding other outlets for your nature appreciation in NYC.\n",
            "\n",
            "I'm glad to see you are seeking other outlets for your nature appreciation in NYC, even if it is the coverage of Central Park's poisoned birds.\n",
            "\n",
            "If you drink alcohol, do so in moderation, with meals, and without putting anyone at risk.\n",
            "\n",
            "Drink alcohol moderately, with meals, and when consumption does not put you at risk. \n",
            "\n",
            "Drink alcohol in moderation, with meals, and when consumption does not put anyone at risk.\n",
            "\n",
            "If you drink alcohol, do so in moderation and when consumption does not put people at risk.\n",
            "\n",
            "If you drink alcoholic beverages in moderation, with meals, it does not put others at risk.\n",
            "\n",
            "Though the happy day is distant, Prudie sends congratulations to the couple and tranquil thoughts to their parents.\n",
            "\n",
            "Though the happy day is  months away, Prudie sends congratulations to the young couple.\n",
            "\n",
            "Prudie sends best wishes and congratulations to the young couple and tranquil thoughts to both sets of parents.\n",
            "\n",
            "The happy day is far, yet Prudie sends best wishes to the couple and tranquil thoughts to both sets of parents.\n",
            "\n",
            "Though the happy day is months away, Prudie sends best wishes to the young couple and happy thoughts to them both.\n",
            "\n",
            "White House staffers are contacting members of Congress to see how they would react to a mea culpa.\n",
            "\n",
            "2) Chief of Staff Erskine Bowles is contacting members of Congress to see their reaction to a mea culpa.\n",
            "\n",
            "Two white house stafe members are contacting congress to see how they'd react to a mea culpa.\n",
            "\n",
            "2) White House staffers are contacting members of Congress to see how they would react to a mea culpa .\n",
            "\n",
            "The WP reveals that Clinton's decision to shut down his defense fund was controversy over the fund's implication in shady DNC fund-raising.\n",
            "\n",
            "WP reveals Clinton's decision to shut down defense fund promoted by controversy over fund's implication in DNC fund raising and contributions.\n",
            "\n",
            "The WP reveals that Clinton's decision to shut down his defense fund was prompted by controversy over the fund's implication in shady DNC.\n",
            "\n",
            "The WP stated that Clinton shut down his defense fund due to the fund's role in shady DNC fund-raising practices and by dwindling contributions.\n",
            "\n",
            "The WP reveals Clinton's decision to close his defense fund was prompted by the fund's implication in shady practices and reduced donations.\n",
            "\n",
            "Washington Wire reports that today Republican leaders will unveil a \"horror stories of the IRS\" web site. \n",
            "\n",
            "Wall Street Journal states in the Halloween spirit, Republican leaders will unveil a \"horror stories of the IRS\" site.\n",
            "\n",
            "The \"Washington Wire\" reports that today, Republicans will unveil a \"horror stories of the IRS\" web site.\n",
            "\n",
            "The WSJ \"Washington Wire\" reports that Republican leaders will unveil a \"horror stories of the IRS\" web site.\n",
            "\n",
            "WSJ's \"Washington Wire\" reports today on Halloween that Republican leaders will unveil a IRS horror stories website.\n",
            "\n",
            "Honda has developed a pollution-free gasoline engine that will be as powerful as conventional one without being more expensive.\n",
            "\n",
            "On the front page of USAT, Honda has developed a pollution free gas engine that is just as efficient as conventional ones.\n",
            "\n",
            "Honda has developed a virtually pollution-free gasoline engine that will be as powerful as conventional ones.\n",
            "\n",
            "Honda has developed a virtually pollution-free gas engine that will be as powerful as conventional ones, and not more expensive.\n",
            "\n",
            "A USAT story reports Honda developing an affordable gas engine that is virtually pollution-free, yet as powerful as conventional.\n",
            "\n",
            "Some people scribbled notes on Judge Jackson's findings in the Microsoft antitrust trial.\n",
            "\n",
            "Some thoughts on Judge Thomas Penfield Jackson's findings in the Microsoft trial, a ruling handed an hour ago.\n",
            "\n",
            "Some quickly written thoughts on the Judge's findings in the Microsoft antitrust trial, a ruling decided an hour ago.\n",
            "\n",
            "Some jotted-down thoughts on Judge Thomas Penfield Jackson's findings in the Microsoft antitrust trial.\n",
            "\n",
            "The facts fit the Panglossian economist's vision: Emerging economies run trade deficits, wages rise with productivity, and experience offers no support.\n",
            "\n",
            "Panglossion economists visions say that emerging economies  run trade deficits, wages rise with productivity, and experience offers no support for grim visions.\n",
            "\n",
            "Panglossian economist's vision: Emerging economies do run trade deficits, wages do rise and experience offers no support for grimmer visions.\n",
            "\n",
            "The facts fit the economist's vision: Emerging economies run trade deficits, wages rise with productivity, and experience offers no support for grimmer visions.\n",
            "\n",
            "The consequences of watching Blazing Saddles many times, is that I can't see Lamarr's name without recalling this exchange from that movie: \n",
            "\n",
            "One consequence of watching Blazing Saddles many times is that I can't hear Hedy Lamarr's name without recalling this exchange from that movie:\n",
            "\n",
            "Watching Blazing Saddles so many times at an early age means I can never see Hedy Lamarr's name without recalling this exchange from the movie:\n",
            "\n",
            "One of the consequences of watching Blazing Saddles many times is that I can never see Hedy Lamarr's name without recalling that movie:\n",
            "\n",
            "President Clinton will meet with Yassir Arafat on Thursday, gets into details on the Mideast talks, the WP reports. \n",
            "\n",
            "The WP reports Clinton, who will meet with Arafat, is getting into an unusual amount of detail in the Mideast talks.\n",
            "\n",
            "The WP reports that the President, who meets with Mr. Arafat on Thursday, is going indepth in his Mideast talks.\n",
            "\n",
            "President Clinton, due to meet with Yassir Arafit on Thursday, is being unusually detailed in the latest Mideast talks\n",
            "\n",
            "The WP reports that Clinton, who will meet with Arafat on Thursday, is getting unusually detailed in Mideast talks.\n",
            "\n",
            "Jews for the Preservation of Firearms Ownership has colorful, inexpensive, and sinister assortment holiday cards.  \"America's most aggressive defender of firearms ownership.\"\n",
            "\n",
            "It's not too soon to order holiday cards, there's an assortment available from Jews for the Preservation of Firearms Ownership.\n",
            "\n",
            "Holiday cards from The Jews for the Preservation of Firearms Ownership, are now available for sale.\n",
            "\n",
            "There's a variety of sinister holiday cards now available from Jews for the Preservation of Firearms Ownership, \"America's most aggressive defender of firearms ownership.\"\n",
            "\n",
            "Order those holiday cards now, and there's a huge assortment available from Jews for the Preservation of Firearms Ownership, \"America's best defender of firearms ownership.\"\n",
            "\n",
            "Fordice explains that it's bad for the president to have an affair, but OK for a governor:\n",
            "\n",
            "Fordice explains that the president having an affair is worse than a governors affair.\n",
            "\n",
            "If the president has an affair, it's bad, if the governor of Mississippi has one, it's OK:\n",
            "\n",
            "Fordice: It's bad if the president has an affair, but ok for the governor of Mississippi.\n",
            "\n",
            "Fordice says that the president having an affair is bad but a governor having one is ok.\n",
            "\n",
            "Nobody knows, but Moore and Bailey both admitted that the evidence has grown since 1980. \n",
            "\n",
            "Moore and Bailey both admitted that the evidence for global warming has grown since 1980.\n",
            "\n",
            "Moore and Bailey both have admitted that the evidence for global warming has grown since 1980.\n",
            "\n",
            "Moore and Bailey admitted that evidence for global warming has grown since 1980.\n",
            "\n",
            "Moore and Bailey both grudgingly admitted that evidence for global warming has grown since 1980.\n",
            "\n",
            "This month's tabs are filled with news of an elemental nature, celebrities to marry, into the lives of others, changing them forever. \n",
            "\n",
            "Tabs are filled with news examining the desires of celebrities to marry, divorce, procreate, and swoop into the lives of others.\n",
            "\n",
            "This month's tabs are filled with news of nature, the desire of celebrities, which swoop into the lives of others, changing them forever.\n",
            "\n",
            "News filled with elemental nature, examining celebrities' lives and diving into the lives of others.\n",
            "\n",
            "This month is filled with news of an elemental nature, examining the desires of celebrities.\n",
            "\n",
            "To be fair, the White House wanted to sweeten the Medicare pot by adding a prescription-drug benefit.\n",
            "\n",
            "Thw White House made the Medicare plan better by adding a prescription-drug benefit.\n",
            "\n",
            "The White House added prescription-drug benefits to  Medicare while making cuts at the same time.\n",
            "\n",
            "The White House wanted to sweeten the  pot at the same time it was adding a prescription-drug benefit. \n",
            "\n",
            "The tobacco settlement is dead for now. The Senate isn't in a barter mood, which is what [legislation] requires, says Gwen Ifill.\n",
            "\n",
            "The tobacco settlement is dead for now, says Gwen Ifill. \"The Senate just isn't in a barter mood, which is what [legislation] requires,\"\n",
            "\n",
            "The tobacco settlement is dead for now, says Gwen Ifill, \"The Senate isn't in a barter mood, which is what [legislation] requires.\"\n",
            "\n",
            "The tobacco settlement is dead, says Gwen Ifill. \"The Senate just isn't in a barter mood, which is what [legislation] requires,\" Ifill says.\n",
            "\n",
            "I'm sure it isn't the first time Broadway theatrics crossed onto the sports field.\n",
            "\n",
            "This is not the first time the theatrics of Broadway have gone to the sports field.\n",
            "\n",
            "This isn't the 1st time the theatrics of Broadway have entered the sports field.\n",
            "\n",
            "This is not the first time that theatrics have crossed over to the sports field.\n",
            "\n",
            "During his handling of the Amadou Diallo shooting, Rudolph Giuliani said the NYPD is not the KKK. \n",
            "\n",
            "Giuliani defends his handling of the Amadou Diallo shooting. \"[The NYPD] is not the KKK,\" he says.\n",
            "\n",
            "Rudolph Giuliani defends his handling of the Amadou Diallo shooting to Newsweek.\n",
            "\n",
            "Rudolph Giuliani defends his handling of the Amadou Diallo shooting to Newsweek, \"The NYPD is not the KKK\".\n",
            "\n",
            "Mayor Giuliani defends his handling of the Diallo shooting to Newsweek . \"The NYPD isn't the KKK,\" he said.\n",
            "\n",
            "Before returning to this book for additional nuggets, let me take a breather.\n",
            "\n",
            "Let me take a breather and say a few more words about Bell the man.\n",
            "\n",
            "Let's take a breather and talk about Bell before going back into this slag-heap book for more gold.\n",
            "\n",
            "Before delving back into this book, let me take a breather and say a few more words about Bell the man. \n",
            "\n",
            "Before delving back into this terrible book, let mesay y a few more words about Bell the man. \n",
            "\n",
            "Harford can leave, though he's warned: \"If you make any more inquiries, there'll be dire consequences for you & your family.\"\n",
            "\n",
            "Harford  is given a stern warning \"If you make any inquiries, there will be dire consequences for you and your family.\"\n",
            "\n",
            "Harford is warned:\"If you make any further inquiries, there will be the most dire consequences for you and your family.\"\n",
            "\n",
            "Harford can leave, though he's given a warning: \"If you make any further inquiries, there will be dire consequences.\"\n",
            "\n",
            "Saw the heavens open and riches ready to drop. Beside you, I stood with a strange tense: the spellbound future.\n",
            "\n",
            "You said you saw the heavens open and show riches. Levitated beside you, the spellbound future.\n",
            "\n",
            "You said you saw the heavens open and show riches. I stood subjected to a strange tense: the spellbound future.\n",
            "\n",
            "You said you saw the heavens open with riches ready to drop on us. I stood subjected to the spellbound future.\n",
            "\n",
            "You saw the heavens open and show riches. Levitated beside you, I was subjected to the spellbound future.\n",
            "\n",
            "Foer neglected to mention Mann's credibility is bolstered by the FBI's decision, after an investigation of her charges.\n",
            "\n",
            "Foer also neglected to mention that Mann's credibility is bolstered by the FBI's decision to refer them to the Justice Department.\n",
            "\n",
            "Foer didn't mention that Mann's credibility is bolstered by the FBI's decision to refer them to the Justice Department.\n",
            "\n",
            "Mann's credibility is bolstered by the FBI's decision, which Foer neglected to mention.\n",
            "\n",
            "The house for sale will be converted into a destination vineyard located in the hear of Oregon's burgeoning wine country.\n",
            "\n",
            "The house that's for sale is in Oregon's burgeoning wine country, and this property could be converted into a vineyard.\n",
            "\n",
            "The house for sale is located in the heart of Oregon's burgeoning wine country, ...converted into a small vineyard.\n",
            "\n",
            "The house that is for sale is in the heart of Oregon's wine country, this could be changed into a small vineyard.\n",
            "\n",
            "I don't follow sports, but I am not surprised by the little league story, regarding what we do in the name of sports. \n",
            "\n",
            "I'm never surprised at the lengths we go to in the name of sports. I guess that makes me a bad lesbian.\n",
            "\n",
            "Re: I am never surprised by the lengths we go in the name of sports, which I do not follow closely.\n",
            "\n",
            "I'm never surprised by what we do in the name of sports, which I don't follow closely, making me a bad lesbian.\n",
            "\n",
            "Re: the little league story, I am not surprised by the lengths we go for sports, which I don't follow closely.\n",
            "\n",
            "Headline: Bernstein's review of the Kissinger's memoirs: \"An Architect of Diplomacy Seeks D√©tente with History\"\n",
            "\n",
            "Richard Bernstein's review of Henry Kissinger's latest memoirs \"Architect of Diplomacy Seeks History D√©tente\"\n",
            "\n",
            "Actual headline: \"An Architect of Diplomacy Seeks D√©tente with History\"\n",
            "\n",
            "IRS official states the reform bill is \"going to be the taxpayer's worst nightmare\" because \"shifting the burden will mean more IRS intrusion into taxpayers finances.\"\n",
            "\n",
            "USAT quotes an IRS official as saying, \"The reform bill will be the taxpayer's worst nightmare,shifting the burden will mean more IRS intrusion for the taxpayer.\n",
            "\n",
            "IRS official states the reform bill is \"going to be the taxpayer's worst nightmare\" because \"shifting the burden will mean more intrusion into taxpayer finances.\"\n",
            "\n",
            "The USAT IRS piece quotes an official saying that reform bill is \"going to be a taxpayer's worst nightmare\" because \"shifting the burden means more IRS intrusion.\"\n",
            "\n",
            "The USAT front-page IRS piece quotes an IRS official saying that the reform bill is \"going to be the taxpayer's worst nightmare\" and \"will mean more IRS intrusion.\"\n",
            "\n",
            "Norman said the remark, conformed to a \"degrading racist stereotype of a person of African-American heritage\"\n",
            "\n",
            "Miss Norman said the remark held her to ridicule, mockery, contempt, and to a \"degrading racist stereotype of a person of African-American heritage.\"\n",
            "\n",
            "Miss Norman said the remark made her a subject of ridicule, and mockery, and contempt.\n",
            "\n",
            "Norman said, the remark held her up to ridicule, mockery and contempt and conformed to defrading racist sterotype person of African-American heritage.\n",
            "\n",
            "Miss Norman said the remark held her up to derision, and conformed to a \"degrading racist stereotype of a person of African-American heritage.\"\n",
            "\n",
            "It seems calming to Brodkey's voice to find itself in a \"true\" first person.\n",
            "\n",
            "It's calming to Brodkey's voice to find a \"true\" first person and lucid present tense.\n",
            "\n",
            "It is calming to Brodkey's voice to be in first person and present tense.\n",
            "\n",
            "It is calming to Brodkey's voice to find a \"true\" first person and a present tense.\n",
            "\n",
            "With 20 years of active duty or reseve service who qualify for retired pay at age 60 \n",
            "\n",
            "Those with 20  years of active duty who qualify for retired pay upon retirement at age 60;\n",
            "\n",
            "They qualify for retired pay at age 60 after 20 years of active duty or reserve service.\n",
            "\n",
            "Long timers with 20 years of active duty qualifies for retired pay upon retirement.\n",
            "\n",
            "People with 20 years of active duty or reserve service who qualify for retired pay at 60;\n",
            "\n",
            "He cursed the technician responsible and said, \"If there is any way to do it wrong, he'll find it.\"\n",
            "\n",
            "After finding that a transducer was wired wrong, he cursed the technician responsible.\n",
            "\n",
            "Realizing a transducer was wired bad, he cursed, saying, \"If there's a way to do it wrong, he'll do it.\"\n",
            "\n",
            "After finding a badly wired transducer, he cursed the technician responsible & said, \"He finds a way to do it wrong.\"\n",
            "\n",
            "The thrust portion of the Nixon Library document that interprets Nixon's remarks on \"Jewish Americans\" is to downplay his anti-Semitism.\n",
            "\n",
            "The thrust of the part of the document that interprets Nixon's remarks on \"Jewish Americans\" is to downplay his anti-Semitism.\n",
            "\n",
            "The thrust of the Nixon Library document that interprets his remarks on \"Jewish Americans\" is indeed to downplay his anti-Semitism:\n",
            "\n",
            "The thrust of the portion of the document that interprets Nixon's remarks on \"Jewish Americans\" is to downplay Nixon's anti-Semitism. \n",
            "\n",
            "The thrust of the Nixon Library portion document interpreted Nixon's remarks on Jewish Americans downplayed his comic-book anti-Semitism.\n",
            "\n",
            "Fairness isn't an aim of your electro-rag, but how about an occasional member who stands to the left?\n",
            "\n",
            "Maybe fairness isn't your aim, but how about an committee member who stands left to Atilla the Helms?\n",
            "\n",
            "Fairness isn't an aim of electro-rag, but an occasional committee member who stands at Atilla the Helms\n",
            "\n",
            "Maybe fairness isn't an aim of your electro-rag, but how about a member who stands left of Atilla?\n",
            "\n",
            "The commentariat cleaves the Clinton Scandals into three issues this week: Kathleen Willey, Congress receiving the Kenneth Starr's report and publicizing of Paula Jones' amorous life.\n",
            "\n",
            "The Clinton Scandals are cut into three issues: 1) the storm around Kathleen Willey; 2) Congress' readiness for Kenneth Starr's report; and 3) Robert Bennett's flip on Paula Jones' love life.\n",
            "\n",
            "The issues in the Clinton scandal: Kathleen Willey,  Congress' readiness to receive Kenneth Starr's report and Robert Bennett's publicizing of Paula Jones' amorous life.\n",
            "\n",
            "The commentariat cleaves the Clinton Scandals into 3 issues: 1) the storm surrounding Willey; 2) Congress' readiness to get Starr's report 3) Bennett's about-face on publicizing Jones' life.\n",
            "\n",
            "Commentarial leaves Clinton Scandals into 3 issues: 1.) Kathleen Willey; 2) Congress' readiness to receive Kenneth Starr's report; 3) Robert Bennett's publicizing Paula Jones\n",
            "\n",
            "Does the Chimp Channel describe footprints in a French Cave and is it premiering on TBS tonight?\n",
            "\n",
            "Which describes a footprint in a French cave, and which describes The Chimp Channel, tonight on TBS?\n",
            "\n",
            "Which describes a footprint discovered in a French cave, and The Chimp Channel, tonight on TBS? \n",
            "\n",
            "Which of these descries a footprint in a French cave and which The Chimp Channel, premiering tonight.\n",
            "\n",
            "Which of the following describes a footprint discovered in a cave, and describes The Chimp Channel?\n",
            "\n",
            "8. Will Hillary stick with Bill or ditch him like a hot potato?\n",
            "\n",
            "Will Hillary stick with Bill or not  when he is out of office?\n",
            "\n",
            "Will Hillary stick with Bill or ditch him once he's out of office?\n",
            "\n",
            "Will Hillary stick with Bill or ditch him?\n",
            "\n",
            "Will Hillary stick with Bill or ditch him when he is out of office?\n",
            "\n",
            "LAT reports the two leaders met last night but that the long talks have failed to restart the Middle East peace process.\n",
            "\n",
            "The LAT reports the two leaders met again but also states that the talks failed to restart the Middle East peace process.\n",
            "\n",
            "LAT reports that the 2 leaders met last night but also that the talks have failed to restart the Middle East peace process.\n",
            "\n",
            "The LAT reports the two leaders met again last night, but talks have so far failed to restart the Middle East peace process.\n",
            "\n",
            "Two leaders met last night but also states that the long talks have failed to restart the Middle East peace process.\n",
            "\n",
            "On Sept. 1, school beatings were banned from Britain's private schools.\n",
            "\n",
            "Beatings were banned from Britain's private schools, like state-run schools where caning was outlawed 13 years ago.\n",
            "\n",
            "On Sept. 1, school beatings were banned from Britain's private schools, bringing them up with state-run schools.\n",
            "\n",
            "On Sept. 1, beatings were banned from Britain's private schools, outlawed in state-run schools 13 years ago.\n",
            "\n",
            "Never be caught 15 feet from a Town car if you're a model or not.\n",
            "\n",
            "Even if you're not an Oil of Olay model, I'd hope that you're never caught farther than 15 feet from a Town Car.\n",
            "\n",
            "Even if not an Oil of Olay model, I would hope that you will never be caught farther than 15 feet from a Town Car.\n",
            "\n",
            "Even if you're not an Oil of Olay model I hope that you won't be caught more than 15 feet from a Town Car.\n",
            "\n",
            "In the 19th century, officers frequently had political alignments, Stevens said.\n",
            "\n",
            "Stevens stated that in the 19th century politicians did not have firm party affiliations.\n",
            "\n",
            "In the 19th century officers had political alignments, but didn't favor a single party Stevens said.\n",
            "\n",
            "In the 19th century officers often had political alignments that sometimes shifted, Stevens said.\n",
            "\n",
            "Fordice admits that it was indeed lover Ann Creson who was with him at the wine-heavy lunch that preceded his car crash:\n",
            "\n",
            "Fordice admits that it was Ann Creson who was with him at the wine-heavy lunch that preceded his car crash\n",
            "\n",
            "After pleading memory lapses, Fordice admits it was lover Ann Creson with him at the lunch that preceded his car crash\n",
            "\n",
            "Fordice finally admits that he was with lover Ann Creson at a wine-heavy lunch before his car crash.\n",
            "\n",
            "After having memory lapses, Fordice admits that it was Ann Creson at the wine-heavy lunch that preceded his car crash:\n",
            "\n",
            "Since Prudie \"responds to questions about manners, personal relations, politics\" etc, here's one about politics.\n",
            "\n",
            "Since it is stated that Prudie \"responds to questions about manners and other subjects,\" here's one about politics.\n",
            "\n",
            "Prudie \"responds to questions about manners, personal relations, politics...\" here's one about politics.\n",
            "\n",
            "You're more likely to regret what you did not do than what you did do.\n",
            "\n",
            "If you are like me, you are more likely to regret what you did not do. \n",
            "\n",
            "If you're like me, you'll regret what you didn't do over what you did.\n",
            "\n",
            "You are far more likely to regret what you did not do than what you do. \n",
            "\n",
            "If you're like me, you regret what you did not do than what you do do.\n",
            "\n",
            "The Columbia Journalism Review always will be independent, tough-minded, fair, and impartial in all its judgments.\n",
            "\n",
            "Let me reiterate: The Columbia Journalism Review has and always will be independent, bold, fair, and impartial in all its judgments.\n",
            "\n",
            "This is a good time for me to say the Columbia Journalism Review was, is, & always will be independent, tough, fair, & impartial.\n",
            "\n",
            "Newt Gingrich strongly supported for action against Saddam, while Richard Armey has stressed for prior Congressional review of any attack plan.\n",
            "\n",
            "USAT says Gingrich has signaled support for action against Saddam, while his colleague Armey has stressed the need for review of any attack.\n",
            "\n",
            "USAT says Gingrich has support for action against Saddam, while his colleague Armey has the need for Congressional review of any attack plan.\n",
            "\n",
            "USAT says Gingrich has signaled support for action against Saddam. Armey has stressed the need for prior Congressional review of plans.\n",
            "\n",
            "USAT says Newt Gingrich wants action against Saddam, while Richard Armey stressed the need for prior Congressional review of any attack plan.\n",
            "\n",
            "Los Angeles Times reports that according to a recently released man, Iraqi prisoners have been the site of thousands of executions of political prisoners since late 1997.\n",
            "\n",
            "According to a recently released man, Iraqi prisons have been the site of 100s, perhaps 1000s, of executions of political prisoners and criminals in 1997.\n",
            "\n",
            "Los Angeles Times reports Iraqi prisons have been the site of hundreds of executions of political prisoners and common criminals in the latter part of 1997. \n",
            "\n",
            "The Sunday Times estimates that hundreds, even thousands of political and common prisoners were executed in Iraqi prisons during 1997.\n",
            "\n",
            "Dutch drug dealers hire young Hasidic men flying from Europe to NY to smuggle MDMA.\n",
            "\n",
            "Dutch drug dealers enlisted young Hasidic men flying from Europe to New York to smuggle MDMA (Ecstasy).\n",
            "\n",
            "Dutch drug dealers enlist Hasidic men to fly from Europe to New York to smuggle MDMA (Ecstasy)into United States.\n",
            "\n",
            "Dutch drug dealers enlisted Hasidic men flying from Europe to NY to smuggle MDMA, a drug that causes brain damage.\n",
            "\n",
            "Dutch dealers enlisted Hasidic men to New York to smuggle MDMA, a drug shown to cause brain damage in squirrels.\n",
            "\n",
            "The AFL-CIO has jump-started the protests by lavishing student activists with internships and trips. \n",
            "\n",
            "The AFL-CIO has jump-started anti-sweatshop protests by lavishing student activists with internships and trips to countries with poor working conditions.\n",
            "\n",
            "Time explains why the anti-sweatshop movement is growing: The AFL-CIO has jump-started the protests by giving students with internships and trips to countries.\n",
            "\n",
            "The AFL-CIO sends students to poor countries for internships, and this has helped the anti-sweatshop movement grow on college campuses.\n",
            "\n",
            "Which explanation did NATO spokesman David Wilby give for the attack that killed civilians?\n",
            "\n",
            "How did NATO's David Wilby explain the attack that killed 10 in a residential area of Pristina last week?\n",
            "\n",
            "What reason did NATO's David Wilby give for last week's attack that killed 10 civilians in Pristina?\n",
            "\n",
            "Which explanation did NATO's David Wilby give for an attack that killed 10 Pristina civilians last week?\n",
            "\n",
            "What reason did NATO's David Wilby give for an attack that killed 10 civilians in Pristina last week?\n",
            "\n",
            "Economists have avoided the subject & tended to rationalize that avoidance by asserting that the subject isn't really important anyway.\n",
            "\n",
            "Economists have avoided the subject; and being human, have rationalized that avoidance by asserting that it isn't really important anyway.\n",
            "\n",
            "And so economists have simply avoided the subject by asserting that the subject isn't really important anyway.\n",
            "\n",
            "Naughton forgot that the NCAA system is corrupt, making millions off students who cant accept plane fare from alummi to visit family\n",
            "\n",
            "Naughton has missed that the NCAA system is corrupt, making millions off athletes who can't even accept plane fare from alumni.\n",
            "\n",
            "Naughton fails to realize the NCAA's deep corruption and their exploitation of student athletes.\n",
            "\n",
            "Naughton has missed that the NCAA system is corrupt, making millions off of athletes who can't accept plane fare to visit family.\n",
            "\n",
            "If a plank creaks in the floor, he grabs his pistols and imagines there's a liberal under his bed.\n",
            "\n",
            "If a plank creaks in the floor, he snatches his pistols and imagines there is a liberal hiding. \n",
            "\n",
            "If a plank creaks, he snatches up his pistols and imagines a liberal hiding under his bed.\n",
            "\n",
            "If a floor plank creaks he snatches up his pistols and imagines there is a liberal under his bed.\n",
            "\n",
            "If a plank creaks, he grabs his pistols and imagines there is a liberal hiding under his bed.\n",
            "\n",
            "Do I say \"Excuse me\" to those seated before me in a theater before or after stepping on their feet?\n",
            "\n",
            "While taking a seat at the movies, do I say, \"Excuse me\" before, while, or after I step on their feet?\n",
            "\n",
            "When in a crowded movie theater, do I say, \"Excuse me\" to those seated before or after I step on them?\n",
            "\n",
            "Do I say, \"Excuse me\" in a theater to those already seated before, while, or after I step on their feet?\n",
            "\n",
            "When taking my seat in a theater, do I say, \"Excuse me\" to people, while, or after I step on their feet?\n",
            "\n",
            "Rise of urban politics destroyed big city machines the Mafia used to carry out its rackets\n",
            "\n",
            "The big city machines the Mafia depended on was ruined by the rise of black urban politics.\n",
            "\n",
            "3) The rise of black urban politics destroyed what the Mafia used to perform its rackets.\n",
            "\n",
            "The rise of black urban politics destroyed big city machines the Mafia once depended on.\n",
            "\n",
            "Join me in wishing Moss a speedy return to her health, and Thatcher to her senses.\n",
            "\n",
            "I'm sure you'll all wish Kate Moss to recover, and Margaret Thatcher to her senses.\n",
            "\n",
            "And I'm sure we wish Kate Moss a fast recovery, and Margaret Thatcher to her senses.\n",
            "\n",
            "Join me in wishing Kate Moss a speedy recovery, and Margaret Thatcher to her senses. \n",
            "\n",
            "In \"Tell The Full story, Mr. President\" , the NYT says the statements offered have compounded the case's oddities,\n",
            "\n",
            "The NYT editorial \"Tell the Full Story, Mr. President,\" says the statements offered by Clinton and Jordan have compounded the case's oddities.\n",
            "\n",
            "The NYT, in an editorial slugged \"Tell the Full Story, Mr. President,\" says that the statements by Clinton and Jordan increased the oddities.\n",
            "\n",
            "The NYT editorial said \"Tell the Full Story, Mr. President,\" says that statements by Clinton & Jordan have increased oddities, not stopped them.\n",
            "\n",
            "6. BANGLADESH POLICE CAPTURE DRUG-DEALING MONKEYS Bangladeshi police said they captured two monkeys trained to deliver drugs.\n",
            "\n",
            "Bangladeshi police caught two trained drug delivery monkeys on Monday in the capital of Dhaka.\n",
            "\n",
            "Bangladeshi police said Monday they had captured two monkeys trained to deliver drugs in the capital Dhaka. \n",
            "\n",
            "I would like to suggest a different solution for Dorothy S. on the subject of bad breath.\n",
            "\n",
            "I do realize that you are an expert, but I would suggest a different solution for Dorothy S. about bad breath.\n",
            "\n",
            "I realize you're the expert on advisory things. I'd like to suggest another solution for Dorothy S. for bad breath.\n",
            "\n",
            "Though you're an expert, I'd like to suggest a different solution for the bad breath of Dorothy S.\n",
            "\n",
            "I haven't seen Tim Roth's The War Zone, Hurricane, Any Given Sunday or Errol Morris's Mr. Death.\n",
            "\n",
            "I haven't seen Tim Roth's The War Zone, Hurricane, Any Given Sunday, or Errol Morris's Mr.Death.\n",
            "\n",
            "It could have been, The War Zone, Hurricane, Any Given Sunday or Mr. Death I hadn't seen.\n",
            "\n",
            "Could be a movie I haven't seen: \"The War Zone\", \"Hurricane\", \"Any Given Sunday\", or \"Mr. Death.\"\n",
            "\n",
            "It could have been a movie I haven't seen: The War Zone, Hurricane, Any Given Sunday, Mr. Death.\n",
            "\n",
            "I look forward to reading his nitpickings; I just hope he develops a sense of humor.\n",
            "\n",
            "I await his future nitpickings; I just hope that he forms a sense of humor along the way.\n",
            "\n",
            "I look forward to future nitpickings; hoping that somewhere he develops a sense of humor.\n",
            "\n",
            "Bush: Women who sees U.S. service as a privilege without staining the house.\n",
            "\n",
            "Bush: Women see country service as a privilege and won't stain the house.\n",
            "\n",
            "Women who will see service to our country as a great privilege.\n",
            "\n",
            "Bush: Women who feel priveleged to serve our country and not stain the house.\n",
            "\n",
            "Women who will see service as a great privilege and will not stain the house.\n",
            "\n",
            "A browser loads and displays the home page listed and the image that it refers to.\n",
            "\n",
            "A browser loading page A sees it refers to image B,  loads it and displays both.\n",
            "\n",
            "A browser loading home page A sees that it refers to image Band loads that too.\n",
            "\n",
            "William Saletan showed bias about the Republican condemnation of Clinton administration's actions in Kosovo.\n",
            "\n",
            "Saletan was biased in his piece about Republican condemnation of the Clinton administration's actions in Kosovo.\n",
            "\n",
            "William Saletan showed bias in his piece about the Republican comdemnation of Clinton's actions in Kosovo.\n",
            "\n",
            "William Saletan showed bias in Republican condemnation of the Clinton administration actions of Kosovo.\n",
            "\n",
            "You give the lead, I give the headline from Wednesday's London Mirror.\n",
            "\n",
            "You give leads, I give headlines from Wed's London Mirror: \"He's Huge, Powerful, Fast & Mean\"\n",
            "\n",
            "He's Huge, He's Powerful, He's Fast and He's Mean says headline of London Mirror Wednesday.\n",
            "\n",
            "You give the lead, I give the headline \"He's Huge, He's Powerful, He's Fast and He's Mean.\"\n",
            "\n",
            "An elderly couple next to me started grumbling as I was repeating my reverence for the great director.\n",
            "\n",
            "As I declared and revisited my reverence for the great director, the elderly couple next to me grumbled.\n",
            "\n",
            "Right when I was declaring my reverence for the great director, an elderly couple next to me was grumbling:\n",
            "\n",
            "While I was declaring my reverence for the great director, the elderly couple next to me was grumbling.\n",
            "\n",
            "When I was declaring my reverence for the great director, the elderly couple sitting next to me was grumbling:\n",
            "\n",
            "Are they setting the agenda for the corporate culture like the radical gay movement?\n",
            "\n",
            "Q: \"They're [leading] ... the agenda for corporate culture along the lines of the LGBT movement.\"\n",
            "\n",
            "They're really in the vanguard of setting the agenda for corporate culture of the gay movement.\n",
            "\n",
            "They're really in the vanguard of setting the agenda for the radical gay movement. \n",
            "\n",
            "Top Aides shouted down at 'Town Meeting' on Iraq, \"The Guys are Pumped,\" and a stealth fighter crews massing in Kuwait story are on the Post top-front.\n",
            "\n",
            "Post top-front is striking: \"Top Aides shouted down with \"The Guys are Pumped,\" over a story about the stealth fighter crews massing in Kuwait.\n",
            "\n",
            "The juxtaposition on the Post top-front is striking: \"Top Aides shouted down at 'Town Meeting' on Iraq\" with \"The Guys are Pumped.\"\n",
            "\n",
            "Top Aides shouted down at 'Town Meeting' on Iraq with \"The Guys are Pumped,\" over a story about the crews massing in Kuwait. \n",
            "\n",
            "Top Aides shouted down at the 'Town Meeting' on Iraq next to \"The Guys are Pumped\" over a story about stealth fighter crews in Kuwait. \n",
            "\n",
            "From the Clean Air Act: Polluters who reduce Toxic output can sell the right to molest the environment to others with less environment control.\n",
            "\n",
            "Polluters who reduce their toxic output beyond requirements can sell the right to molest the environment to others.\n",
            "\n",
            "Polluters who reduce their toxic output beyond requirements can sell the right to molest the environment to others less able to control emissions.\n",
            "\n",
            "Polluters who reduce their toxins beyond requirements can sell the right to molest the environment to others less able to control emissions.\n",
            "\n",
            "Let's not forget that in a typical bookstore, you can also--if you choose- acquire books in zero days by going to the store.\n",
            "\n",
            "Let's not forget that in a bookstore, you can also acquire books in zero days, by \"going to\" the store in the sense of actually going there. \n",
            "\n",
            "Let's not forget that in a conventional bookstore, you can also acquire books in zero days through the pre-Internet sense of actually going there.\n",
            "\n",
            "Let's not forget that in a bookstore, you can acquire books in zero days by actually going there.\n",
            "\n",
            "Remember, you can also--if you choose--acquire books in zero days, by \"going to\" the store in the pre-Internet sense of actually going there.\n",
            "\n",
            "Monica may not be what Shakespeare had in mind for his \"dark lady,\" but he offers commentary on her literary endeavor.\n",
            "\n",
            "Shakespeare's \"dark lady\" may have not meant Monica, but his Sonnet 80 does offer commentary on Monica's literary effort.\n",
            "\n",
            "Shakespeare offers some commentary on Monica in Sonnet 80, though she may not be what he pictured for his \"dark lady:\"\n",
            "\n",
            "Monica may not be what Shakespeare concurred when he wrote on his \"dark lady,\" he offers some words on Monica in Sonnet 80.\n",
            "\n",
            "While Monica may not resemble Shakespeare's mental image of the \"dark lady,\" he does offer some commentary on her in Sonnet 80:\n",
            "\n",
            "Although Swiss law require an eight-week leave for new mothers, the Swiss rejected financial assistance for mothers four times since 1945.\n",
            "\n",
            "Although Swiss law requires mothers to take an 8 weeks off, it has rejected assistance for mothers four times since the law was enacted.\n",
            "\n",
            "The Swiss have rejected financial assistance four times since enacting the Maternity Leave Law requiring new moms to take an 8 week leave.\n",
            "\n",
            "Although the maternity leave law requires new mothers to take a leave, the Swiss have rejected aid four times since it was enacted.\n",
            "\n",
            "Although Swiss law requires new mothers to take an eight-week leave, they rejected financial assistance for mothers since 1945. \n",
            "\n",
            "The LAT story is the same as everybody else, although reporting that at one coffee President Clinton says hi to George Steinbrenner before getting to the Fowler story.\n",
            "\n",
            "The LAT coffee tapes story unaccountably reports that at one coffee President Clinton greets George Steinbrenner before getting to the potentially explosive Fowler story.\n",
            "\n",
            "The LAT story has the same basics as everybody else, although reporting the non-news that at one President Clinton says hi to George Steinbrenner before the Fowler story.\n",
            "\n",
            "The LAT coffee tapes story reports the non-news that at one coffee President Clinton says hi to George Steinbrenner before getting to the potentially explosive Fowler story.\n",
            "\n",
            "The LAT coffee tapes story has the same basics as everybody else, although reporting that one coffee President Clinton says hi to George Steinbrenner.\n",
            "\n",
            "sued CBS, alleging the network had broken copyright laws using the \"I Have a Dream\" speech.\n",
            "\n",
            "CBS sued, saying the network violated copyright laws by excepting \"I Have a Dream\".\n",
            "\n",
            "CBS was sued, having allegedly violated copyright laws due to their use of the speech.\n",
            "\n",
            "sued CBS, saying they violated copyright laws by putting \"I Have a Dream\" speech in a show.\n",
            "\n",
            "They sued CBS saying they violated copyright laws by quoting the \"I Have a Dream\" speech.\n",
            "\n",
            "There is no recourse for mailings from places that frequently send material to dogs and toddlers.\n",
            "\n",
            "As for mailing from Publishers Clearing house and others like it, there is no recourse.\n",
            "\n",
            "As for mailings from entities such as Publisher's Clearing house, there is no recourse.\n",
            "\n",
            "To tell you the truth, I don't see any way out of this., he said. \n",
            "\n",
            "To tell you the truth, he sighs, \"I don't see any way out of this.\" \n",
            "\n",
            "To tell you the truth, he sighs, \"I don't see any way out of this.\"\n",
            "\n",
            "tell you the truth, summing up his radio life, \"I don't see any way out\"\n",
            "\n",
            "The popular Family Therapy Network chatroom posting about marijuana included discussion about law, professional responsibility, mental health, addiciton, mind expansion, and children.\n",
            "\n",
            "The Family Therapy Network's popular posting on marijuana prompts a wide-range of adult discussion of law, responsibility, mental health, addiction, mind expansion, and children.\n",
            "\n",
            "In the Family Therapy Network chat room, a posting on marijuana was the most popular ever, prompting an adult discussion of law, mental health, addiction, and above all, children.\n",
            "\n",
            "In the Family Therapy Network chat, a marijuana post was the most popular, fueling a long discussion on law, health, brain, addiction, and children.\n",
            "\n",
            "Chatterbox asked Felt if there was any reason to deny being Deep Throat aside from actually not being Deep Throat. \n",
            "\n",
            "Chatterbox asked Felt if there were any other reason that might impel him to deny he was Deep Throat.\n",
            "\n",
            "Chatterbox asked Felt if there were other reasons, aside from Felt not actually being Deep Throat, that might make him deny it.\n",
            "\n",
            "Chatterbox asked Felt if there were any other reason, besides not actually being Deep Throat, that might impel him to deny he was.\n",
            "\n",
            "Chatterbox, trying not to plead, asked Felt if there was reason aside from Felt's not being Deep Throat, to make him deny it.\n",
            "\n",
            "Or a party of redwings grazing whatfalls--blossom and seed, nutmeat and fruit--made light, swept up, carried downwind, taken ...\n",
            "\n",
            "Or a party of redwings grazing what falls, swept from the ground, carried downwind, taken...\n",
            "\n",
            "Or a party of redwings grazing what falls made light in the head and cut by the swept from the ground, carried downwind, taken. \n",
            "\n",
            "A party of redwings grazing whatfalls made light in the head and cut by the light, swept from the ground, carried downwind, taken \n",
            "\n",
            "Gwen Ifill feels that \"legacy\" - not liberalism - is the L word haunting Clinton's campaign (Washington Week in Review/Meet the Press).\n",
            "\n",
            " Gwen Ifill double dribbled her observation that the L word currently haunting Clinton is \"legacy,\" not liberalism.\n",
            "\n",
            "Gwen Ifill observed that the L word currently haunting Clinton is legacy not liberalism.\n",
            "\n",
            "L Is for Legacy: Gwen Ifill noted that the L word currently haunting Clinton is \"legacy,\" not liberalism.\n",
            "\n",
            "Gwen Ifill made the observation that the L word currently haunting Clinton is \"legacy,\" (Washington Week in Review and Meet the Press).\n",
            "\n",
            "Kinsley thinks it is OK for Washington to take a third of anything.\n",
            "\n",
            "Kinsley thinks it is OK for Washington to take a third of anything this retired historian makes through entrepreneurship.\n",
            "\n",
            "Kinsley thinks it is OK for Washington to take a third of anything this historian labors to make through risk-taking.\n",
            "\n",
            "Kinsley thinks it is OK for Washington to take a third of anything I make through entrepreneurial risk-taking. \n",
            "\n",
            "Kinsley thinks it is OK for Washington to take a 3rd of anything this retired historian labors to make through risk taking.\n",
            "\n",
            "Punditus Interruptus, Week 4: Al Hunt stepped on Robert Novak twice this week making Hunt the leader, 4-2.\n",
            "\n",
            "Al Hunt stepped on Robert Novak twice this week, so Hunt's the interruption leader, 4-2.\n",
            "\n",
            "Al Hunt stepped on Novak twice this week while Novak held his fire, making Hunt the interruption leader. \n",
            "\n",
            "Al Hunt stepped on Robert Novak twice this week, making Hunt the interruption leader, 4-2.\n",
            "\n",
            "Kristol repeated, almost verbatim, in a \"Memo to Bill Bradley\" that appeared in the next issue of Newsweek \n",
            "\n",
            "Kristol repeated this in a \"Memo to Bill Bradley\" that appeared in Newsweek that hit newsstands the next day:\n",
            "\n",
            "Kristol repeated this, almost verbatim, in a \"Memo to Bill Bradley\" that appeared in an issue of Newsweek:\n",
            "\n",
            "Kristol repeated almost the same thing in a \"Memo to Bill Bradley\" that appeared in Newsweek the next day.\n",
            "\n",
            "Kristol repeated this the following day, almost verbatim, in Newsweek's \"Memo to Bill Bradley.\"\n",
            "\n",
            "Bill Parcells said this about the use of instant replay to challenge an official's call, a change for the new National Football League season.\n",
            "\n",
            "New York Jets coach Bill Parcells said a rule change instituted for the new National Football League season that began Sunday.\n",
            "\n",
            "New York Jets coach Bill Parcells said this about the use of instant replay to challenge an official's call, a rule change for the new NFL season.\n",
            "\n",
            "Bill Parcells said this about the use of instant replay to challenge an official's call. \n",
            "\n",
            "If I can go out on a limb here, and bear in mind I'm just speculating--Tina Brown. \n",
            "\n",
            "Grumpy Knicks forward Larry Johnson assesses non-Knicks, and--I'm speculating--Tina Brown.\n",
            "\n",
            "Larry Johnson assesses non-Knicks, and bear in mind I'm just speculating--Tina Brown.\n",
            "\n",
            "Tina Brown said that Knicks Forward Larry Johnson, assesses non-Knicks.\n",
            "\n",
            "That's no more true than saying there's only one standard by which you can call yourself white, Democrat, or any other philosophy or race.\n",
            "\n",
            "That's no more true than saying there is only one standard by which you can call yourself a specific philosophy or race.\n",
            "\n",
            "That‚Äôs just like saying there‚Äôs one standard for being a Catholic, Protestant, Jew, black, white, Republican, Democrat, or anyone else.\n",
            "\n",
            "There is only one standard by calling yourself Catholic, Protestant, Jew, black, white, Republican, Democrat, or etc.\n",
            "\n",
            "There's not one standard you can call yourself; Catholic, Protestant, Jew, black, white, Republican, Democrat.\n",
            "\n",
            "Speaking of Peter Max, I hear he's made a comeback on the 70's bandwagon--he even had a show back in Des Moines.\n",
            "\n",
            "I hear Peter Max has made a comeback on the '70s bandwagon-- he even had some show a few years back in Des Moines.\n",
            "\n",
            "Peter Max had a show years ago in Des Moines, it was a '70s nostalgia comeback.\n",
            "\n",
            "I hear Peter Max has made a sort of comeback on the '70's nostalgia bandwagon--he even had a show in Des Moines.\n",
            "\n",
            "Buena Visa Social club. Trimphant concert by Director Wim Wenders, is also a act of reanimation of culture,city, a way of life.\n",
            "\n",
            "7. The Buena Vista Social Club. A triumphant concert that is a act of reanimation of culture, a city and way of life.\n",
            "\n",
            "The Buena Vista Social Club is a triumphant concert, a reanimation of a culture, a city, a way of life directed by Wim Wenders.\n",
            "\n",
            "7. The Buena Vista Social Club. A triumphant concert that's also a triumphant act of reanimation.\n",
            "\n",
            "The NYT and WP both report that Trent Lott, conservative talk show host, called homosexuality a sin like alcoholism, kleptomania, etc.\n",
            "\n",
            "The NYT and WP both run stories inside reporting that in an interview with a conservative talk show host, Trent Lott called homosexuality a sin.\n",
            "\n",
            "The NYT and WP both run stories reporting that in an interview with a talk show host, Trent Lott called homosexuality a sin.\n",
            "\n",
            "The NYT and WP ran stories that in an interview with Trent Lott, he called homosexuality a sin, like alcoholism, kleptomania and sex addiction.\n",
            "\n",
            "NYT and WP ran stories reporting that in an interview with Trent Lott, called homosexual a sin.\n",
            "\n",
            "John Longhouser , retired after an affair he had had five years ago became public knowledge.\n",
            "\n",
            "Longhouser of the Aberdeen Proving Ground retired after a five year old affair became known.\n",
            "\n",
            "John Longhouser, head of the Aberdeen Proving Ground, retired after an affair became public.\n",
            "\n",
            "Longhouser, head of Aberdeen Proving Ground, retired after an affair became public knowledge. \n",
            "\n",
            "John Longhouser retired after an affair he had had five years ago became public knowledge.\n",
            "\n",
            "Dole: Former aide Alex Castellanos says, \"She's a tough lady; she's as hard as her hairdo.\"\n",
            "\n",
            "Former aide Alex Castellanos says, \"She's a tough lady; she's as hard as her hairdo.\"\n",
            "\n",
            "Dole: Can't tell from the news, but former aide Alex Castellanos says she's a tough lady.\n",
            "\n",
            "Can't tell from news, but Castellanos says,\"She's a tough lady; she's as hard as her hairdo\"\n",
            "\n",
            "The Hard Rock cafe does not serve poorly prepared food; the Hard Rock Cafe has no customers.\n",
            "\n",
            "The Hard Rock Cafe doesn't serve food made with poor ingredients; the Hard Rock Cafe has no customers.\n",
            "\n",
            "The Hard Rock Cafe doesn't serve its customers bad food; the Hard Rock Cafe has no customers.\n",
            "\n",
            "4. During the inauguration, the Clintons had an exchange at Blair house, trading endearments as \"fucking bitch,\" and \"stupid motherfucker.\" \n",
            "\n",
            "On the morning of the '93 inauguration, the Clintons had a talked in front of Blair's house, saying, \"fucking bitch\" & \"stupid motherfucker.\"\n",
            "\n",
            "In 1993, the Clintons had a frank exchange of views, trading such endearments as \"fucking bitch,\" and \"stupid motherfucker.\"\n",
            "\n",
            "On the morning of the inauguration in 1993, the Clintons had a frank exchange, trading words like \"fucking bitch,\" and \"stupid motherfucker.\"\n",
            "\n",
            "He's gone too far and I am no longer \"cool\" about him as president.\n",
            "\n",
            "He has gone too far in his foolish mistakes, and I am no longer cool about him as president.\n",
            "\n",
            "He's gone too far in his foolish mistakes, and I am no longer \"cool\" about him as president.\n",
            "\n",
            "He has gone too far in his mistakes, and I'm no longer \"cool\" about him being president.\n",
            "\n",
            "Al Hunt frames the weekend as a move to get Janet Reno to appoint an independent counsel to investigate campaign finance violations in Chinagate.\n",
            "\n",
            "Liberal Al Hunt frames the weekend's dull center, sending Janet Reno by appointing a counsel to investigate campaign-finance violations.\n",
            "\n",
            "Liberal Al Hunt ( Capital Gang ) frames the weekend's dull center, imploring Janet Reno to get to the bottom of Chinagate\n",
            "\n",
            "Liberal Al Hunt asks Janet Reno to get to the bottom of Chinagate by appointing an independent counsel to investigate violations.\n",
            "\n",
            "Your first paragraphs should be about what you do now and what you did at the White House as a career person and as a political appointee.\n",
            "\n",
            "Your first few paragraphs should be about you, what you do, what you did at the White House, and how long you were the political appointee.\n",
            "\n",
            "The beginning should be about you; what you do, what you did then, and how many years you were a career person and a political appointee.\n",
            "\n",
            "Your first few paragraphs should be about what you do now and did at the White House and how long you were there as a political appointee\n",
            "\n",
            "A little-discussed consequence of the calendar turn is the impact it is likely to have our tradition: the year-in-review survey.\n",
            "\n",
            "A consequence of the pending calendar turn is the impact it is likely to have on one of the more hackneyed journalistic traditions.\n",
            "\n",
            "A consequence of the calendar turn is the impact it is likely to have on the journalistic tradition: year-in-review survey.\n",
            "\n",
            "A consequence of the pending calendar is the impact it will have on the year in review survey.\n",
            "\n",
            "A consequence of the pending calendar turn is the impact it may have on a journalistic tradition: the year-in-review survey.\n",
            "\n",
            "Participants can submit a similar set (a pair)--a domain name that is already taken along with an alternative.\n",
            "\n",
            "Participants are invited to submit a similar set--a domain name that is already taken. \n",
            "\n",
            "Participants are asked to submit sets of amusing and available alternatives for domain names already taken.\n",
            "\n",
            "Humpty Dumpty stated in a cynical tone \"When I use a word it means just what I choose it to mean.\"\n",
            "\n",
            "Humpty Dumpty said, \"When I use a word, it means just what I choose it to mean.\" \n",
            "\n",
            "When I use a word it means just what I choose it to mean, neither more nor less. he said. \n",
            "\n",
            "Humpty Dumpty said, \"When I use a word it means what I choose it to mean--neither more nor less.\"\n",
            "\n",
            "ANGRY MONKEY BITES STEWARDESS IN LATEST CASE OF \"AIR RAGE\" Fed up with lines, cramped seats, service, movies ChiChi ...\n",
            "\n",
            "5. ANGRY MONKEY BITES STEWARDESS IN LATEST CASE OF \"AIR RAGE\" Fed up with travel inconveniences and poor service, ChiChi...\n",
            "\n",
            "5. ANGRY MONKEY BITES STEWARDESS IN LATEST CASE OF \"AIR RAGE\" Fed up with bad service, ChiChi ...\n",
            "\n",
            "Fed up with long lines, cramped seats, indifferent service, and third-rate movies with the hot parts edited out, ChiChi\n",
            "\n",
            ". ANGRY MONKEY BITES STEWARDESS IN LATEST CASE OF \"AIR RAGE\", not satisfied with service\n",
            "\n",
            "Fill in the blank as Chase Untermeyer assesses the new Republican dynasty led by Jeb and George W. \n",
            "\n",
            "Chase Untermeyer assesses the new Republican dynasty led by victorious Jeb and George W.:\n",
            "\n",
            "Former appointments secretary Chase Untermeyer assess the Republican dynasty led by Jeb and George W. Bush.\n",
            "\n",
            "Fill in the blank as Chase Untermeyer assesses the new Republican dynasty led by victorious Jeb and George W\n",
            "\n",
            "The downside would be literacy volunteers being killed during God's wrath on Rupert Murdoch\n",
            "\n",
            "This could be the night Rupert Murdoch feels God's wrath, as hundreds of literacy volunteers could be endangered.\n",
            "\n",
            "Rupert Murdoch could see god's wrath, killing hundreds of literacy volunteers in damage from lightning strike.\n",
            "\n",
            "God's wrath descends on Murdoch, killing hundreds of volunteers in damage from lightning strike. \n",
            "\n",
            "The night that hundreds of volunteers died from a lightning strike could be God's wrath on Rupert Murdoch.\n",
            "\n",
            "Nash and Joe team up with a NYPD Special Crimes Detective to track down a stalker.\n",
            "\n",
            "A)\"Skin Deep\": Nash and Joe team up with a tough-talking Penny Marshall to track down a famous fashion model's deadly stalker.\n",
            "\n",
            "A) \"Skin Deep\": Nash and Joe team up with a tough-talking detective (Penny Marshall) in order to track down a deadly stalker.\n",
            "\n",
            "A) \"Skin Deep\": Nash and Joe team up with a NYPD Special Crimes Detective in order to track down a famous model's stalker.\n",
            "\n",
            "A) \"Skin Deep\": Nash and Joe team up with a tough-talking NYPD detective in order to track down a model's deadly stalker.\n",
            "\n",
            "There was the memory of a holiday party a generation ago in a high neighborhood of the capital\n",
            "\n",
            "The memory of a holiday party a generation ago in a posh neighborhood of the capital leapt to mind.\n",
            "\n",
            "When suddenly, there leapt to mind the memory of a holiday party a generation ago.\n",
            "\n",
            "There leapt to mind the memory of a holiday party in a neighborhood of the nation's capital.\n",
            "\n",
            "There leapt to mind the memory of a holiday party a generation ago in the nation's capital:\n",
            "\n",
            "If you're out of shape, you may consider starting a moderate program of weight training with aerobic exercise. Call Kathy at work if you need some tips.\n",
            "\n",
            "(If you're not in shape, you may want to consider embarking on a weight training program with aerobic exercise-call Kathy at work for tips. \n",
            "\n",
            "If you're not in shape, you may want to embark on a program of weight training, with aerobic exercise--call Kathy at work if you need some tips.\n",
            "\n",
            "(If you're not in shape, consider a moderate program of weight training and aerobic exercise--call Kathy at work for some tips on getting started.)\n",
            "\n",
            " At age 11, \"bet a friend...a dollar versus a chicken that Eisenhower would win\"\n",
            "\n",
            "He \"bet a friend who had a farm, a dollar versus a chicken that Eisenhower would win the election.\"\n",
            "\n",
            "8. Age 11, \"bet a friend a dollar versus a chicken that Eisenhower would win the election.\"\n",
            "\n",
            "8. At age 11, \"bet a friend who had a farm, a dollar vs a chicken that Eisenhower wins the election.\"\n",
            "\n",
            "At 11 I \"bet a friend who had a farm $1 versus a chicken that Eisenhower would win the election.\"\n",
            "\n",
            "A. cuddly memory B. adorable artifact C. precious puffball D. child's stuffed animal E. zoo-confined rarity \n",
            "\n",
            "A. cuddly memory B. adorable artifact C. precious puffball D. stuffed animal E. a zoo-confined rarity\n",
            "\n",
            "A memory, an artifact, a puffball, a child's stuffed animal, or a rarity?\n",
            "\n",
            "A. memory B. adorable artifact C. precious puffball D. child's stuffed animal E. \"a zoo-confined rarity\"\n",
            "\n",
            "cuddly memory; adorable artifact; precious puffball; memories of a stuffed animal; a zoo-confined rarity\n",
            "\n",
            "2 Woman vs. fetus: In the 1980s, the focus shifted to the relative rights of the prospective mother and her fetus.\n",
            "\n",
            "In the '80s the focus of abortion shifted to the rights of the mother and her offspring.\n",
            "\n",
            "In the 1980s, the focus of the abortion controversy shifted to the rights of the mother and her offspring.\n",
            "\n",
            "2 Woman vs. fetus: In the 1980s, abortion controversy shifted to the rights of the mother and her offspring.\n",
            "\n",
            "Woman vs. fetus: In the 1980s, abortion controversy shifted to the rights of the mother and her offspring.\n",
            "\n",
            "Diaz then tells Ellis that unsealed court records show that he was involved in a meth lab, but Ellis pleaded to \"a lesser charge\" that was still a felony.\n",
            "\n",
            "Records show that Ellis was involved in a very large methamphetamine lab manufacturing speed, but that he plead to \"a lesser charge\" that was a felony.\n",
            "\n",
            "Diaz then tells Ellis that unsealed court records show \"that you were involved in making speed,\" but that Ellis pleaded to \"a lesser charge\".\n",
            "\n",
            "Diaz says that unsealed records show \"that you were part of a methamphetamine lab manufacturing speed,\" but that Ellis pleaded to charge that was a felony.\n",
            "\n",
            "Ellis pleaded to a \"lesser charge\" felony after Diaz said unsealed court records show \"that you were involved in a very large meth lab manufacturing speed.\"\n",
            "\n",
            "The heavily decorated, including those who won the Medal of Honor, Distinguished Service Cross, Navy Cross, or Purple Heart;\n",
            "\n",
            "The heavily decorated, including those who won the Medal of Honor, Distinguished Service Cross, Silver Star, or Purple Heart;\n",
            "\n",
            "The decorated include winners of the Medal of Honor, Distinguished Service Cross/Medal, Navy/Air Force Cross, Silver Star & Purple Heart.\n",
            "\n",
            "The heavily decorated, including those who won the Medal of Honor, Distinguished Service Cross, Navy Cross, and many more.\n",
            "\n",
            "The \"Washington Wire\" reports that three suicides by Navy officers in recent months have the service rattled.\n",
            "\n",
            "Washington Wire reports that three separate suicides by Navy officers around Washington have the service rattled.\n",
            "\n",
            "The WSJ \"Washington Wire\" reports that recent Navy officer suicides in and around Washington have the service rattled.\n",
            "\n",
            "Washington Wire, reports three seperate Navy officer suicides, that rattle the service.\n",
            "\n",
            "David Boldt noted that \"Many people saw the editorial as part of an ongoing white conspiracy to carry out genocide of blacks in America.\"\n",
            "\n",
            "Many people saw the editorial as part of an ongoing white conspiracy to carry out genocide of blacks in America,  said David Boldt.\n",
            "\n",
            "Many people, David Boldt, \"saw the editorial as part of an ongoing white conspiracy to carry out genocide of blacks in America.\"\n",
            "\n",
            "Many people, Boldt noted in a subsequent commentary, \"saw the editorial as part of an ongoing white conspiracy to carry out genocide of blacks in America.\"\n",
            "\n",
            "To learn more about the former secretary of State, read The Kissinger Transcripts or visit the National Security Archive Web site. \n",
            "\n",
            "Learn more about the hell-bound former secretary of State by reading The Kissinger Transcripts, or visit the National Security Archive Web site.\n",
            "\n",
            "To learn more about the former secretary of State, read The Kissinger Transcripts or visit the National Security Archive Web site.\n",
            "\n",
            "To learn more about the former secretary of State, read The Kissinger Transcripts , edited by William Burr, or visit http://www.seas.gwu.edu/nsarchive/.\n",
            "\n",
            "To learn more about Kissinger, read The Kissinger Transcripts or visit the National Security Archive Web site at http://www.seas.gwu.edu/nsarchive/.\n",
            "\n",
            "Springer's excuses are halfhearted and contradictory--saying that television doesn't create values, then lecture about value.\n",
            "\n",
            "Springer's excuses are halfhearted and contradictory:he says TV doesn't create values,then lectures his audience about values.\n",
            "\n",
            "Springer's excuses are halfhearted and contradictory--it's not consistent claim TV doesn't create values, then lecture values.\n",
            "\n",
            "Springer's excuses are halfhearted (it's not okay to say that television doesn't create values, then tell your fans about values).\n",
            "\n",
            "For the second time in a week, Congress' performance appears in a NYT paper as \"HEALTH INDUSTRY SEES WISH LIST MADE INTO LAW\"\n",
            "\n",
            "A NYT front-pager about Congress' performance is  frank, appearing under the headline \"HEALTH INDUSTRY SEES WISH LIST MADE INTO LAW.\"\n",
            "\n",
            "NYT front-pager about Congress' performance this year is frank, under the headline \"HEALTH INDUSTRY SEES WISH LIST MADE INTO LAW.\n",
            "\n",
            "Yet again, NYT speaks out on Congress' performance with a front page story: \"HEALTH INDUSTRY SEES WISH LIST MADE INTO LAW.\"\n",
            "\n",
            "Here  are the five major groups for a refresher on harassment law and its history.\n",
            "\n",
            "In descending order of sternness, here are 5 major groups (to see harassment law, click)\n",
            "\n",
            "In descending order of sterness, are five major groups (for a reminder on harassment, click):\n",
            "\n",
            "Here are the five major groups (for a refresher on harassment law and its history, click ):\n",
            "\n",
            "Here are the five major groups (for a refresher on harassment law and its history, click):\n",
            "\n",
            "4)Of the new subsidy, technology is moving so fast that the old regulatory apparatus don't apply to the Internet.\n",
            "\n",
            "4) However well-meaning the new subsidy, technology is moving so fast that the old regulatory apparatus don't apply to the Internet.\n",
            "\n",
            "4) Technology is moving so fast that the old regulations no longer apply to the Internet.\n",
            "\n",
            "Which of these adjectives are from the 1960 Encyclopedia article on beaver, and which appears on New York times describing George W. Bush.\n",
            "\n",
            "Which adjectives are in a New York Times piece about George W. Bush's New Hampshire appearance, and which are from an encyclopedia article on the beaver?\n",
            "\n",
            "Which adjectives appear in a New York Times piece on George W. Bush at his New Hampshire campaign appearance, and which are from the article on the beaver?\n",
            "\n",
            "Which of these adjectives appear in a NYT piece describing Bush at his first NH campaign, and which are from the Encyclopedia article on the beaver?\n",
            "\n",
            "We challenge you to get from the United States Hang Gliding Association site to this page.\n",
            "\n",
            "Leave the United State Hang Gliding Association site and come to this page which tells the hoary marmots location.\n",
            "\n",
            "We challenge you to get from the official US Hang Gliding Association site to this page.\n",
            "\n",
            "We challenge you to get from the United States Hang Gliding Association site to here, which shows the hoary marmots.\n",
            "\n",
            "If I knew you were coming, I would have baked a cake. How did you do?\n",
            "\n",
            "If I knew you were coming', I'd've baked a cake. Howdja do?\n",
            "\n",
            "If I knew you were comin', I'd've baked a cake! Howdja do? Howdja do?\n",
            "\n",
            "If I knew you were comin', I'd've baked a cake (3x) I knew you were comin', I'd've baked a cake Howdja do?(3x)\n",
            "\n",
            "I went down endless dead ends before hitting the right link. I suppose Northwest should have given me a clue.\n",
            "\n",
            "This was difficult, I went down endless dead ends, although I suppose \"Northwest\" should have given me a clue.\n",
            "\n",
            "I went down dead ends before the right link, although I suppose \"Northwest\" should have given me a clue. \n",
            "\n",
            "I hit endless dead ends before finding the right link, although \"Northwest\" should have given me a clue.\n",
            "\n",
            "This is a hard one. I went down dead ends before hitting the right link. \n",
            "\n",
            "Remembering Mr. Shawn's \"New Yorker,\" The Invisible Art of Editing, \"Here But Not Here: A Love Story.\"\n",
            "\n",
            "Books--Remembering Mr. Shawn's \"New Yorker\": The Invisible Art of Editing; Here But Not Here: A Love Story;\n",
            "\n",
            "New Yorker: The Invisible Art of Editing, by Ved Mehta & Here But Not Here: A Love Story, by Lillian Ross.\n",
            "\n",
            "These books remember New Yorker, The Invisible Art of Editing, and Here But Not Here\n",
            "\n",
            "Anne Sheafe Miller was the first person to be saved by the use of penicillin.\n",
            "\n",
            "Mrs. Whozit [her name was Anne Sheafe Miller], the first person ever to be saved by penicillin\n",
            "\n",
            "Mrs. Whozit , the first person ever to be saved by penicillin (Blair Bolles)\n",
            "\n",
            "Anne Sheafe Miller, the first person ever to be saved by penicillin (Blair Bolles)\n",
            "\n",
            "Pass this correction to the author of the segment, along with my appreciation.\n",
            "\n",
            "Pass along this correction to the author of the segment, as well as my appreciation for the writing.\n",
            "\n",
            "Please pass this correction with my appreciation to the author of this segment for its intriguing format.\n",
            "\n",
            "Pass this correction to the author, along with my appreciation for the writing that is being done.\n",
            "\n",
            "Apple said it had already received 150,000 orders for the G4, but that Motorola was not going to be able to produce that many chips.\n",
            "\n",
            "Apple said it had already received 150,000 orders for the G4, but that Motorola wasn't going to be able to produce that many chips.\n",
            "\n",
            "Apple already received 150000 orders for the G4 in three weeks but Motorola was not going to be able to produce that many chips.\n",
            "\n",
            "Apple has received 150,000 orders for the G4 in the last three weeks, but Motorola is not able to produce that many chips.\n",
            "\n",
            "Apple already received 150,000 orders of the G4 since it went on sale, but Motorola can't produce that many chips.\n",
            "\n",
            "Despite contrary opinions, women are advised: the way they dress can put them at risk.\n",
            "\n",
            "In spite of protests, women should know that the way they dress can put them at risk.\n",
            "\n",
            "In spite of protests of the contrary, women should know that how they dress is a risk.\n",
            "\n",
            "Despite protests woman should be awre that the way the dress can put them at risk.\n",
            "\n",
            "The proof put forth for the soul that exists is that the body weighs something less, after death--\n",
            "\n",
            "The proof put forth for the soul is that the body weighs less after death.\n",
            "\n",
            "The proof for the soul as a thing that exists is that the body weighs something less, after death\n",
            "\n",
            "The proof most commonly put forth for the soul having weight is that the body weighs less after death.\n",
            "\n",
            "Proof commonly put forth that the soul exists and has weight is that the body weighs less after death--\n",
            "\n",
            "I can't deny I wanted the Republic of Texas trailer-trash compound standoff  to last longer than it did- for selfish reasons.\n",
            "\n",
            "The truth is, I wanted the standoff at the Republic of Texas trailer-trash compound to last longer than it did.\n",
            "\n",
            "I can't deny it: I wanted the standoff at the Republic of Texas trailer-trash compound to last longer than it did.\n",
            "\n",
            "For selfish reasons, I wanted the standoff at the Republic of Texas to last longer that it did.\n",
            "\n",
            " I desperately wanted the standoff at the Republic of Texas compound to last longer than it did--for selfish reasons. \n",
            "\n",
            "Clinton has the grace to pull off such an apology in a way that doesn't seem phony.\n",
            "\n",
            "2)Even though Clinton will blame it on his own heart, an apology will be said that doesn't seem phony.\n",
            "\n",
            "Clinton has the rhetorical grace to pull off such an apology in a way that doesn't seem phony.\n",
            "\n",
            "2) Clinton has the ability to make an apology not seem phony (he'll blame it on his heart, his desire not to hurt family).\n",
            "\n",
            "Here are the most recent installments of this column: Tuesday, 11/10, and Friday, 11/6.\n",
            "\n",
            "If you missed the recent column, here they are: posted Tuesday,Nov.10, and Friday, Nov. 6\n",
            "\n",
            "If you missed the most recent columns, here they are: posted  Nov. 6 and Nov. 10. \n",
            "\n",
            "If you missed installments of this column here they are: Tuesday, NOV 10, Friday, NOV 8.\n",
            "\n",
            "Here are the recent installments of this column: posted Nov. 10 and Nov. 6.\n",
            "\n",
            "(Note: All Mr. Peanut comments quoted in the Times. All Bob Smith comments come from his Senate speech.)\n",
            "\n",
            "(Note: Mr. Peanut comments come from Times ad guys. Smith comments come from his Senate speech Tues.)\n",
            "\n",
            "(Note: Mr. Peanut comments quoted by ad guys in the Times. Bob Smith comments from his Senate speech.)\n",
            "\n",
            "(Note: All Mr. Peanut comments in the Times. All Bob Smith comments come from his speech Tuesday.)\n",
            "\n",
            "(Note: All Bob Smith comments come from his speech Tuesday in the Senate.)\n",
            "\n",
            "3: While the argument continues, recently the subject of whose judgment counts in the abortion decision has come to the fore.\n",
            "\n",
            "3 Who decides vs. what's done: While argument persists, the question of whose decree counts in the abortion decision comes to the fore.\n",
            "\n",
            "In recent years the question of whose judgment should count in the abortion decision has come to the fore.\n",
            "\n",
            "Who decides vs. what's done: the argument continues, the question of whose judgment should count in the abortion decision has come up.\n",
            "\n",
            "3. Who decides vs. what's done: The question of whose judgment should count in the abortion decision has come to the fore.\n",
            "\n",
            "New Scots MPs took an oath of allegiance to the queen, but they did sing Robert Burns' \"A Man's a Man for A' That.\"\n",
            "\n",
            "The new MPs took an oath of allegiance, but instead of \"God Save the Queen\" they sung Robert Burns' \"A Man's a Man for A' That.\"\n",
            "\n",
            "There was no singing of \"God Save the Queen,\" even though the Scots MPs took an oath of allegiance. \n",
            "\n",
            "The new Scots MPs sang \"A Man's a Man for A' That\" over \"God Save the Queen\", despite swearing allegiance to her.\n",
            "\n",
            "Although the new Scots MPs took an oath to the queen, there was no singing of \"God Save The Queen\" They did sing Robert Burns.\n",
            "\n",
            "Search for articles by authors who have been divorced, have red hair, or voted Republican in at least three elections;\n",
            "\n",
            "Search for articles by those who have divorced, have red hair, or voted Republican in three to five of the past six elections;\n",
            "\n",
            "Search for articles by authors by any identifying qualities that they have.\n",
            "\n",
            "Search for authors who have voted Republican in at least three of the past six elections, have red hair, and have been divorced.\n",
            "\n",
            "Find articles by authors who've been divorced, have red hair, or voted Republican in at least 3 presidential elections;\n",
            "\n",
            "--Senator Mitch McConnell, R-Ky., on John McCain and Bill Bradley's agreement on soft money donations (Meet the Press)\n",
            "\n",
            "Senator Mitch McConnell, on John McCain and Bill Bradley's agreement to forego money donations if they become their presidential nominees\n",
            "\n",
            "Senator Mitch McConnell on John McCain and Bill Bradley's agreement to forego soft money donations if they become presidential nominees\n",
            "\n",
            "Senator Mitch McConnell, R-Ky., on John McCain and Bill Bradley's pact to stop donations if they become presidential nominees (Meet the Press)\n",
            "\n",
            "China will prosecute the leaders of Falun Gong, but will excuse most followers saying they were brainwashed into joining.\n",
            "\n",
            "China will prosecute the leaders of Falun Gong. A government order excused most followers saying they had been brainwashed.\n",
            "\n",
            "China will prosecute leaders of Falun Gong. A government order excused most followers saying they were brainwashed.\n",
            "\n",
            "China to prosecute leaders of Falun Gong. An order excused most followers as they had been brainwashed by the organization.\n",
            "\n",
            "China will prosecute the leaders of Falun Gong, a government order excused followers saying they were brainwashed into joining.\n",
            "\n",
            " Teach you to ask me bullying questions about my past drug use, beanpole.  \n",
            "\n",
            "How many angels can dance on the head of a pin, Senator?\n",
            "\n",
            "SAM: How many angels can dance on the head of a pin, Senator?\n",
            "\n",
            "Teach you to ask me questions about my past drug use:How many angels can dance on the head of a pin?\n",
            "\n",
            "SAM[Don't ask me bullying questions about my past drug use]: How many angels dance on the head of a pin?\n",
            "\n",
            "On the other hand, reformers haven't shown they can win the confidence of the public, which remain wary of legalization of any drug.\n",
            "\n",
            "Reformers have not shown consistent public support, which remains wary of legalization of any drug -- even marijuana.\n",
            "\n",
            "The reformers haven't shown that they can consistently win the public's confidence, which remains wary of legalization of any drug.\n",
            "\n",
            "The reformers show they consistently win the public's confidence, but they remain wary of drug legalization--even marijuana.\n",
            "\n",
            "Reformers have not been able to consistently win the confidence of the public, which remains very wary of legalizing any drug.\n",
            "\n",
            "USAT is the only paper to mention the momentum from Princess Diana's death, who took up the cause shortly before her death.\n",
            "\n",
            "Of everything covering the ban, only USAT says the momentum from the death of Diana, who embraced the cause before dying.\n",
            "\n",
            " USAT mentions the momentum derived from the death of Princess Diana, who embraced the cause  before her death.\n",
            "\n",
            "Of the papers covering the ban today, only USAT mentions the momentum derived from Princess Diana's death.\n",
            "\n",
            "The NYT asked screenwriter John Milius his opinion and he said it sounded just fine to him \n",
            "\n",
            "The New York Times asked filmmaker John Milius for his opinion; he said it sounded just fine to him.\n",
            "\n",
            "New York Times asked John Milius for an opinion, he said it sounded just fine to him.\n",
            "\n",
            "The NY Times asked Milius for his opinion, and he said it sounded just fine.\n",
            "\n",
            "The NYT asked screenwriter John Milius for his opinion, and he said it sounded just fine to him.\n",
            "\n",
            "A WP story reports that tobacco companies spent three times as much on their anti-tobacco bill TV campaign as the health insurance companies did.\n",
            "\n",
            "A WP story reports that tobacco companies spent nearly three times as much on their TV campaign as health insurance companies did on theirs.\n",
            "\n",
            "The WP reports that tobacco companies spent three times as much on their anti-tobacco bill TV ads as health insurance companies did on their spots.\n",
            "\n",
            "A WP story reports that the tobacco companies spent nearly three times on their anti-tobacco bill TV ads as the health insurance companies did on theirs\n",
            "\n",
            "is the grandmother to take along on the Normandy landing where it turned out to have powers and a time of its own\n",
            "\n",
            "The grandmother entrusted her powerful Baedeker to you to take along Normandy Landing.\n",
            "\n",
            "is the grandmother whose Baedeker you brought to Normandy landing where it had powers and a time of its own\n",
            "\n",
            "the grandmother gave you an old Baedeker to take with you, it turned out to have powers a time of its own.\n",
            "\n",
            "The grandmother gave you her old Baedeker to take to Normandy landing where it had powers and a time of its own.\n",
            "\n",
            "Admiring concern for the spouse's self-esteem, peace, and the reputation of the other partner, she points out all are jeopardized by his actions.\n",
            "\n",
            "Prudie admires spouse's self-esteem, family peace, and the illicit partner, she must point out that all are jeopardized.\n",
            "\n",
            "While Prudie admires concern for the spouse's self-esteem, family, and reputation, she point's out all are jeopardized by the illicit actions.\n",
            "\n",
            "Purdie says the spouse's self esteem, peace in the family, and reputation of the illicit partner are because of the \"gentleman's actions\"\n",
            "\n",
            "Michael Kinsley's \"Book Bork, Browser Bork\" says that his stance on Microsoft's antitrust case represents a change from his book on antitrust law.\n",
            "\n",
            "Kinsley's \"Book Bork, Browser Bork\" is right that his current stance on Microsoft's case is a departure from his 20-year-old antitrust law book.\n",
            "\n",
            "Michael Kinsley's \"Book Bork, Browser Bork\" is right, that Robert Bork's posture on the Microsoft antitrust case departs from his book on antitrust law.\n",
            "\n",
            "Michael Kinsley's \"Book Bork, Browser Bork\" is right to say Robert Bork on the Microsoft antitrust case represents a departure.\n",
            "\n",
            "Michael Kinsley's \"Book Bork, Browser Bork\" is right to say that Robert Bork's antitrust case represents a departure from his antitrust law. \n",
            "\n",
            "(To calculate the deal's value, multiply the price of AOL's stock by 1.5, multiply that by Time Warner shares, and add $17 billion.\n",
            "\n",
            "The way to calculate the value is to multiply the AOL's stock price by 1.5, multiply the Time Warner shares, and add $17 billion.\n",
            "\n",
            "To calculate the deal's value, multiply the price of AOL's stock by 1.5, multiply that by Time Warner shares amount, add $17 billion.\n",
            "\n",
            "Calculate the deal by multiplying the price of AOL's stock by 1.5, multiply that by the number of Warner shares, and add $17 billion.\n",
            "\n",
            " I  wish there was more to watch--say, a discussion of microeconomic theory from the American Enterprise Institute.\n",
            "\n",
            "I wish there were better things to watch--say, a discussion of theory by a fellow of the American Enterprise Institute.\n",
            "\n",
            "I wish there were worthwhile things to watch--a microeconomic theory talk by a American Enterprise Institute fellow.\n",
            "\n",
            "I wish there were more things to watch-- a  discussion of microeconomic theory from the American Enterprise Institute.\n",
            "\n",
            "If they had a 15 percent criterion for the primary debates.\n",
            "\n",
            "With 15% criterion for the debates, Keyes would have already been reduced to crying \"racism\" from the edge.\n",
            "\n",
            "If they had a criterion for the debates, Alan Keyes would have long since yelled \"racism\" from the sidelines.\n",
            "\n",
            "If they had a 15% criteria for the primary debates, Alan Keyes would've been reduced to yelling \"racism\".\n",
            "\n",
            "If they had a 15 percent criterion for debates, Alan Keyes would have been reduced to yelling \"racism.\" \n",
            "\n",
            "Table shows how beers performed on \"raw score\" - without the advanced statistical adjustment.\n",
            "\n",
            "This table shows how beers performed without the statistical adjustment of throwing out the highest and lowest score of each beer.\n",
            "\n",
            "This table shows the \"raw score\" performance--without the statistical adjustment of throwing out the highest and lowest score.\n",
            "\n",
            "This table shows how beers performed on \"raw score\" without statistical adjustment of throwing out the highest & lowest scores.\n",
            "\n",
            "Pointing this out doesn't change anything, but it may help calm the fears of underemployed Japan-bashers who have gone searching for new enemies.\n",
            "\n",
            "Pointing this out doesn't change anything, but it may help calm some fears being fostered by underemployed Japan-bashers who have gone searching for new enemies\n",
            "\n",
            "Pointing this doesn't change anything, but perhaps it may help calm underemployed Japan-bashers who,like old cold warriors, have gone searching for new enemies.\n",
            "\n",
            "Perhaps it may help calm some of the fears being fostered by underemployed Japan-bashers who, like old cold warriors, have gone searching for new enemies.\n",
            "\n",
            "If the transgressor is called on the carpet by his wife, Bible's admonition is the one to follow.\n",
            "\n",
            "If the transgressor is accused by his wife, the Bible's admonition is the one to follow.\n",
            "\n",
            "If the transgressor is called upon by his wife, follow the Bible, do not say whom you suspect.\n",
            "\n",
            "The Dylan anecdote reminds me that the book is chock-a-block with excellent tidbits and it would be unfair to not share a few favorites.\n",
            "\n",
            "The Dylan anecdote reminds me that the book is filled with great tidbits and it would be unfair of me to not share a few favorites:\n",
            "\n",
            "The Dylan anecdote reminds me that the book is full of excellent tidbits and it would be unfair to not share a few favorites:\n",
            "\n",
            "The Dylan anecdote reminds me the book is full of excellent tidbits, it is unfair to let the week pass without sharing a few favorites.\n",
            "\n",
            "The Dylan anecdote reminds me that the book is chock-a-block with excellent tidbits and it would be unfair to let the week pass:\n",
            "\n",
            "Decades of explaining are a fan opens against light and there proving something that darkens again.\n",
            "\n",
            "Decades of explaining are a shade against the light proving something that darkens again they are at hand but closer\n",
            "\n",
            "and decades of explaining are a fan that opens the light here proves something that darkens again.\n",
            "\n",
            "Decades of explaining are a fan that opens against the light, proving something that then darkens again...\n",
            "\n",
            "Decades of explaining opens the light but once something is proven, the road again darkens.\n",
            "\n",
            "I wore a black hat so I could blend in in the war and had a small bag to look like a doctor.\n",
            "\n",
            "I wore a black hat  and carried a  bag so I could be mistaken for a doctor in the war.\n",
            "\n",
            "I wore a black knit hat so I could be undistinguished in the war.\n",
            "\n",
            "To be undetected in the war, I wore a black hat and carried a bag to look like a doctor.\n",
            "\n",
            "Most of Clintons acceptance speech was used to publicize therapeutic laws passed on his watch and new ones he wanted considered.\n",
            "\n",
            "A third of Clinton's speech at the Democratic Convention was about therapeutic laws passed or new ones he wanted considered:\n",
            "\n",
            "A third of Clinton's acceptance speech at the DNC was publicizing therapeutic laws that he passed and also hopes to pass.\n",
            "\n",
            "A portion of Clinton's acceptance speech at the Democratic Convention was used to publicize therapeutic laws passed on his watch:\n",
            "\n",
            "A third of Clinton's acceptance speech at the Convention was used to publicize laws passed or ones he wanted Congress to consider: \n",
            "\n",
            "This is for fortitude: Prudie's doctor friend reveals that good doctors understand and aren't offended.\n",
            "\n",
            "Prudie's close friend tells her that good doctors understand these things and do not take affront.\n",
            "\n",
            "Prudie's close doctor friend tells her that good doctors understand these things and do not take affront.\n",
            "\n",
            "For courage, Prudie's good friend told her good doctors understand these things and do not take affront.\n",
            "\n",
            "For your fortitude: Prudie's doctor friend says good doctors understand to not take affront.\n",
            "\n",
            "I have been in the title insurance business for 27 years, and did my thesis on the field at Wharton. \n",
            "\n",
            "I have been in title insurance for 27 years, and did my master's at Wharton.\n",
            "\n",
            "Regarding \"\": I've been in the title insurance business for years, and did my master's thesis on it.\n",
            "\n",
            "I did my master's thesis on the field at Wharton, and I have 27 years in the  title insurance business.\n",
            "\n",
            "If your motives are selfish, you'll probably make discreet inquiries to determine whether the president is prepared to outbid the prosecutor.\n",
            "\n",
            "If all your motives are selfish, you'll make some inquiries to determine whether the president is prepared to outbid the prosecutor.\n",
            "\n",
            "If all your motives are selfish, you'll probably first make some discreet inquiries.\n",
            "\n",
            "Man is born for lovin', woman to weep and fret, tend to her oven and drown her past in coffee and cigarettes.\n",
            "\n",
            "And stay at home and tend her ovenAnd drown her past regretsIn coffee and cigarettes?\n",
            "\n",
            "Now man was born to love; was woman born to weep & fret? & stay at home & tend her oven & drown her past regrets?\n",
            "\n",
            "Now man was born to love; But woman born to fret? And stay at home to drown her regrets in coffee and cigarettes?\n",
            "\n",
            "You would probably be traipsing through New York right now, enjoying many misadventures, like a latter-day Ann Marie. Why, there is even a resemblance!\n",
            "\n",
            "[Y]ou would be traipsing through New York, enjoying misadventures, like a Ann Marie, Marlo Thomas' character from That Girl . Why, there is even a resemblance!\n",
            "\n",
            "You would be walking through NYC right now, enjoying misadventures, like Ann Marie, Marlo Thomas' character from the 1966 sitcom That Girl. You guys are similar!\n",
            "\n",
            "You would probably be traipsing through New York right now, like a latter-day Ann Marie, Marlo Thomas' character from the 1966-1971 TV sitcom That Girl.\n",
            "\n",
            "Now that the money is a different color, foreigners will be able to buy more things, or perhaps fewer.\n",
            "\n",
            "EUROPEN FOR BUSINESS: With money being a different color, foreigners can buy more, or perhaps less.\n",
            "\n",
            "EUROPEN FOR BUSINESS: Now that the money is a different color, foreigners will be able to buy more\n",
            "\n",
            "EUROPEN FOR BUSINESS: With the money a different color foreigners will be buy more or maybe less.  \n",
            "\n",
            "Go to the Mirror, Boy: John McLaughlin made George Stephanopoulos the year's \"Most Boring Person\" for his \"predictable commentary.\"\n",
            "\n",
            "John McLaughlin designated Stephanopoulos the year's \"Most Boring Person\" for his \"predictable and platitudinous commentary\".\n",
            "\n",
            "John McLaughlin designated George Stephanopoulos the \"Most Boring Person\" for his predictable and platitudinous commentary on This Week .\n",
            "\n",
            "Boy: John McLaughlin designated fellow commentarian George Stephanopoulos the year's \"Most Boring Person\" for his commentary on This Week.\n",
            "\n",
            "John McLaughlin designated fellow commentarian George Stephanopoulos the year's \"Most Boring Person\" on This Week.\n",
            "\n",
            "As I am about to tell my doctor, Leopold, she absently remarks, \"you know, 90 percent of these back problems are hereditary.\"\n",
            "\n",
            "As I'm telling my doctor, Leopold, she's staring at the X-ray and says, \"90 percent of these back problems are hereditary.\"\n",
            "\n",
            "Doctor Leopold told me that 90% of all back problems are hereditary.\n",
            "\n",
            "So just as I'm about to tell my doctor all this, she says, \"You know, 90 percent of these back problems are hereditary.\"\n",
            "\n",
            "It seems that one can hide from fallout by stating, \"I accept personal responsibility.\"\n",
            "\n",
            "One can avoid fallout by stating beforehand, \"I accept personal responsibility.\"\n",
            "\n",
            "One can hide from fallout by stating, early on, \"I accept personal responsibility.\"\n",
            "\n",
            "Lately one can hide from fallout by saying, \"I accept personal responsibility.\"\n",
            "\n",
            "Maybe it's because I'm a conservative, but I count nine reasons in the misnamed article \"8 Reasons Not to Cut the Capital-Gains tax,\"\n",
            "\n",
            "I count nine reasons in the misnamed article \"Eight Reasons Not to Cut the Capital-Gains Tax\".\n",
            "\n",
            "Maybe it's because I'm narrow-minded, but I count nine in the article \"Eight Reasons Not to Cut the Capital-Gains Tax,\".\n",
            "\n",
            "Maybe it's because I'm a conservative, but I count nine reasons in the article \"Eight reasons Not to Cut the Capital Gains Tax.\"\n",
            "\n",
            "The Miller imbroglio and the assault on Bin Laden appear to differ however, they both illustrate development in American foreign policy.\n",
            "\n",
            "The Miller imbroglio and Bin Laden's assault have nothing in common, but both illustrate James Bondification.\n",
            "\n",
            "The Miller imbroglio and the assault on Bin Laden look unrelated, but both illustrate a development in foreign policy: James Bondification.\n",
            "\n",
            "James Bondification of American foreign policy is illustrated by the Miller imbroglio and assault on Bin Laden.\n",
            "\n",
            "The Miller imbroglio and the Bin Laden assault appear to be different, but both show a development in US policy: James Bondification.\n",
            "\n",
            "How does Betty respond when scholar Mark Tushnet says: \"You can punish people for what they do; you can't for what they are.\"\n",
            "\n",
            "Q: How does Betty Loren-Maltese respond when Mark Tushnet noted you can punish people for what they do, but not what they are.\n",
            "\n",
            "How does Betty Loren-Maltese respond with Mark Tushnet notes \"You can punish people for what they do not what they are.\"\n",
            "\n",
            "How does Betty Loren-Maltese respond when scholar Mark Tushnet says: \"You can punish people for what they do; not what that are.\"\n",
            "\n",
            "How does Betty Loren-Maltese respond when constitutional scholar Mark Tushnet notes.\n",
            "\n",
            "If the cloud becomes blacker, follow Prudie's dictum: \"See no evil, Hear no evil, Date no evil.\"\n",
            "\n",
            "If you see this cloud become blacker, follow Prudie's dictum.\n",
            "\n",
            "If things worsen then follow Prudie's dictum of \"See no evil, Hear no evil, Date no evil.\"\n",
            "\n",
            "If you see this cloud becoming blacker over time follow \"See no evil, Hear no evil, Date no evil.\"\n",
            "\n",
            "If the cloud grows blacker, remember Prudie's dictum: \"See no evil, Hear no evil, Date no evil.\"\n",
            "\n",
            "Sir, I assure you it is completely random, said the agent. \"...half an hour ago the computer tagged a guy who could barely walk.\"\n",
            "\n",
            "Sir, I assure you it is...random, said the agent, \"Why, half an hour ago [the computer] tagged a guy who could barely walk.\"\n",
            "\n",
            "Sir, I assure you it is completely random, said the agent,\"Why, half an hour ago it  tagged a guy who could barely walk.\" \n",
            "\n",
            "Sir, I assure you it is completely random, said the agent, adding, \"Why, half an hour ago we tagged a guy who could barely walk.\"\n",
            "\n",
            "\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the Texas fair. - Brook Saucier\t5\t3\t3\t102389\t    T  Th  The  The   The  Th  T    B  Bu  Bus  Bust  Bust   Bust g  Bust   Bust  Bus  Bush  Bush   Bush g  Bush go  Bush got  Bush got   Bush got a  Bush got a   Bush got a p  Bush got a pl  Bush got a pla  Bush got a play  Bush got a playl  Bush got a play  Bush got a pla  Bush got a pl  Bush got a p  Bush got a   Bush got a k  Bush got a ki  Bush got a kis  Bush got a kiss  Bush got a kiss   Bush got a kiss f  Bush got a kiss fr  Bush got a kiss fro  Bush got a kiss from  Bush got a kiss from   Bush got a kiss from A  Bush got a kiss from An  Bush got a kiss from Ann  Bush got a kiss from Anna  Bush got a kiss from Anna   Bush got a kiss from Anna S  Bush got a kiss from Anna Sm  Bush got a kiss from Anna Smi  Bush got a kiss from Anna Smit  Bush got a kiss from Anna Smith  Bush got a kiss from Anna Smith   Bush got a kiss from Anna Smith a  Bush got a kiss from Anna Smith at  Bush got a kiss from Anna Smith at   Bush got a kiss from Anna Smith at t  Bush got a kiss from Anna Smith at th  Bush got a kiss from Anna Smith at the  Bush got a kiss from Anna Smith at the   Bush got a kiss from Anna Smith at the W  Bush got a kiss from Anna Smith at the Wo  Bush got a kiss from Anna Smith at the Wor  Bush got a kiss from Anna Smith at the Worl  Bush got a kiss from Anna Smith at the World  Bush got a kiss from Anna Smith at the World'  Bush got a kiss from Anna Smith at the World's  Bush got a kiss from Anna Smith at the World's   Bush got a kiss from Anna Smith at the World's B  Bush got a kiss from Anna Smith at the World's Bi  Bush got a kiss from Anna Smith at the World's Big  Bush got a kiss from Anna Smith at the World's Bige  Bush got a kiss from Anna Smith at the World's Biges  Bush got a kiss from Anna Smith at the World's Bigest  Bush got a kiss from Anna Smith at the World's Bigest   Bush got a kiss from Anna Smith at the World's Bigest B  Bush got a kiss from Anna Smith at the World's Bigest Bo  Bush got a kiss from Anna Smith at the World's Bigest Boo  Bush got a kiss from Anna Smith at the World's Bigest Bo  Bush got a kiss from Anna Smith at the World's Bigest B  Bush got a kiss from Anna Smith at the World's Bigest   Bush got a kiss from Anna Smith at the World's Bigest  Bush got a kiss from Anna Smith at the World's Biges  Bush got a kiss from Anna Smith at the World's Bige  Bush got a kiss from Anna Smith at the World's Big  Bush got a kiss from Anna Smith at the World's Bigg  Bush got a kiss from Anna Smith at the World's Bigge  Bush got a kiss from Anna Smith at the World's Bigges  Bush got a kiss from Anna Smith at the World's Biggest  Bush got a kiss from Anna Smith at the World's Biggest   Bush got a kiss from Anna Smith at the World's Biggest B  Bush got a kiss from Anna Smith at the World's Biggest Bo  Bush got a kiss from Anna Smith at the World's Biggest Bob  Bush got a kiss from Anna Smith at the World's Biggest Bo  Bush got a kiss from Anna Smith at the World's Biggest Boo  Bush got a kiss from Anna Smith at the World's Biggest Boob  Bush got a kiss from Anna Smith at the World's Biggest Boob   Bush got a kiss from Anna Smith at the World's Biggest Boob r  Bush got a kiss from Anna Smith at the World's Biggest Boob ra  Bush got a kiss from Anna Smith at the World's Biggest Boob r  Bush got a kiss from Anna Smith at the World's Biggest Boob   Bush got a kiss from Anna Smith at the World's Biggest Boob R  Bush got a kiss from Anna Smith at the World's Biggest Boob RA  Bush got a kiss from Anna Smith at the World's Biggest Boob RAc  Bush got a kiss from Anna Smith at the World's Biggest Boob RAce  Bush got a kiss from Anna Smith at the World's Biggest Boob RAcee  Bush got a kiss from Anna Smith at the World's Biggest Boob RAce  Bush got a kiss from Anna Smith at the World's Biggest Boob RAc  Bush got a kiss from Anna Smith at the World's Biggest Boob RA  Bush got a kiss from Anna Smith at the World's Biggest Boob RAa  Bush got a kiss from Anna Smith at the World's Biggest Boob RAac  Bush got a kiss from Anna Smith at the World's Biggest Boob RAace  Bush got a kiss from Anna Smith at the World's Biggest Boob RAac  Bush got a kiss from Anna Smith at the World's Biggest Boob RAa  Bush got a kiss from Anna Smith at the World's Biggest Boob RA  Bush got a kiss from Anna Smith at the World's Biggest Boob R  Bush got a kiss from Anna Smith at the World's Biggest Boob   Bush got a kiss from Anna Smith at the World's Biggest Boob a  Bush got a kiss from Anna Smith at the World's Biggest Boob   Bush got a kiss from Anna Smith at the World's Biggest Boob R  Bush got a kiss from Anna Smith at the World's Biggest Boob RA  Bush got a kiss from Anna Smith at the World's Biggest Boob RAc  Bush got a kiss from Anna Smith at the World's Biggest Boob RAce  Bush got a kiss from Anna Smith at the World's Biggest Boob RAc  Bush got a kiss from Anna Smith at the World's Biggest Boob RA  Bush got a kiss from Anna Smith at the World's Biggest Boob R  Bush got a kiss from Anna Smith at the World's Biggest Boob Ra  Bush got a kiss from Anna Smith at the World's Biggest Boob Rac  Bush got a kiss from Anna Smith at the World's Biggest Boob Race  Bush got a kiss from Anna Smith at the World's Biggest Boob Race   Bush got a kiss from Anna Smith at the World's Biggest Boob Race /  Bush got a kiss from Anna Smith at the World's Biggest Boob Race /   Bush got a kiss from Anna Smith at the World's Biggest Boob Race /  Bush got a kiss from Anna Smith at the World's Biggest Boob Race   Bush got a kiss from Anna Smith at the World's Biggest Boob Race -  Bush got a kiss from Anna Smith at the World's Biggest Boob Race -   Bush got a kiss from Anna Smith at the World's Biggest Boob Race - B  Bush got a kiss from Anna Smith at the World's Biggest Boob Race - Br  Bush got a kiss from Anna Smith at the World's Biggest Boob Race - Bro  Bush got a kiss from Anna Smith at the World's Biggest Boob Race - Broo  Bush got a kiss from Anna Smith at the World's Biggest Boob Race - Brook  Bush got a kiss from Anna Smith at the World's Biggest Boob Race - Brook   Bush got a kiss from Anna Smith at the World's Biggest Boob Race - Brook S  Bush got a kiss from Anna Smith at the World's Biggest Boob Race - Brook Sa  Bush got a kiss from Anna Smith at the World's Biggest Boob Race - Brook Sau  Bush got a kiss from Anna Smith at the World's Biggest Boob Race - Brook Saui  Bush got a kiss from Anna Smith at the World's Biggest Boob Race - Brook Sauic  Bush got a kiss from Anna Smith at the World's Biggest Boob Race - Brook Saui  Bush got a kiss from Anna Smith at the World's Biggest Boob Race - Brook Sau  Bush got a kiss from Anna Smith at the World's Biggest Boob Race - Brook Sauc  Bush got a kiss from Anna Smith at the World's Biggest Boob Race - Brook Sauci  Bush got a kiss from Anna Smith at the World's Biggest Boob Race - Brook Saucie  Bush got a kiss from Anna Smith at the World's Biggest Boob Race - Brook Saucier  Bush got a kiss from Anna Smith at the World's Biggest Boob Race - Brook Saucier.  Bush got a kiss from Anna Smith at the World's Biggest Boob Race - Brook Saucier  Bush got a kiss from Anna Smith at the World's Biggest Boob Race: - Brook Saucier  Bush got a kiss from Anna Smith at the World's Biggest Boob Race - Brook Saucier  Bush got a kiss from Anna Smith at the World's Biggest Boob Race - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race\"\" - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race \"\" - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race v\"\" - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race v - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race  - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race a - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at  - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at t - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at th - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the  - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the t - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the  - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the T - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the Te - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the Tex - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the Texa - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the Texas - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the Texas  - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the Texas d - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the Texas da - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the Texas dai - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the Texas dair - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the Texas dai - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the Texas da - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the Texas d - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the Texas df - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the Texas d - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the Texas  - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the Texas f - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the Texas fa - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the Texas fai - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the Texas fair - Brook Saucier  \"\"Bush got a kiss from Anna Smith at the World's Biggest Boob Race at the Texas fair. - Brook Saucier\"\n",
            "\n",
            "Bush got a kiss from Anna Nicole Smith at the World's Biggest Boob Relay Race in Texas.- Brooke Saucier \n",
            "\n",
            "Bush French kissed Smith at World's Biggest Boob Relay Race at Texas State Fair -- Brooke Saucier.\n",
            "\n",
            "Bush got a kiss from Anna Nicole Smith at a relay race at the Texas State Fair\"-- Brooke Saucier\n",
            "\n",
            "Charles Murray is a genius, and the publication of his book, The Bell Curve: Intelligence and Class Structure in American Life, was his masterpiece.\n",
            "\n",
            "Charles Murray is a publicity genius, and the publication of his and Richard Herrnstein's book in the fall of 1994 was his masterpiece.\n",
            "\n",
            "Charles Murray is a publicity genius. His and Richard Herrnstein's book was his masterpiece.\n",
            "\n",
            "Charles Murray's publication, The Bell Curve: Intelligence and Class Structure in American Life was his masterpiece. \n",
            "\n",
            "As 1998 has drawn to a close, I'vm in evaluation mode and have felt blue and bluer.\n",
            "\n",
            "As 1998 comes to an end and I evaluate the past year I find myself growing more blue.\n",
            "\n",
            "I have found myself in evaluation mode and felt increasingly bluer as 1998 gets closer.\n",
            "\n",
            "As 1998 is ending, I have found myself in evaluation mode and have felt down.\n",
            "\n",
            "As 1998 ends, I've been in evaluation mode and have felt increasingly blue and bluer.\n",
            "\n",
            "Rumschpringes (noun): an Amish rite of passage during which teen-agers are temporarily freed from the community rules.\n",
            "\n",
            "Rumschpringes: Running around; an Amish rite of passage during which teen-agers are temporarily freed from the community rules.\n",
            "\n",
            "Rumschpringes: Pennsylvania Dutch meaning \"running around\", or an Amish process where teenagers are free of community rules.\n",
            "\n",
            "Rumschpringes (noun): Pennsylvania Dutch meaning; an Amish rite of passage where teens are freed from community rules.\n",
            "\n",
            "Rumschpringes (n.): an Amish rite of passage during which teenagers are temporarily freed from community rules.\n",
            "\n",
            "The 4 events: NYT Op-Ed and New Yorker Talk of the Town\" (max length, 750 words each); First 1000 Words of Vanity Fair profile; Breaking News Story.\n",
            "\n",
            "The four events: a New York Times Op-Ed; a New Yorker Talk of the Town\" ;the First 1,000 Words of a Vanity Fair profile; a Breaking News Story. \n",
            "\n",
            "Harry J. Lennix does a superb job of playing Aaron, the arch-villain in Titus, although Anthony Hopkins gets to bake Tamora's sons into meat pies.\n",
            "\n",
            "This just in: Harry J. Lennix does a great job of playing Aaron, although Anthony Hopkins gets to bake Tamora's sons into two meat pies.\n",
            "\n",
            "The black actor Harry J. Lennix does great playing Aaron, the villain in Titus, although Anthony Hopkins gets to bake Tamora's sons into meat pies.\n",
            "\n",
            "Harry J. Lennix does a superb job of playing Aaron, the arch-villain in Titus , although Hopkins, gets to bake Tamora's sons into two meat pies. \n",
            "\n",
            "We had every right, and we were just and moral, to smash both of those evil empires.\n",
            "\n",
            "We had every right to smash both of those evil empires[Nazi Germany and Imperial Japan].\n",
            "\n",
            "We had every right to smash both of those evil empires [Nazi Germany and Imperial Japan].\n",
            "\n",
            "We had every right and we're more than right - to smash both of those evil empires.\n",
            "\n",
            "We were... right, just, and moral--to smash both of those evil empires [Nazi Germany and Imperial Japan].\n",
            "\n",
            "A topic of immeasurable importance is buried deep in the NYT business section: How could a story about \"Today's Papers\" be underplayed?\n",
            "\n",
            "Today's Papers, a story with social and intellectual importance, is buried in the NYT business section. Why is it so underplayed?\n",
            "\n",
            "A topic of immeasurable importance is buried inside the NYT business section: How could a story about \"Today's Papers\" be so underplayed?\n",
            "\n",
            "Buried in the NYT business section, was a topic of social and intellectual importance, Today's Papers, how could a story be so underplayed.\n",
            "\n",
            "Rather than dueling with Sedlak and Broadhurst‚Äôs data, this history best shows their selective presentation of information.\n",
            "\n",
            "I mention this history instead of Sedlak and Broadhurst's statistics because it shows their selective presentation.\n",
            "\n",
            "Rather than dueling with Sedlak and Broadhurst's statistics, because it exemplifies their selective presentation.\n",
            "\n",
            "I mention this history because I think that it exemplifies their selective presentation of information.\n",
            "\n",
            "I mention this history because  I think that it exemplifies their selective presentation of information.\n",
            "\n",
            "Nothing's wrong with buying new things; it's the talking that interferes with personal judgment and turns the effort into a burden.\n",
            "\n",
            "There's nothing to matter when buying new things; personal judgments that turns happy into embarrassing burden.\n",
            "\n",
            "It's the invasive verbal hype that interferes with personal judgment and turns the happy effort into an embarrassing burden.\n",
            "\n",
            "It's the verbal hype that interferes with personal judgment and turns happy effort into an embarrassing burden.\n",
            "\n",
            "Invasive verbal hype interferes with judgment and turns buying lovely new things into an embarrassing problem.\n",
            "\n",
            "La Ceremonie (MK2 Productions) The prospect before her: A History of Women in Europe, 1500-1800 By, Olwen Hufton; King of the Hill, and Tokyo film festival.\n",
            "\n",
            "15: La C√©r√©monie; The Prospect Before Her: A History of Women in Western Europe, 1500-1800 , by Olwen Hufton; King of the Hill; and Tokyo International Forum.\n",
            "\n",
            "La Ceremonie, the Prospect Before Her: A History of Women in Western Europe 1500-1800, King of the Hill, and Tokyo international Forum.\n",
            "\n",
            "La C√©r√©monie; The Prospect Before Her: A History of Women in Western Europe, 1500-1800 , by Olwen Hufton; King of the Hill (Fox); and Tokyo International Forum.\n",
            "\n",
            "Dole entered the race last April to highlight his service in World War II, his 50th anniversary since being wounded.\n",
            "\n",
            "Dole specifically chose to jump into the race, marking the 50th anniversary of when he was wounded during WW II.\n",
            "\n",
            "Dole chose last April to join the race, marking the 50th anniversary of when he was wounded in World War II.\n",
            "\n",
            "I want to know what happens next with the mob--in real life--as they realize the lifestyle is dead.\n",
            "\n",
            "I want to know what happens with the mob-if the Bada-Bing lifestyle is dead. \n",
            "\n",
            "I want to know what happens next with the mob they realize that the Bada-Bing lifestyle is dead.\n",
            "\n",
            "I want to know what happens with the real mob: if the smarter ones realize the old lifestyle is dead.\n",
            "\n",
            "What does it show you about the the judgment of the person who made that statement, if anything? \n",
            "\n",
            "Apart from the oddness, what does the Vice president's statement say about him.\n",
            "\n",
            "Apart from the oddness of the statement what does it show you about the judgment of the person who made that statement, if anything?\n",
            "\n",
            "Apart from the oddness of the statement what does it show about the the judgment of the person who made the statement, if anything?\n",
            "\n",
            "Apart from the oddness of the statement, what does it show you about the judgment of the person who made it, if anything?\n",
            "\n",
            "scroll down and click Glacier National Park--National Park Service Homepage, which takes you to\n",
            "\n",
            "voyageurs.com/nwvoyage/frames/noframes/, Glacier National Park--National Park Service Homepage...\n",
            "\n",
            "On the homepage click Glacier National Park which will then take you to the next page.\n",
            "\n",
            "voyageurs.com/nwvoyage/frames/noframes/, where you scroll down a bit, click Glacier National Homepage, and go to ...\n",
            "\n",
            "The smirk resurfaced at last week's NH debate, according to The New Yorker 's Joe Klein.\n",
            "\n",
            "The smirk resurfaced at last week's New Hampshire debate, according to The New Yorker's Joe Klein.\n",
            "\n",
            "The smirk resurfaced at last week's debate, according to Joe Klein. \n",
            "\n",
            "The smirk resurfaced, according to The New Yorker's Joe Klein, who in the Dec. 13 issue writes that Bush\n",
            "\n",
            "The smirk resurfaced at last week's New Hampshire debate, according to The New Yorker 's Joe Klein.\n",
            "\n",
            "Recent installments of this column are here: posted Tues., Nov. 17, and Fri., Nov. 13.\n",
            "\n",
            "The most recent installments of this column are here: Tues, Nov. 17, and Fri, Nov. 13.\n",
            "\n",
            "If you missed the recent installments, here they are: posted Nov. 17 and Nov. 13.\n",
            "\n",
            "The most recent installments were posted on Friday Nov. 13 and Tuesday Nov. 17.\n",
            "\n",
            "Two-thirds of U.S. households have answering machines and half use them them to screen incoming calls.\n",
            "\n",
            "The Wall Street Journal reports that two-thirds of U.S. households have answering machines to screen calls.\n",
            "\n",
            "The Wall Street Journal reports, two-thirds of households have answering machines and half are used to screen calls.\n",
            "\n",
            "Wall Street reports that 2/3s of US households have answering machines and fully half use them to screen calls.\n",
            "\n",
            "The WSJ reports that two-thirds of U.S. households have answering machines and that half of those use them.\n",
            "\n",
            "A forthcoming biography of Al Gore challenges yet another key assertion by the Gore campaign about the candidate's former marijuana use. \n",
            "\n",
            "WASHINGTON--A forthcoming biography of Vice President Al Gore challenges another key assertion about the candidate's former marijuana use.\n",
            "\n",
            "WASHINGTON--An upcoming biography of Al Gore challenges a key assertion by the Gore campaign, the candidate's marijuana use.\n",
            "\n",
            "The Gore campaign faces challenges and assertions with the candidates marijuana use in a forthcoming biography.\n",
            "\n",
            "If I were chatting with Al Gore on Connecticut Ave at this moment, we'd be stuck in a massive snowdrift.\n",
            "\n",
            "If I were chatting with Al Gore outside that movie theater, we'd be stuck in a massive snowdrift.\n",
            "\n",
            "Now, if we are chatting with Al Gore at the theater on Connecticut Ave we would be in a snowdrift.\n",
            "\n",
            "Al Gore and I would be stuck in a snowdrift if we were outside that Connecticut Avenue theater now.\n",
            "\n",
            "A voice arose among overhead In a full-hearted; An aged thrush, frail, gaunt, and small In plume, Had chosen thus to fling his soul Upon the gloom.\n",
            "\n",
            "At once a voice arose among The bleak twigs overhead In a full-hearted evensong Of joy illimited; An aged thrush.\n",
            "\n",
            "A voice arose among the bleak twigs overhead. In a full-hearted evensong of joy illimited. An aged thrush, frail, gaunt, and small In blast-beruffled plume...\n",
            "\n",
            "bleak twigs overhead full-hearted evensong Of joy illumined aged thrush, frail, gaunt, and In blast-be ruffled plume, Had chosen fling his soul with growing gloom.\n",
            "\n",
            "Time's profile of Trent Lott reaches a similar conclusion: like Clinton, Lott is a compromiser.\n",
            "\n",
            "Time's profile of Trent Lott reaches the same conclusion: Like Clinton, Lott is a compromiser. \n",
            "\n",
            "Time's profile of Trent Lott reaches the same conclusion as earlier profiles of the leader: Lott is a compromiser.\n",
            "\n",
            "Time's profile of Trent Lott reaches the same conclusion as earlier profiles of the Senate majority leader.\n",
            "\n",
            "Time's profile of Trent Lott reaches the conclusion of the Senate majority leader: Lott is a compromiser.\n",
            "\n",
            "The WP off-lead reports that U.N. investigators have evidence that before the Gulf War, Iraq put nerve gas into missile warheads.\n",
            "\n",
            "The WP reports that U.N. investigators have evidence that before the Gulf War, Iraq put nerve gas into missile warheads.\n",
            "\n",
            "WP off-lead reports that U.N. investigators have evidence that before the Gulf war, Iraq put nerve has into missile warheads.\n",
            "\n",
            "In a developing story, the WP off-lead reports that U.N. investigators have evidence that Iraq put nerve gas into missile warheads.\n",
            "\n",
            "Starr & Bennett said they have no worries if these or other reporters reveal their conversations.\n",
            "\n",
            "Starr and Bennett have claimed they have nothing to worry about if reporters reveal their conversations.\n",
            "\n",
            "Starr and Bennett claimed that they have nothing to worry about if there conversations are revealed.\n",
            "\n",
            "Starr and Bennett claimed that they have nothing to worry about if reporters reveal their conversations.\n",
            "\n",
            "1) It would shock no one and disappoint few to find out Clinton and Lewinsky did have an affair.\n",
            "\n",
            "1.) Clinton and Lewinsky's affair would shock no one and disappoint a few.\n",
            "\n",
            "No one was shocked or surprised to learn Clinton had an affair with Lewinsky.\n",
            "\n",
            "It would be no surprise to find out that Clinton and Lewinsky did have an affair.\n",
            "\n",
            "It would shock no one to find out that Clinton and Lewinsky did have an affair. \n",
            "\n",
            "The men have competing ideas for the 2,600 tons of German paper money as it switches over to the euro.\n",
            "\n",
            "As Germany discards paper money and switches to euros, two men have ideas on disposing of it.\n",
            "\n",
            "The two men have different ideas on how to dispose of 2,600 tons of German paper money.\n",
            "\n",
            "The two men have competing ideas for disposing of the 2,600 tons of German paper money.\n",
            "\n",
            "Two men have competing ideas for disposing 2,600 tons of German paper money as it switches over to the euro.\n",
            "\n",
            "This 9-to-12-year-old age group's discovery of rock and roll cemented into us older boomers two lessons that were behind much of what happened in the '60s:\n",
            "\n",
            "I think this 9-12-year-old age group's discovery of rock & roll, cemented into us boomers two lessons that were behind much of what happened in the '60s.\n",
            "\n",
            "I think this 9-to-12-year-old age group's discovery of rock and roll, against our parents wishes, cemented into us two lessons of what happened in the '60s:\n",
            "\n",
            "I honestly think this 9-to-12-year-old age group's discovery of rock and roll, against the wishes of our parents, cemented into us older boomers.\n",
            "\n",
            "The Globe's list of the \"Dream Couple's 50 favorite things,\" including Carolyn Bessette's favorite masseuse and John's favorite cereal.\n",
            "\n",
            "The Globe's list of the \"Dream Couple's 50 favorite things,\" include Bessette's favorite masseuse Bree Neumann & oatmeal for John.\n",
            "\n",
            "The Globe's list of the \"Dream Couple's 50 favorite things,\" including Bessette's fave masseuse and John's favorite cereal.\n",
            "\n",
            "Most needless story: The Globe's \"Dream Couple's 50 favorite things,\" including Carolyn's favorite masseuse and John's favorite cereal.\n",
            "\n",
            "The Globe 's list of the \"Dream Couple's 50 favorite things,\" including Carolyn Bessette's favorite masseuse.\n",
            "\n",
            "Trent Lott, Ronald Reagan & Steve Martin did it in their youth & this summer over 400k will attend camps to do it better.\n",
            "\n",
            "Trent Lott, Ronald Reagan, and Steve Martin attended camps so they can learn how to do better.\n",
            "\n",
            "Trent Lott, Ronald Reagan, and Steve Martin did it, and this summer people will attend camps to learn how to do it.\n",
            "\n",
            "As Trent Lott, Ronald Reagan, and Steve Martin did, 400,000+ people will attend camps to learn how to do it better.\n",
            "\n",
            "This summer more than 400,000 people will attend camps to learn how to do this better.\n",
            "\n",
            "It gave me freedom with walls so I could handle bulging and sagging.  One summer I read Steinbeck and made love in the bedroom.\n",
            "\n",
            "Washing hands or touching car doors gave me freedom with walls so I could handle bulging and sagging when I had to.\n",
            "\n",
            "Washing hands or touching car doors, gave me freedom with walls so I can handle bulding and sagging.\n",
            "\n",
            "Washing hands & touching car doors gave me freedom so I could handle bulging & sagging when I had to. One summer I read Steinbeck & made love.\n",
            "\n",
            "I had a freedom with walls so I could handle sagging when I had to; and one of the summers I read Steinbeck and made love-in the bedroom.\n",
            "\n",
            "He said 1986 Peking was \"ghastly\" and told students: \"If you stay here much longer you'll all be slitty-eyed.\"\n",
            "\n",
            "He told some British students during his 1986 visit, ‚ÄúIf you stay here much longer, you‚Äôll all be slitty-eyed.‚Äù\n",
            "\n",
            "During a visit in 1986, he said Peking was \"ghastly\" and said \"If you stay here longer you'll all be slitty-eyed\"\n",
            "\n",
            "During a 1986 visit, he told students, \"If you stay here longer you'll be slitty-eyed.\", calling Peking ghastly.\n",
            "\n",
            "3. In 1986, he said Peking was \"ghastly\" and told British students: \"If you stay here you'll be slitty-eyed.\"\n",
            "\n",
            "A search for Bill Gates will find articles containing both the words bill and gates.\n",
            "\n",
            "Bill Gates (or bill and gates) search will find articles containing both the word bill & gates.\n",
            "\n",
            "A search for Bill, Gates, or Bill Gates, will find articles that contain both Bill, and Gates.\n",
            "\n",
            "A search for \"Bill Gates\" will find articles containing both the word bill and the word gates .\n",
            "\n",
            "Get me to Sydney, to the opening ceremony and the torch and the hymns.\n",
            "\n",
            "Get me to Sydney, get me to the opening ceremony and I'll be fine\n",
            "\n",
            "Get me to Sydney, to the opening ceremony, the torch, and the hymns.\n",
            "\n",
            "Get me to the opening and the torch ceremony in Sydney and I'll be fine.\n",
            "\n",
            "Get me to Sydney, get me to the opening ceremony, and I'll be fine.\n",
            "\n",
            "An ad for a penile enlargement clinic ran in the New York Times. The masthead now read \"The newspaper of record and small penises.\"\n",
            "\n",
            "A penile enlargement clinic ran an ad in the NYT. The masthead now displays the slogan \"The newspaper of record and small penises.\"\n",
            "\n",
            "An ad for another penile enlargement clinic ran in the NY Times. The masthead displays \"The newspaper of record and small penises.\"\n",
            "\n",
            "An ad for a penile enlargement clinic ran in the New York Times. The masthead now displays the slogan \"The newspaper of penises.\"\n",
            "\n",
            "Another ad for penile enlargement rad on Monday. The masterhead said \"The newspaper of record and small penises.\"\n",
            "\n",
            "Participants are asked to provide a postelection headline to show on the media outlet of their choice.\n",
            "\n",
            "Participants are invited to provide a headline that  would run the media outlet of their choice. \n",
            "\n",
            "Participants are invited to provide post election headlines of their choice in Wednesday's media outlet. \n",
            "\n",
            "Last week, Bradley forces focused on the VP's claim, saying the EITC became law in 1975, a year before Gore was in Congress.\n",
            "\n",
            "The Bradley forces jumped on the veep's claim of authorship, saying that the EITC became law in '75, before Gore was elected.\n",
            "\n",
            "The Bradley forces jumped on the veep's claim of authorship, pointing out the EITC became law in 1975.\n",
            "\n",
            "Also in the New Republic, Jefferson-mania continues: A long book review celebrates the third president.\n",
            "\n",
            "Jefferson-mania continues: A book review celebrates the third president as a \"great democrat.\" \n",
            "\n",
            "Jefferson-mania occurs in the New Republic: It celebrates the president as a \"great democrat\", albeit slave-owning.\n",
            "\n",
            "In the New Republic Jefferson-mania continues: A book review calls him a \"great democrat,\" but a slave-owning one.\n",
            "\n",
            "1939: Lou Gehrig has ALS; \"With My Name, I Figured It Was Only a Matter of Time,\" Says Yankee\n",
            "\n",
            "Lou Gehrig said \"With my name, I figured it was only a matter of time\", citing his illness.\n",
            "\n",
            "Lou Gehrig has Lou Gehrig's disease. \"With my name, I figured it was only a matter of time\".\n",
            "\n",
            "1939: Lou Gehrig Has Lou Gehrig's Disease; He said with his name it was only a matter time.\n",
            "\n",
            "1939: Lou Gehrig Has Lou Gehrig's Disease; \"I Figured It Was a Matter of Time,\" He Says\n",
            "\n",
            "Simon & Schuster announced they would publish The Dream Catcher, the memoirs of Salinger's 43-year-old daughter, Margaret.\n",
            "\n",
            "Simon & Schuster announced the impending publication of The Dream Catcher, the memoirs of Salinger's daughter, Margaret. \n",
            "\n",
            "In older news, Simon & Schuster announced the impending publication of the Dream Catcher, a memoir of Salinger's daughter. \n",
            "\n",
            "The troop move is in the front-page news box at the Wall Street Journal.\n",
            "\n",
            "The front page of the WSJ, WP, LAT, and the inside of NYT, is the troop move.\n",
            "\n",
            "The troop move is in the front-page, on the WP and LAT, WSJ fronts, and inside at the NYT.\n",
            "\n",
            "The troop move is in the front-page news box at the Wall Street Journal, WP, LAT, and NYT.\n",
            "\n",
            "Is too willing to provoke constitutional standoffs for the sake of his investigation.\n",
            "\n",
            "c) Too willing to provoke standoffs in the name of his investigation, places little value in presidency.\n",
            "\n",
            "He is too willing to create constitutional standoffs and is indifferent to the dignity of the presidency.\n",
            "\n",
            "Too willing to provoke constitutional standoffs for investigation, seems indifferent to the presidency.\n",
            "\n",
            "c) Is too prone to spur constitutional deadlock for his case, is aloof to the honor of the presidency. \n",
            "\n",
            "A better topic is why the price of Win95 hasn't come down in three years\n",
            "\n",
            "A topic to examine is why Windows 95 price hasn't come down in three years.\n",
            "\n",
            "A good topic to review is why the price of Windows 95 hasn't lowered in 3yrs.\n",
            "\n",
            "A better topic is why the Windows 95 price hasn't come down in three years.\n",
            "\n",
            "A better topic is why the price of Windows 95 hasn't come down in 3 years.\n",
            "\n",
            "The WSJ flags Motorola story with Motorola surprises Analysts with slim profit while the WP said Motorola earnings plunge. \n",
            "\n",
            "The WSJ says \"Motorola Surprises Analysts, Posting Slim operating Profit\", while WP uses \"Motorola Reports Earnings Plunge/2nd Quarter Operating Profit Negligible.\n",
            "\n",
            "The WSJ flags its story with \"Motorola Surprises Analysts, Posting Slim Operating Profit,\" while the WP goes the other way with \"Motorola Reports Earnings Plunge.\"\n",
            "\n",
            "The WSJ flags its Motorola story with \"Motorola Surprises Analysts With Slim Profit,\" while the WP is different with \"Motorola Reports Plunge/Profit Negligible.\"\n",
            "\n",
            "Corporations are run by people, and people have feelings, Hellman. I'm sure Coulter doesn't appreciate public official diatribes against BofA.\n",
            "\n",
            "Corporations are run by people, and people have feelings, Hellman said. \"I'm sure Coulter doesn't like public officials going against BofA.\"\n",
            "\n",
            "Corporations are run by people, and people have feelings, I'm sure Coulter doesn't appreciate public officials delivering diatribes against BoA.\n",
            "\n",
            "Corporations are run by people who have feelings, Hellman told the SFC. She's sure Coulter doesn't like officials bashing BoA\n",
            "\n",
            "The recent installments of the column are: posted Tuesday, Nov 24, and Friday, Nov 20.\n",
            "\n",
            "If you missed the recent columns, they're posted on Tues,  11/24 & Fri, 11/20.\n",
            "\n",
            "If you missed the most recent installments of this column, here they are: \n",
            "\n",
            "If you missed the installments of this column, here they are: TUE 24th and FRI 20th.\n",
            "\n",
            "The most recent installments can be found here: Tuesday, Nov. 24, and Friday, Nov. 20.\n",
            "\n",
            "Once again, I called Burke to ask whether U-Haul changes confirmed reservations behind the customer's back, but Burke did not call back.\n",
            "\n",
            "I called Burke to ask whether U-Haul is in the habit of changing confirmed reservations behind the customer's back, but Burke did not call back. \n",
            "\n",
            "I called Burke to ask whether U-Haul changes reservations behind customers' backs but, even knowing the Shopping Avenger's deadline approached, he didn't call back.\n",
            "\n",
            "Even knowing that the deadline is approaching, Burke did not call back when I asked whether U-Haul changes confirmed reservations behind the customers back.\n",
            "\n",
            "I called Burke to ask whether U-Haul is in the habit of changing confirmed reservations behind the customer's back.\n",
            "\n",
            "USAT reports that Jordan met four times with Lewinsky, but never mentions that this was first.\n",
            "\n",
            "USAT says Jordan met four times with Lewinsky, but never mentioned first reporting was yesterday.\n",
            "\n",
            "Vernon Jordan met four times with Lewinsky, but never mentions the first reported yesterday.\n",
            "\n",
            "Chatterbox has learned that Currie told friends President Clinton and his wife lead separated lives that the president learned Hillary was testifying on TV!\n",
            "\n",
            "Currie told friends President Clinton and his wife lead such separated lives that the president only learned Hillary was testifying when he saw it on TV!\n",
            "\n",
            "Chatterbox learned that Currie told Clinton and his wife lead separated lives that the president only learned Hillary was testifying before the grand jury!\n",
            "\n",
            "President Clinton and his wife lead such separated lives that the president only learned Hillary was testifying before Starr's grand jury when he saw it on TV!\n",
            "\n",
            "Chatterbox learned that the Clintons lead such separate lives that the president learned Hillary was testifying before Starr's grand jury when he saw it on TV!\n",
            "\n",
            "7) Casual Fridays are back! But that doesn't mean you should slip back into your Office 97 jacket or favorite Microsoft Bob T-shirt.\n",
            "\n",
            "We will have Casual Fridays, but please refrain from slipping  back into your Office 97 jacket or favorite Microsoft Bob T-shirt.\n",
            "\n",
            "We will have Casual Fridays, but that doesn't mean you should just slip back into your Office 97 jacket or that favorite T-shirt.\n",
            "\n",
            "7) We will have Casual Fridays like all other good media companies, but there are restrictions.\n",
            "\n",
            "We have Casual Fridays, but that doesn't mean slip into your old Microsoft gear.\n",
            "\n",
            "Only the Journal could find in this an inspiring story about a lesson in the power of connections.\n",
            "\n",
            "The Journal found the above events a story about a kid's first lesson in the power of connection.\n",
            "\n",
            "The Journal found an uplifting story in a kid's \"first lesson in the power of connections.\"\n",
            "\n",
            "The uplifting story \"first lesson in the power of connections.\" was found in the Journal.\n",
            "\n",
            "Only the Journal could find positivity in a kid's \"first lesson in the power of connections.\"\n",
            "\n",
            "He appreciates dictionaries, even if they spring into existence without help from editors.\n",
            "\n",
            "So he appreciates dictionaries, even if he thinks that they spring into existence with no help.\n",
            "\n",
            "So he does appreciate dictionaries, even if he thinks that they exist without editor help.\n",
            "\n",
            "He appreciates dictionaries, even if he thinks that they come with no help from editors.\n",
            "\n",
            "Another difference is that Bush didn't pay Magnet for his advice, while Gore paid Wolf $15,000 a month.\n",
            "\n",
            "Distinction between Wolf and Magnet is that Bush didn't pay Magnet, while Gore valued Wolf's at $15k a month.\n",
            "\n",
            "Another distinction between Wolf and Magnet is that Bush didn't pay Magnet anything for his advice.\n",
            "\n",
            "Another distinction between Wolf and Magnet is that Bush did not pay Magnet and Gore paid Wolf 15000 a month.\n",
            "\n",
            "The Post suggests that the dispute was beneficial for Clinton because of the internal Republican disagreements.\n",
            "\n",
            "The dispute was on balance a plus for Clinton. White House advisors were delighted at the fissures inside Republican ranks it opened up.\n",
            "\n",
            "The Post floats the view that the dispute was a plus for Clint, saying that several advisers were delighted at the opened up ranks.\n",
            "\n",
            "The Post stated that several White House advisors were delighted at the fissures inside Republican ranks.\n",
            "\n",
            "The Post believes the dispute was good for Clinton. Several White House advisors were delighted at the issues it caused for Republicans.\n",
            "\n",
            "The LAT ran a front-page story on juror interviews reporting that, contrary to the Nichols jury foreman's opinion, the jury was leaning towards the death penalty.\n",
            "\n",
            "The LAT front page story was about the jury leaning toward the death penalty contrary to the Forewoman's interview, yesterday.\n",
            "\n",
            "The LAT runs a story based on juror interviews. Against opinions told yesterday by the jury forewoman, there was \"a strong faction\" on the jury for death penalty.\n",
            "\n",
            "The LAT runs a story based on a juror interview that expressed by the Nichols forewoman, there was a strong faction on the jury leaning towards the death penalty.\n",
            "\n",
            "The LAT runs a story based on juror interviews reporting that there was \"a strong faction\" leaning towards the death penalty.\n",
            "\n",
            "32 percent of benefits of the Clinton tax bill flow to the top 1 percent of earners and 78 percent go to the top 20 percent.\n",
            "\n",
            "The WSJ reports that 78 percent of the benefits of the Clinton-approved tax bill go to the top 20 percent of earners.\n",
            "\n",
            "The WSJ reports that 32% of benefits of the Clinton-approved tax bill flow to the top 1% of earners and 78% go to the top 20%.\n",
            "\n",
            "The WSJ \"Washington Wire\" reports that 32 percent of benefits flow to the top 1 percent of earners.\n",
            "\n",
            "32 percent of the Clinton tax bill benefits flow to the top 1 percent of earners and 78 percent to the top 20 percent WSJ reports.\n",
            "\n",
            "To play with the big boys in LA and NY, we have to dress like them - even if we are girls.\n",
            "\n",
            "We have to dress like the big boys in LA and NY to play with them--even if we are girls.\n",
            "\n",
            "If we want to play with the big boys in LA and NY, we have to dress like them.\n",
            "\n",
            "If we girls want to play with the big boys in LA and NY, we have to dress like them.\n",
            "\n",
            "To play with the big boys in LA and NY, we have to dress like them, even if we are girls.\n",
            "\n",
            "Time reports that the overfishing of sharks for fins  and cartilage has brought several species to low population levels. \n",
            "\n",
            "Bill Clinton running for Congress in 1974 contemplated but did not buy votes to steal the election.\n",
            "\n",
            "Bill Clinton contemplated buying black votes in order to steal the election back in 1974.\n",
            "\n",
            "1. While running for Congress, Bill Clinton contemplated buying votes in order to win, but he didn't.\n",
            "\n",
            "1. While running for Congress in 1974, Clinton contemplated buying black votes, but ultimately did not.\n",
            "\n",
            "wouldn't result in either donor's name being inscribed in granite, or being honored by a dinner or ceremony.\n",
            "\n",
            "wouldn't normally result in the donor's name in granite with a fancy dinner or ceremony; and/or\n",
            "\n",
            "wouldn't result in either the donor's name being inscribed in granite or honored at a glitzy dinner; and/or\n",
            "\n",
            "It wouldn't normally result in the donor's name being inscribed in granite or their honoring at a ceremony.\n",
            "\n",
            "wouldn't normally result in either the donor's name being inscribed or the donor being honored at a ceremony\n",
            "\n",
            "Hemingway's final manuscript, True at First Light, contains some of his funniest and most complex work. \n",
            "\n",
            "True at First Light, written by Ernest Hemingway contains his funniest and most complex work.\n",
            "\n",
            "writes that Ernest Hemingway's final manuscript, \"True at First Light,\" contains some of his funniest and most complex work.\n",
            "\n",
            "Ernest Hemingway's soon-to-be published final manuscript, True at First Light, contains some of his funniest and most complex work.\n",
            "\n",
            "writes that Ernest Hemingway's soon-to-be published final manuscript, True at First light, contains some of his funniest and most complex work.\n",
            "\n",
            "Newsweek says organic food often contains pesticides from rainwater and is no more nutritious than regular.\n",
            "\n",
            "Organic food often contains pesticides from rainwater or dust and is not more nutritious or tasty.\n",
            "\n",
            "Newsweek says organic food has pesticides from rainwater/dust & isn't more nutritious than other food.\n",
            "\n",
            "Pesticides from rainwater/dust often makes organic food no more nutritious than conventionally grown fare.\n",
            "\n",
            "Newsweek says organic food has pesticides from rainwater & is no more nutritious than regular grown food.\n",
            "\n",
            "I don't always agree with Roger Milliken, but he is an man from whom Paul Krugman could learn.\n",
            "\n",
            "As for Roger Milliken, I don't always agree with him, but he is an honest and honorable man. \n",
            "\n",
            "I don't always agree with Roger Milliken, but he is an honorable man whom Paul Krugman could learn.\n",
            "\n",
            "As for Roger Milliken he is an honest and honorable man from whom Paul Krugman could learn a lot.\n",
            "\n",
            "I don't always agree with him, but he is an honest and honorable man.\n",
            "\n",
            "Yeah, he's dead, bent over the trunk of a Trans Am, face against the window.\n",
            "\n",
            "In a parking lot he's dead, bent over a Trans Am, face against the rear window. \n",
            "\n",
            "He's dead in a parking lot, bent over a car's trunk, face against the window.\n",
            "\n",
            "In a parking lot he's dead,bent over the trunk of a Trans Am, face on the window\n",
            "\n",
            "That flying car Popular Science has been putting on the cover every year since 1939 is finlly really about to happen\n",
            "\n",
            "Its that flying car that Popular Science has been putting on the cover every year since 1939.\n",
            "\n",
            "It's that flying car Popular Science has been putting on the cover every year since 1939..., says the BBC.\n",
            "\n",
            "The BBC says that the flying car Popular Science has been putting on its cover since 1939 is about to really exist.\n",
            "\n",
            "Actual event at Monday's Drama League benefit: Mary Tyler Moore, Diane Sawyer, Katie Couric, and Liz Smith.\n",
            "\n",
            "Actual event at Drama League benefit: Mary Tyler Moore, Diane Sawyer, Katie Couric, and Liz Smith dance. \n",
            "\n",
            "Drama League event: Mary Tyler Moore, Diane Sawyer, Katie Couric, Liz Smith dance in a Cabaret number.\n",
            "\n",
            "Mary Tyler Moore, Diane Sawyer, Katie Couric, and Liz Smith dance in a number from Cabaret.\n",
            "\n",
            "Monday Night event benefit: Mary Tyle Moore, Diane Sawyer, Katie Couric, and Liz Smith dance from Carabet\n",
            "\n",
            "A WP piece on the president's office managing his initiative on race mentions that it has a staff of 21 and a budget of five million dollars.\n",
            "\n",
            "WP reported the president's newly created office managing his race and reconciliation initiative has 21 staff and a five million dollar budget. \n",
            "\n",
            "Martina Hingis seems to resent her absent mother, although I've not seen her in a clinical setting.\n",
            "\n",
            "Apologetic Martina Hingis resents her absent mother, though I haven't seen her clinically.\n",
            "\n",
            "Apologetic tennis great Martina Hingis seems to hate her mother, while I haven't had her as a client.\n",
            "\n",
            "Apologetic tennis great Martina Hingis seems to resent her absent mother.\n",
            "\n",
            "In two hour long conversations, I gave Gates the opportunity to confirm or deny nearly every matter of fact in this article.\n",
            "\n",
            "In two hour long conversations, I gave Gates the opportunity to confirm or deny every matter of fact in this article.\n",
            "\n",
            "I would like to make clear that I gave Gates the opportunity to confirm or deny every matter of fact in this article. \n",
            "\n",
            "I would like to clarify that in two hourlong conversations, I gave Gates the opportunity to confirm or deny this article.\n",
            "\n",
            "In two hourlong conversations, I gave Gates the opportunity to confirm or deny nearly every matter of fact in this article.\n",
            "\n",
            "Notes of Katha Politt-Andrew Sullivan in \"The Book Club\" about Unauthorized Freud: Doubters Confront a Legend.\n",
            "\n",
            "Regarding the Pollitt-Andrew dialogue in \"The Book Club\", about my anthology, Unauthorized Frued\n",
            "\n",
            "Notes on Pollitt-Sullivan dialogue in \"The Book Club\" on my anthology Unauthorized Freud: Doubters Confront a Legend\n",
            "\n",
            "Katha Pollitt-Andrew Sullivan dialogue in \"The Book Club\" about anthology Unauthorized Freud.\n",
            "\n",
            "The TL reports that Alex Balk knew that a pleas was received to free Augusto Pinochet.\n",
            "\n",
            "The Times of London reports that Alex Balk knew of the Pope's plea to free Augusto Pinochet.\n",
            "\n",
            "The Foreign Office received a plea from the pope to free Augusto Pinochet.\n",
            "\n",
            "The pope appealed to the Foreign Office to free Augusto Pinochet, says the Times of London.\n",
            "\n",
            "Times of London says Balk knew the Foreign Office received the Pope's plea to free Pinochet.\n",
            "\n",
            "The Pollock stamp and Johnson stamp eliminate the cigarette from each man's mouth, and the aldulterous gleam in Pollock's eye.\n",
            "\n",
            "A and B. The new Pollock stamp and an earlier Johnson stamp, eliminate each man's cigarette, and the adulterous gleam from Pollock's eye.\n",
            "\n",
            "The new Pollock stamp and an earlier Johnson stamp, eliminate the cigarette from each man's mouth, and the gleam from Pollock's eye.\n",
            "\n",
            "A and B. The Pollock stamp and the Johnson stamp, based on photographs which eliminates the cigarettes and a gleam from Pollock's eye. \n",
            "\n",
            "TheStreet.com first said the deal was worth $180 billion, after saying it was worth $125 billion.\n",
            "\n",
            "TheStreet.com said the deal was worth $125 billion, then by the end of the day said it was worth $180 billion.\n",
            "\n",
            "There are people who talk a lot, observes Monica Lewinsky's lawyer William H. Ginsburg, \"and . . . they may tell fibs, lies, exaggerations, oversell.\"\n",
            "\n",
            "People who talk a lot, says Monica Lewinsky's lawyer William Ginsburg, \"may tell fibs, lies, exaggerations, oversell.\"\n",
            "\n",
            "Monica Lewinsky's lawyer William H. Ginsberg observed that many people gossip and spread rumors.\n",
            "\n",
            "There are people who talk a lot, says William Ginsburg, \"and as part of that scenario, peccadilloes, they may tell fibs, lies, exaggerations, oversell.\"\n",
            "\n",
            "L'affaire Brown was 1 story in Slate. When you need a roundup, you might want to re-examine your priorities.\n",
            "\n",
            "When you reach the point of needing a roundup, you might want to re-examine your editorial priorities.\n",
            "\n",
            "L'affaire Brown was worth a story. But when needing a roundup, you might want to re-examine your priorities.\n",
            "\n",
            "L'affaire was worth one story to Slate. When you reach the point of needing a roundup, re-examine your priorities.\n",
            "\n",
            "L'affaire Brown might want to re-examine his editorial skills because he is worth only one story in Slate.\n",
            "\n",
            "The LAT emphasizes the Supreme Court's assertion on assisted suicide which don't involve constitutional issue.\n",
            "\n",
            "The LAT emphasizes the Supreme Court's general stance on assisted suicide laws.\n",
            "\n",
            "The LAT, more than the NYT, emphasizes the Supreme Court's stance on assisted suicide. They are the province of the individual states.\n",
            "\n",
            "The LAT supports Supreme Court's stance on assisted suicide laws that they involve no constitutional issue but are up to individual states.\n",
            "\n",
            "What follows is a taxonomy of the Senate, an attempt to classify senators.\n",
            "\n",
            "It attempts to classify and explain their actions through a taxonomy of the Senate.\n",
            "\n",
            "A taxonomy of the Senate, an attempt to classify senators and explain their doings.\n",
            "\n",
            "This just in regarding Bush's smirk from the University of North Carolina's John Shelton Reed. \n",
            "\n",
            "This just in (via e-mail) regarding George W. Bush's smirk at University of North Carolina, John Shelton Reed.\n",
            "\n",
            "This just in regarding George W. Bush's smirk from UNC's John Shelton Reed, who co-edits Southern Cultures magazine:\n",
            "\n",
            "This just in regarding George W. Bush's smirk from UNC's John Shelton Reed, who co-edits Southern Cultures magazine.\n",
            "\n",
            "Next year, let's switch to Gay Pride Street Fair -- good exercise, culture, and cheap socks.\n",
            "\n",
            "Let's move from the Gay Pride Parade to the Gay Pride Street Fair--exercise, cultural celebration, and cheap socks.\n",
            "\n",
            "Let's switch from Gay Pride to the Gay Pride Street Fair--exercise, cultural celebration, and a chance to buy socks.\n",
            "\n",
            "Let's switch to the Gay Pride Street Fair--good exercise, cultural celebration, and a chance to buy inexpensive socks.\n",
            "\n",
            "The Gay Pride Parade will change it's name next year to Gay Pride Street Fair.\n",
            "\n",
            "Envirotest had also been a donor to the national ALA, giving a total of more than $100,000 to the charity between '94 and '95.\n",
            "\n",
            "Envirotest has been a donor to the ALA, giving more than $100,000 to them between '94 and '95, according to tax filings.\n",
            "\n",
            "Envirotest was a generous donor to the national ALA, giving more than $100,000 to the charity between '94 & '95, according to taxes.\n",
            "\n",
            "Envirotest gave a total of more than $100,000 to the national ALA between '94 and '95. \n",
            "\n",
            "On the other hand, pay is terrific, notes researcher Miriam Kleinman, \"Some of those people have limousines picking them up.\"\n",
            "\n",
            "The pay is terrific, says researcher Miriam Kleinman, who works t for a class-action law firm. \"Some people have limousines picking them up.\"\n",
            "\n",
            "The pay is terrific, notes Kleinman, who works the other side of the street for a law firm: \"Some of those people have limousines picking them up.\" \n",
            "\n",
            "On the other hand, the pay is terrific, notes researcher Miriam Kleinman \"Some of those people have limousines picking them up.\"\n",
            "\n",
            "I [remember] the meeting, says Bill Clinton in Washington's ongoing sexual and legal battles, \"and I told the truth.\"\n",
            "\n",
            "I have a clear memory of the meeting, says Bill Clinton in his ongoing sexual/legal battles, \"& I told the truth.\"\n",
            "\n",
            "I have a clear memory of the meeting, said Bill Clinton in the ongoing legal battles, \"and I told the truth.\"\n",
            "\n",
            "I have a clear memory of the meeting, Bill Clinton in Washington's ongoing sexual and legal battles, \"I told truth.\"\n",
            "\n",
            "The papers note that upon his victory, Kim pledged to implement the agreed on IMF-crafted economic bailout.\n",
            "\n",
            "Upon his victory, Kim pledged to implement the IMF-crafted economic bailout.\n",
            "\n",
            "Kim pledged to implement the IMF-crafted economic bailout that was already agreed to by the current government.\n",
            "\n",
            "The papers note that upon his victory, Kim pledge to implement the economic bailout.\n",
            "\n",
            "The papers, Kim pledged to implement the IMF-crafted economic bailout. \n",
            "\n",
            "Edward Jay Epstein sent the following e-mail: \"Preliminary Concerns I Have About Monica and Other Babes From Beverly Hills.\" \n",
            "\n",
            "Epstein sent Chatterbox an email with subject: \"Preliminary Concerns I Have About Monica and Other Babes From Beverly Hills.\"\n",
            "\n",
            "Edward Jay Epstein has sent an e-mail, subject \"Preliminary Concerns I have About Monica and Other Babes From Beverly Hills.\"\n",
            "\n",
            "Edward Jay Epstein sent this e-mail, subject: \"Preliminary Concerns I Have About Monica and Other Babes From Beverly Hills.\"\n",
            "\n",
            "Writer Edward Jay Epstein sent Chatterbox this e-mail: \"Preliminary Concerns I Have About Monica & Other Beverly Hills Babes\"\n",
            "\n",
            "It's called wing-rowing, the burdened armsunbending, yielding, striking balance, walking the invisible line drawn ahead.\n",
            "\n",
            "It's called wing-rowing, the wing-burdened armsunbending, yielding, walking the invisible line drawnjust ahead in the air.\n",
            "\n",
            "Wing-rowing, wing-burdened arms bending yielding, and striking a balance, walking.\n",
            "\n",
            "It's called wing-rowing, yielding, striking a balance, walking the invisible line drawn in the air, first sign the slur,\n",
            "\n",
            "Wing-rowing is the yielding, striking a balance, walking the white invisible line in the air, first sign the slur.\n",
            "\n",
            "The dogs more sullen father up, the churches below, the sunlit river, the bridge empty, the outer half hidden, I was shocked by the distance.\n",
            "\n",
            "I was shocked by the sudden distance, the dogs more sullen the farther up you went.\n",
            "\n",
            "the dogs more sullen, and churches below, the sunlight on the river, the bridge empty, the outer one hidden, I was shocked by the distance\n",
            "\n",
            "The dog's more sullen the farther you go. I was shocked by the sudden distance of the churches below, the sunlight on the river, & empty bridge.\n",
            "\n",
            "More than 70 percent of Swiss voters approved tougher rules involving asylum and rejected a proposal for maternity leave.\n",
            "\n",
            "Over 70% of Swiss voters approved tougher rules for asylum-seekers and rejected maternity leave, concerned that someone might abuse the law.\n",
            "\n",
            "More than 70 percent of Swiss voters approved tougher rules for maternity leave.\n",
            "\n",
            "Over 70% of Swiss voters approved tougher rules for asylum-seekers and rejected a maternity leave proposal, fearing abuse by incoming babies.\n",
            "\n",
            "Over 70 percent of Swiss voters approved restricting asylum-seekers, rejecting proposals for maternity leave, concerned that baby might abuse laws.\n",
            "\n",
            "Last week, the federal courts accomplished something no one has been able to: They said \"no\" to the Secret Service.\n",
            "\n",
            "The federal court said \"no\" to the secret service last week, something no other government or private organization has done before.\n",
            "\n",
            "Last week, the federal courts said \"no\" to the Secret Service, something no government agency, person, or committee has accomplished before.\n",
            "\n",
            "Last week, the federal courts accomplished something no government or private entity has been able do: They said \"no\" to the Secret Service.\n",
            "\n",
            "The heart in the mouth melodious, which starts chanting, the crooning, the long lyricsilences, the song of our undoing. \n",
            "\n",
            "the liquidy liquid, the melodious heart in mouth, starts the chanting, the crooning, the long lyrics and silences, undoing\n",
            "\n",
            "the liquid notes too liquid, the heart in the mouth melodious, too close, which starts the song of our undoing.\n",
            "\n",
            "notes too liquid, heart in the mouth, too close, which starts chanting, crooning, lyric silences, song of our undoing.\n",
            "\n",
            "The liquid too liquid, the heart melodious, too close, starts chanting, crooning long lyric silences, the song of undoing.\n",
            "\n",
            "Investigative commission headed by Lawrence Poitras was set up in 1996 to look into cover-ups and threads about a botched investigation.\n",
            "\n",
            "The investigative commission headed by former Chief Justice Mr. Poitras was set up to look into allegations of cover-ups and threats.\n",
            "\n",
            "The investigative commission headed by Lawrence Poitras was set up in 1966 to look into cover-ups and threats in drug investigations.\n",
            "\n",
            "The investigative commission headed by former Chief Justice Poitras was set up to look into allegations of cover-ups and threats.\n",
            "\n",
            "Cow, produced by Jim Riswold, Alice Chevalier, and John Jay, with animation from Gordon Clark and Peter DeSeve.\n",
            "\n",
            "Cow, produced by Jim Riswold, Alice Chevalier, and John Jay, with animation help from Gordon Clark and Peter DeSeve.\n",
            "\n",
            "Cow, produced by Riswold, Chevalier, and Jay of W&K, with animation assistance from Clark and DeSeve of WAH.\n",
            "\n",
            "Cow, produced by Riswold, Chevalier, and Jay, with animation assistance from Clark and DeSeve of Wildbrain Animation House.\n",
            "\n",
            "Cow was produced by Jim Riswold, Alice Chevalier, and John Jay with assistance by Gordon Clark and Peter DeSeve.\n",
            "\n",
            "Despite Kaiser and Janeway's invitation to answer with generalities, McPherson answers specifics about his tobacco business:\n",
            "\n",
            "McPherson answers by getting into specifics about his firm's tobacco business: \n",
            "\n",
            "Despite Kaiser and Janeway's invitation to answer with generalities, McPherson answers by getting into tobacco business specifics:\n",
            "\n",
            "Despite Kaiser and Janeway's invitation to answer this question with generalities, McPherson gets into specifics about his firm's business\n",
            "\n",
            "Despite Kaiser and Janeway's invitation to answer questions, McPherson answers by talking about his firm's tobacco business.\n",
            "\n",
            "The coverage plays to Washington's preference for politics, there is no word about any of the family planning organizations.\n",
            "\n",
            "The coverage plays into Washington's preference for politics over substance: there isn't a word about those family planning organizations and to what they facilitate abortions. \n",
            "\n",
            "The coverage plays into Washington's preference for politics over substance: there isn't a word about family planning organizations and to what extent they facilitate abortions.\n",
            "\n",
            "The coverage plays into Washington's preference for politics over substance: there's nothing about international family planning organizations & their abortion facilities.\n",
            "\n",
            "The coverage plays into Washington's preference for politics over substance: not a word about those international family planning organizations and to how they aid abortions.\n",
            "\n",
            "(Editor's note: No response exploited the suffering of anyone afflicted with a dreadful disease.)\n",
            "\n",
            "(Editors note: No response exploited the suffering of anyone with a disease; all target profit-making medicine, California foolishness and, or course, the sisters.)\n",
            "\n",
            "No exploitation of suffering by diseased; all profit-making medicines, California foolishness and, surviving Gabor Sisters, if existent. \n",
            "\n",
            "(Editor's note: No response exploited the suffering of anyone with a dreadful disease; all profit-making medicine, and, of course, the surviving Gabor sisters.)\n",
            "\n",
            "(Editor's note: No response exploited anyone afflicted with a disease; all targeted profit-making medicine, CA foolishness and any surviving Gabor sisters.)\n",
            "\n",
            "Jacob Weisberg's article \"Washington Swingers\" was both inaccurate and unfair when it comes to Alexis Herman.\n",
            "\n",
            "Weisberg's article was inaccurate and unfair about Alexis Herman, President Clinton's nominee for secretary of labor.\n",
            "\n",
            "Washington Swingers was inaccurate and unfair about Alexis Herman, Clinton's nominee to be secretary of labor.\n",
            "\n",
            "Washington Swingers was inaccurate and unfair when it comes to Herman, Clinton's nominee to be secretary of labor. \n",
            "\n",
            "Prior press reports wondered if Suharto's health would impair his ability to lead his country out of crisis, but neither Times stories emphasize this.\n",
            "\n",
            "Neither of today's Times stories emphasize the 76-year-old Suharto's failing heath and his ability to lead his country out of the current crisis.\n",
            "\n",
            "Prior press reports have wondered if the 76-year-old Suharto's failing health would impair his ability to lead his country out of the current crisis.\n",
            "\n",
            "Although prior press reports have wondered if Suharto's health would impair his ability to lead his country, neither of today's Times stories said this.\n",
            "\n",
            "Neither of Times' stories for today, report Suharto's failing health as an impairment in leading his country.\n",
            "\n",
            "Dole is more willing to speak of being shot in World War II, and his recovery from wounds that almost killed him and left his right shoulder lame.\n",
            "\n",
            "[Dole is] increasingly willing to speak of being shot in WWII and his recovery from wounds that almost killed him and left his shoulder disabled.\n",
            "\n",
            "More revealingly, Dole is willing to speak of being shot in WWII, and of his lengthy recovery that nearly killed him and his right shoulder.\n",
            "\n",
            "Dole is willing to speak about his lengthy recovery from almost fatal wounds in WWII that left his right shoulder incapacitated.\n",
            "\n",
            "All the papers lead with Hurricane Bret, while continuing to update on earthquake relief efforts in Turkey.\n",
            "\n",
            "Papers lead with Hurricane Bret, while offering updates on relief efforts in the Turkish earthquake zone.\n",
            "\n",
            "Headlines reference pitiful Hurricane Bret, while ignoring updates on Turkish earthquake relief.\n",
            "\n",
            "All the papers lead with weak Hurricane Bret, while continuing to give updates on relief efforts in Turkey.\n",
            "\n",
            "Papers lead with weaker Hurricane Bret, while continuing to front updates on relief efforts in Turkey.\n",
            "\n",
            "Time derides the author of Men Are From Mars, Women Are From Venus as a huckster making millions from vulnerable couples.\n",
            "\n",
            "Time derides John Gray as an egomaniacal huckster who's making millions selling banalities to vulnerable couples.\n",
            "\n",
            "John Gray,the author of Men Are From Mars` is making millions selling banalities to vulnerable couples.\n",
            "\n",
            "In the last couple of weeks, I have read Slate, Salon, the Wall Street Journal, and e-texts of various novels and short stories.\n",
            "\n",
            "Among the other places I have been reading Slate, Salon, an the Wall Street Journal , and the e-texts of various novels and short stories\n",
            "\n",
            "In the last couple of weeks I have been reading Slate, Salon, the Wall Street Journal, and the e-texts of various novels and short stories.\n",
            "\n",
            "The other places I've been reading Slate, Salon, Wall Street Journal, and e-texts of various novels and short stories, in former weeks.\n",
            "\n",
            "During the last two weeks, I've read Slate, Salon, an e-version of the Wall Street Journal, and the various e-texts.\n",
            "\n",
            "After research I am able to report on the the 207 channels available with the packages I have, or at least what was available. \n",
            "\n",
            "After researching, I am able to report on the content available during prime time of the 207 channels available with the packages I have.\n",
            "\n",
            "I am able to report on the content of the 207 channels available, or at least what was available during prime time in one evening.\n",
            "\n",
            "Participants are invited to submit a domain name that is already taken along with an amusing and available alternative.\n",
            "\n",
            "Participants are asked to submit a domain name that is already taken, along with an amusing and available alternative.\n",
            "\n",
            "Participants are invited to submit a pair of domain names, one already taken, the other an amusing available alternative.\n",
            "\n",
            "Participants should submit a pair, like the examples, of a domain name that's already taken & an amusing, available one.\n",
            "\n",
            "Participants are to find sentence in a publication that embodies consumption and fatuousness better than the following\n",
            "\n",
            "Participants are invited to find a sentence in a publication that embodies conspicuous consumption better than the New York Times \"Home\" section.\n",
            "\n",
            "People are invited to try to find a published sentence that embodies conspicuous consumption better than last week's New York Times. \n",
            "\n",
            "Participants are invited to find a sentence that embodies conspicuous consumption and fatuousness better than the following, from last week's Times.\n",
            "\n",
            "Participants look for a sentence in actual publications that embody consumption and fatuousness better than last week's NY Times's \"Home\" section:\n",
            "\n",
            "I aim to occupy the same ground claimed by Abraham Lincoln in his sixth debate against Douglas.\n",
            "\n",
            "I aim to occupy the same ground claimed by Lincoln in his 6thh debate against S.A. Douglas.\n",
            "\n",
            "I aim to occupy the same high ground claimed by Lincoln in his 6th debate against Douglas:\n",
            "\n",
            "I aim to occupy the same ground claimed by Lincoln in his sixth debate against Douglas. \n",
            "\n",
            "My aim is to take the same stance as Abraham Lincoln in his 6th debate vs Douglas.\n",
            "\n",
            "The WP observes that perjury or obstruction of justice charges against Clinton would be based on his conduct in a defunct case.\n",
            "\n",
            "WP makes the point that its not obvious, observing that perjury charges against Clinton would be based on his conduct is now dead.\n",
            "\n",
            "The WP observes that any charges against Clinton would be based on his conduct in a now-dead case.\n",
            "\n",
            "The WP is observing any perjury or obstruction of justice charges against Clinton.\n",
            "\n",
            "The WP and LAT fronts describe how, hackers have broken into unclassified Pentagon networks to examine and alter payroll and personnel data.\n",
            "\n",
            "The WP & LAT fronts describe how computer hackers have broken into unclassified Pentagon networks to examine and maybe alter data.\n",
            "\n",
            "In the past 11 days, computer hackers have broken into unclassified Pentagon networks to examine and alter payroll and personnel data.\n",
            "\n",
            "The WP and LAT fronts describe how hackers have broken into Pentagon networks to examine and possibly alter payroll and personnel data.\n",
            "\n",
            "WP and LAT fronts describe how, the last eleven days, computer hackers have broken into Pentagon networks to possibly alter personnel data.\n",
            "\n",
            "I venture to propose that a bell be attached by a ribbon to the Cat neck.\n",
            "\n",
            "I propose a bell be procured, attached to a ribbon, and put around the neck of the Cat.\n",
            "\n",
            "I venture to propose that a small bell be attached by a ribbon around the Cat's neck.\n",
            "\n",
            "I propose a small bell be procured and attached to the Cat's neck by a ribbon.\n",
            "\n",
            "Premature post-mortems on the Kosovo conflict filled the front pages of the world's newspapers.\n",
            "\n",
            "The world's newspapers contains post-mortems on the Kosova conflict.\n",
            "\n",
            "Post-mortems of the Kosovo conflict filled the world's newspapers.\n",
            "\n",
            "Newspapers filled their front pages this weekend with premature post-mortems on the Kosovo conflict.\n",
            "\n",
            "The world's newspapers featured premature post-mortems on the Kosovo conflict on their front pages.\n",
            "\n",
            "The new president of ABC News, David Westin, admitted his affair with ABC public relations executive Sherrie Rollins.\n",
            "\n",
            "The president of ABC News, David Westin, acknowledged his affair with Sherrie Rollins, wife of political consultant Ed Rollins. \n",
            "\n",
            "The president of ABC News acknowledged his affair with ABC executive Sherrie Rollins , wife of political consultant Ed Rollins.\n",
            "\n",
            "The newly appointed president of ABC News, David Westin, acknowledged his affair with Sherrie Rollins.\n",
            "\n",
            "The Senate vote to expand NATO and the European Union's  move toward a common currency makes nary a ripple.\n",
            "\n",
            "Int'l news - like the Senate vote on NATO and Europe's move toward a common currency - makes nary a ripple.\n",
            "\n",
            "News like the Senate vote to expand NATO, and the EU's move to a common currency, makes not a ripple.\n",
            "\n",
            "News, such as the vote to expand NATO, and the EU's move toward a common currency, is insignificant.        \n",
            "\n",
            "International news, Senate vote to expand NATO, and the EU's move toward common currency, makes no ripple.\n",
            "\n",
            "We challenge you to get from this page devoted to The Beatles to this page about beetles.\n",
            "\n",
            "This weeks puzzle challenge's you to get from Beatles tribute page to the eating habits of beetles page.\n",
            "\n",
            "In this week's puzzle, you will need to get from this page to a page with beetle eating habits.\n",
            "\n",
            "We challenge you to get from this page the eating habits of beetles.\n",
            "\n",
            "This weeks puzzle involves this page about The Beatles and literally the eating habits of beetles\n",
            "\n",
            "Look across the second row, which tells that firms with no employees in 1991 netted astounding jobs by 1993.\n",
            "\n",
            "The second row seems to say that firms with no employees in 1991 netted an astounding 1,898,600 jobs by 1993.\n",
            "\n",
            "Firms with no employees in 1991 netted an astounding 1,898,600 jobs by 1993.\n",
            "\n",
            "The second row seems to tell you that firms with no employees in 1991 netted 1,898,600 jobs by 1993. \n",
            "\n",
            "Look at the second row, which tells you that firms in 1991 without employees netted 1,898,600 jobs by 1993.\n",
            "\n",
            "When the Ten Commandments can't be place in courtrooms and Moses can, and school kids are harassed for practicing their own faith, something's wrong.\n",
            "\n",
            "9. \"When the Ten Commandments is not freely accepted in the courtroom, and schoolchildren aren't allowed to practice their faith, something is wrong.\"\n",
            "\n",
            "9. \"When the Ten Commandments can't be placed in courtrooms and schoolchildren are harassed by school officials for privately practicing their faith, something is wrong.\"\n",
            "\n",
            "The Times says thiswas confirmed by a White House aide, while the Post says the White House declined to comment about it.\n",
            "\n",
            "The Times says this meeting was confirmed by a White House aide, while the Post says the White House declined to comment about it.\n",
            "\n",
            "The Times says this meeting was confirmed, while the Post says the White House didn't comment & refused to release relevant information.\n",
            "\n",
            "The Times says this meeting was confirmed, while the Post says the White House declined to comment and refuses to release entry logs.\n",
            "\n",
            "And what fun if a youngster misunderstands the custom just a little.\n",
            "\n",
            "And what fun if a child misunderstood, imagining she will grow up to marry Winnie the Pooh.\n",
            "\n",
            "Misunderstanding the custom, some kids may imagine she will grow up to marry Winnie the Pooh\n",
            "\n",
            "What fun when a youngster misunderstands and imagines she will marry Winnie The Pooh.\n",
            "\n",
            "What fun if a youngster misunderstands and imagines she will grow up to marry Pooh.\n",
            "\n",
            "This years elections are almost enough to make one give up on democracy- or the idea that they are more devoted to peace than others.\n",
            "\n",
            "This election year is enough to make one give up on the idea that democracies are more committed to peace than other forms of government.\n",
            "\n",
            "This year of elections is almost enough to make one give up on democracy--or at least on the idea that democracies are committed to peace.\n",
            "\n",
            "This years elections is enough to make one give up on democracy or the idea that it is more committed to peace than other governments.\n",
            "\n",
            "This election year is almost enough to make one give up on democracy, or the idea that democracies are more committed to peace than others.\n",
            "\n",
            "Though Clinton emulates JFK in every other way, he'd be a fool to steal his MO d'amour.\n",
            "\n",
            "Despite Clinton emulating JFK , he'd be a fool to steal his MO d'amour . Here's why:\n",
            "\n",
            "Though Clinton emulates JFK, he'd be a fool to steal Kennedy's MO d'amour . Here's why:\n",
            "\n",
            "Though Clinton emulates JFK in every way, he'd be a fool to steal Kennedy's MO d'amour.\n",
            "\n",
            "Tina Brown, \"Of course, we needed a new format, one that would reflect...\"\n",
            "\n",
            "Tina Brown, same magazine, same piece, same lame figure of speech.\n",
            "\n",
            "2. Tina Brown, same magazine, piece, and lame expression: \"Of course we needed a new format...\"\n",
            "\n",
            "Tina Brown, same magazine, piece, figure of speech: \"We need a new format, one that would reflect..\"\n",
            "\n",
            "Tax cuts to benefit the wealthy brushed aside the warnings of the Federal Reserve Chairman Greenspan and well known works of Jane Goodall. \n",
            "\n",
            "REPUBLICAN TAX CUTS TO BENEFIT WEALTHY,Brushing aside the warnings of Federal Reserve Chairman Greenspan and the widely accepted research of Jane Goodall.\n",
            "\n",
            "REPUBLICAN TAX CUTS TO BENEFIT WEALTHY, MONKEYS Brushing aside the warnings of Greenspan and the research of Goodall, House Republicans pushed ahead with\n",
            "\n",
            "Brushing aside the warnings of Federal Reserve Chairman Greenspan and Jane Goodall, House Republicans pushed ahead with...\n",
            "\n",
            "Brushing aside the warnings of Federal Reserve Chairman Greenspan and the widely accepted research of Jane Goodall, House Republicans pushed ahead with ...\n",
            "\n",
            "I realized that, had Simon followed Lerner's advice, we'd have had to go get to the theater at 10:30 in the morning to read up.\n",
            "\n",
            "And I realized that we'd have had to get to the theater at 10:30 in the morning to read up on the textual footnotes.\n",
            "\n",
            "I realized, had Simon followed Lerner's advice by writing musicals, we needed to arrive early to the theater to read up on the footnotes.\n",
            "\n",
            "If we would have followed Lerner's advice to start writing musicals, we'd have to go to the theater in the morning to review footnotes. \n",
            "\n",
            "I realized that, had Simon started writing musicals, we'd have had to get to the theater at 10:30am to read up on the footnotes.\n",
            "\n",
            "Maine is one of 48 states spending the $50 million a year Congress allocates for abstinence education.\n",
            "\n",
            "Maine, one of 48 states spending the $50m a year Congress allocates for abstinence education, is matching every $4 of federal money with $3 of state funds. \n",
            "\n",
            "Maine is 1 of 48 states spending the $50 million a year Congress allows for abstinence education. Every $4 of federal cash is matched with $3 of state funds.\n",
            "\n",
            "California and New Hampshire opted out of abstinence education where congress allocates $50 million, with $4 of federal money matched with $3 of state funds.\n",
            "\n",
            "A simpler observation is that some movies are badly imagined & written; nobody cares enough to do anything about it.\n",
            "\n",
            "Some movies are just badly imagined and badly written and nobody cares enough to do anything about it.\n",
            "\n",
            "Then, there's the observation that some movies are badly imagined and badly written, and nobody cares to fix it.\n",
            "\n",
            "There's a simpler observation that some movies are just badly imagined and badly written, and nobody cares.\n",
            "\n",
            " the simpler observation that movies are just badly imagined and badly written that no one cares.\n",
            "\n",
            "Asked how to respond to a rival company's gambit, the man looks out of the window and says simply, \"Napalm.\" \n",
            "\n",
            "Asked how to respond to rival company's gambit, the man looks out of the window of his NY office and says, \"Napalm.\"\n",
            "\n",
            "Asked how to respond to a rival's gambit, the businessman looks out his lavish New York office window, and says, \"Napalm.\"\n",
            "\n",
            "Asked how to respond to a rival's gambit, the man looks out of the window of his lavish New York office and says, \"Napalm\"\n",
            "\n",
            "Reba White Williams thinks its okay to put a telephone booth at any vacant spot, no matter how it looks.\n",
            "\n",
            "Reba Williams said, \"It seems anyone can put up a telephone booth in a vacancy with no consideration of how it looks.\"\n",
            "\n",
            "Williams said, \"It seems wherever there is a vacant spot, anybody can put up a telephone booth despite how it looks.\" \n",
            "\n",
            "In \"The Luck of the Irish,\" James Surowiecki makes blatantly false statements and omits many fundamental issues.\n",
            "\n",
            "In \"The Luck of the Irish,\" James Surowiecki lies and omits the real issues.\n",
            "\n",
            "James Surowiecki, \"The Luck of the Irish\", statements are false and he omits issues that are the real problems.\n",
            "\n",
            "In \"The Luck of the Irish,\" Surowiecki often lies, and omits many issues that are the real root of the problems.\n",
            "\n",
            "In The Luck of the Irish, James Surowiecki made false statements and omitted issues that were a problem.\n",
            "\n",
            "But for me, the revealing part of Earth in the Balance was the book's conclusion.\n",
            "\n",
            "The best part of Earth in the Balance was the part where Gore talks about sandpiles and how they changed his life.\n",
            "\n",
            "For me, the most revealing part of Earth in the Balance was the end where Gore talks about how sandpiles changed his life.\n",
            "\n",
            "The revealing part of Earth in the Balance was the conclusion,  about sandpiles and how they changed his life.\n",
            "\n",
            "Thomas Mann's essay \"This Man is My Brother\" is the most convincing picture of Hitlerism as an \"artist-phenomenon\".\n",
            "\n",
            "I reread Mann's 1938 Esquire essay, \"This Man Is My Brother,\" a picture of Hitlerism as an \"artist-phenomenon\"\n",
            "\n",
            "After reading Rosenbaum, I returned to Thomas Mann's, \"This Man Is My Brother,\" about Hitlerism as an \"artist-phenomenon\":\n",
            "\n",
            "After reading Rosenbaum, I read the essay, \"This Man Is My Brother,\" a picture of Hitlerism as an \"artist-phenomenon\":\n",
            "\n",
            "After reading Rosenbaum, I went back to the 1938 Esquire essay which is the most convincing of Hitlerism. \n",
            "\n",
            "The question was about Beatty's age as opposed to the age of some U.S. presidents and politicians who you probably thought were older than him.\n",
            "\n",
            "The question was about Warren Beatty's age as opposed to the age of some U.S. presidents who you probably thought were older than Warren Beatty.\n",
            "\n",
            "The question was about Warren Beatty's age, compared to the age of some presidents and politicians who you probably thought were older than Warren Beatty.\n",
            "\n",
            "The question was about Warren Beatty's age compared to the age of some U.S. politicians who you probably think are older than him, as they're not well lit.\n",
            "\n",
            "The question was about Warren Beatty's age as opposed to the ages U.S. politicians who you probably thought were older than Beatty because of the lighting.\n",
            "\n",
            "Newsweek's optimistic spin of Titanic's success: It's inspiring Hollywood to make movies targeted at women.\n",
            "\n",
            "Titanic's success: It's not inspiring Hollywood to make action blockbusters, it's inspiring them to make movies for women.\n",
            "\n",
            "Newsweek's spin of Titanic's success: It's inspiring Hollywood to make movies targeted at women, not $200 million action blockbusters.\n",
            "\n",
            "It's not inspiring Hollywood to make $200 million action blockbusters, it's inspiring them to make movies targeted at women.\n",
            "\n",
            "Newsweek's spin of Titanic's success: It's not inspiring Hollywood to make action movies, it's inspiring them to target women.\n",
            "\n",
            "He has shown through his behavior to me, my family, Israel and Jews that he is owed nothing less than my total loyalty.\n",
            "\n",
            "Yet Stein can now write: \"But I know of nothing in his behavior to all Jews that entitles him to anything less than my loyalty.\"\n",
            "\n",
            "Stein wrote, \"I know of nothing in his behavior to me, my family, or to Jews in general that entitles him to less than my loyalty.\"\n",
            "\n",
            "Yet Stein can now write:  \"His has been loyal to me Jews and Israel in general so he is owed my total loyalty.\"\n",
            "\n",
            "Stein wrote \"I know of nothing in his behavior that entitles him to anything less than my total loyalty.\n",
            "\n",
            "All readers of Goldhagen's book should take note of these studies, which convincingly and authoritatively dismantle its arguments\n",
            "\n",
            "Note 5: \"All readers of Goldhagen's book should take note these studies, which convincingly dismantle its arguments.\"\n",
            "\n",
            "Note 5: \"All readers of Goldhagen's book should take note of these studies, which, in line with historians, dismantle its arguments.\"\n",
            "\n",
            "Note 5: Readers of Goldhagen's controversial book should take note of much more needed studies.\n",
            "\n",
            "All who read Goldhagen's book should view these studies which, in line with serious historians, convincingly dismantle it's arguments.\n",
            "\n",
            "Michael Jordan has been talking to the Washington Wizards about becoming an executive with the team and even taking on an ownership stake. \n",
            "\n",
            "WP reports Michael Jordan is talking to the Washington Wizards about being a team executive and perhaps even getting an ownership stake.\n",
            "\n",
            "The WP sports exclusive claims Michael Jordan may become an executive with the Washington Wizards and may take an ownership stake.\n",
            "\n",
            "The WP fronts an exclusive: Michael Jordan has been talking to the Washington Wizards about becoming an executive and becoming an owner. \n",
            "\n",
            "The WP states: Michael Jordan has been talking to the Wizards about possibly becoming an executive and even taking on an ownership stake.\n",
            "\n",
            "The X-acto Knife Award for Creative Editing goes to the movie Sleepy Hollow. Their NYT ads feature Newsweek quote:\n",
            "\n",
            "The X-acto Knife Award for Creative Editing goes to the promoters of the movie Sleepy Hollow.\n",
            "\n",
            "The X-acto Knife Award for Creative Editing goes to \"Sleepy Hollow\" promoters. Their ads feature a Newsweek quote:\n",
            "\n",
            "X-acto Knife Award for Creative Editing goes to Sleepy Hollow.\n",
            "\n",
            "The X-acto Knife Award goes to the promoters of Sleepy Hollow.\n",
            "\n",
            "The complexity of AOL's acquisition of Time Warner is exhibited in the fact that no one knows how much the deal was worth.\n",
            "\n",
            "One apparent thing about AOL's acquisition of Time Warner is that no one seemed able to agree on how much the deal was worth.\n",
            "\n",
            "One of the things about AOL's acquisition of Time Warner is the fact that no one seemed to agree on how much the deal was worth.\n",
            "\n",
            "The fact that no one was able to agree on how much the deal was worth shows the complexity of AOL's acquisition of Time Warner.\n",
            "\n",
            "AOL's acquisition of Time Warner was complex.  No one seemed able to agree on just how much the deal was worth.\n",
            "\n",
            "The Postal Service's advertising has drawn fire in the past--in 1992, it spent $90 million advertising in the Olympics Spain, and France.\n",
            "\n",
            "The Postal Service has spent a lot of money on advertising, ranging for $90 million in 1992, to $7 million in 1994.\n",
            "\n",
            "The Postal Service's advertising campaigns have drawn fire-in 1992,it spent $90 million in the Olympics in Barcelona, and France;and developing a new logo cost $7 million\n",
            "\n",
            "The Postal Service's advertising spent $90 million in '92 advertising in Barcelona, Spain, Albertville, & France Olympics. In '94, they spent $7 million on a logo.\n",
            "\n",
            "The Postal Service spent $90 million advertising the Olympics in Barcelona,Spain, and Albertville, France and $7 million for a new logo.\n",
            "\n",
            "Distraughtly Murphy said:\"If there are two or more ways to do something and one of those results in a catastrophe,then someone will do it that way.\"\n",
            "\n",
            "Murphy proclaimed the version of the famous maxim: \"If there are ways to do something and it results in a catastrophe, then someone will do it.\"\n",
            "\n",
            "This report by Steven Erlanger of the New York Times, lists NATO Alliance aliases from the Serbian Information Ministry. \n",
            "\n",
            "This is a list of terms used to refer to the NATO alliance and its members, reports Steven Erlanger in the New York Times .\n",
            "\n",
            "This is a list used to refer to the NATO alliance, by order of the Serbian Information Ministry.\n",
            "\n",
            "This is a list of terms used to refer to the NATO alliance and its members reports Steven Erlanger.\n",
            "\n",
            "This is a list of terms used to refer to members of NATO alliance by order of the Serbian Information Ministry.-Steven Erlanger\n",
            "\n",
            "Susan Page reported that President Clinton would make a recess appointment of Bill Lann Lee to the job the Senate won't confirm, assistant AG for civil rights\n",
            "\n",
            "Breaking news, Susan Page reports that President Clinton would appoint Bill L. Lee as the Civil Rights Assistant Attorney \n",
            "\n",
            "Susan Page reported that President Clinton would make a January recess appointment of Bill Lann Lee.\n",
            "\n",
            "Susan Page reported President Clinton will appoint Bill Lann Lee to the job that Senate won't confirm, assistant attorney general for civil rights.\n",
            "\n",
            "Pons noted that Popeye the gelding has been tugged so many times that he's developed a curvature.\n",
            "\n",
            "Pons noted that Popeye, has been tugged to the side so many times, he's developed a curvature.\n",
            "\n",
            "Pons noted that Popeye has been tugged to the side so many times, he's developed a curvature.\n",
            "\n",
            "Popeye, the gelding, has been tugged to the side so many times he's developed a pronounced curvature.\n",
            "\n",
            "Pons noted that poor Popeye has developed a pronounced curvature, due to being tugged so many times.\n",
            "\n",
            "Is it your experience that language experts are challenged with greater regularity by the public than, say, experts on math?\n",
            "\n",
            "Are experts on language challenged more than experts on math by the general public?\n",
            "\n",
            "Is it your experience that experts on language are challenged with greater regularity than experts on math? \n",
            "\n",
            "Do you find language experts are challenged more often by the public than (barring evolutionists) experts on math?\n",
            "\n",
            "Would you agree that experts on language are challenged more by the general public than, say, experts on math? \n",
            "\n",
            "Traditions in the West are  hard to break, but we find this to be egregious, says  Andrea Lococo.\n",
            "\n",
            "Traditions in the West are hard to break, but we find this to be egregious, says Andrea Lococo, coordinator.\n",
            "\n",
            "Western traditions can be hard to break, but we find this to be shocking - Andrea Lococo.\n",
            "\n",
            "Traditions are sometimes hard to break, but this one is egregious, says coordinator Andrea Lococo. \n",
            "\n",
            "Rocky Mountain coordinator Andrea Lococo says traditions in the West are hard to break, but this is egregious.\n",
            "\n",
            "President Clinton has not kept the drug issue a top issue with society.\n",
            "\n",
            "To the extent that a president can keep the issue at a roiling boil, President Clinton has not.\n",
            "\n",
            "President Clinton has not keep the drug issue at a roiling boil in society.\n",
            "\n",
            "President Clinton has not kept the drug issue at a roiling boil in society at large.\n",
            "\n",
            "President Clinton has not kept the drug issue in importance.\n",
            "\n",
            "One thing that's always given me real erotic contentment is knowing that, while having sex, it's hard for me to get involved in hockey.\n",
            "\n",
            "One thing that's always given me real erotic contentment is that, while having sex, it's hard for me to get involved in playing hockey.\n",
            "\n",
            "1 thing that's always given me real erotic contentment is knowing that, while having sex, it's hard for me to get involved in hockey.\n",
            "\n",
            "One thing that's given me real erotic contentment is knowing while having sex it's hard for me to get involved in playing hockey.\n",
            "\n",
            "Not to drag in my own life, but a thing that gives me erotic contentment is that, while having sex, it's hard for me to play hockey. \n",
            "\n",
            "a) Dragged unwillingly into scandal by Clinton the Secret Service agents have no choice about being near the president.\n",
            "\n",
            "Dragged into scandal by Clinton, unlike Currie or his aides, the agents have no choice about being near the president. \n",
            "\n",
            "Unlike Currie,the Secret Service are being dragged unwillingly by the Clinton scandal.\n",
            "\n",
            "The Clinton/Netanyahu talks lead at the NYT. USA Today and LAT go with the finding that Theodore Kacszynski is legally competent to stand trial.\n",
            "\n",
            "The Clinton/Netanyahu talks lead at the New  York Times. USA Today finds that Theodore Kacszynski is legally competent to stand trial.\n",
            "\n",
            "The Clinton/Netanyahu talks lead at the New York Times. USA Today goes with the finding that Theodore Kacszynski is legally competent to stand trial.\n",
            "\n",
            "USA Today finds that Theodore Kacszynski is legally competent to stand trial, which is the top national story at LAT.\n",
            "\n",
            "The Clinton/Netanyahu talks lead at the NYT. While USA Today and LAT go with the finding that Theodore Kacszynski is legally competent to stand trial.\n",
            "\n",
            "The spot is aimed at the woman, reminding her that an alternative to \"no\" is \"wait a minute,\" followed by a quick grab for a rubber. \n",
            "\n",
            "The spot: aimed at the woman reminding her the alternative to \"no\" is \"wait a minute,\" followed by a quick dip into her nightstand for a rubber.\n",
            "\n",
            "The spot is aimed at the woman, reminding her that an alternative is \"wait a minute,\" followed by a dip into her nightstand drawer for a rubber.\n",
            "\n",
            "The ad is aimed at women, who also use condoms, that \"wait a minute\" while dipping into the drawer for a rubber is an alternative to \"no\".\n",
            "\n",
            "The spot is aimed at the woman to remind her that an alternative to \"no\" is to grab a condom.\n",
            "\n",
            "When I get jaded by living in the city, I find it refreshing to visit John Deere,where I can't identify implements on the page.\n",
            "\n",
            "When I get too jaded by living in the city, I always find it refreshing to visit John Deere.\n",
            "\n",
            "When I get jaded, I find it refreshing to visit John Deere, where I realize I can't identify half the implements.\n",
            "\n",
            "\"When I get jaded by living in the city, I visit John Deere where I can't identify half the implements featured on the page.\t11\t3\t2.66666666666667\t161981\t      \"\"W  \"\"Wh  \"\"Whe  \"\"When  \"\"When   \"\"When I  \"\"When I   \"\"When I g  \"\"When I ge  \"\"When I get  \"\"When I get   \"\"When I get j  \"\"When I get ja  \"\"When I get jad  \"\"When I get jade  \"\"When I get jaded  \"\"When I get jaded   \"\"When I get jaded l  \"\"When I get jaded li  \"\"When I get jaded liv  \"\"When I get jaded livi  \"\"When I get jaded livin  \"\"When I get jaded living  \"\"When I get jaded living   \"\"When I get jaded living i  \"\"When I get jaded living in  \"\"When I get jaded living in   \"\"When I get jaded living in t  \"\"When I get jaded living in th  \"\"When I get jaded living in the  \"\"When I get jaded living in the   \"\"When I get jaded living in the c  \"\"When I get jaded living in the ci  \"\"When I get jaded living in the cit  \"\"When I get jaded living in the city  \"\"When I get jaded living in the city,  \"\"When I get jaded living in the city,   \"\"When I get jaded living in the city, I  \"\"When I get jaded living in the city, I   \"\"When I get jaded living in the city, I v  \"\"When I get jaded living in the city, I vi  \"\"When I get jaded living in the city, I vis  \"\"When I get jaded living in the city, I visi  \"\"When I get jaded living in the city, I visit  \"\"When I get jaded living in the city, I visit   \"\"When I get jaded living in the city, I visit J  \"\"When I get jaded living in the city, I visit Jo  \"\"When I get jaded living in the city, I visit Joh  \"\"When I get jaded living in the city, I visit John  \"\"When I get jaded living in the city, I visit John   \"\"When I get jaded living in the city, I visit John D  \"\"When I get jaded living in the city, I visit John De  \"\"When I get jaded living in the city, I visit John Dee  \"\"When I get jaded living in the city, I visit John Deer  \"\"When I get jaded living in the city, I visit John Deere  \"\"When I get jaded living in the city, I visit John Deere   \"\"When I get jaded living in the city, I visit John Deere w  \"\"When I get jaded living in the city, I visit John Deere wh  \"\"When I get jaded living in the city, I visit John Deere whe  \"\"When I get jaded living in the city, I visit John Deere wher  \"\"When I get jaded living in the city, I visit John Deere where  \"\"When I get jaded living in the city, I visit John Deere where   \"\"When I get jaded living in the city, I visit John Deere where I  \"\"When I get jaded living in the city, I visit John Deere where I   \"\"When I get jaded living in the city, I visit John Deere where I c  \"\"When I get jaded living in the city, I visit John Deere where I ca  \"\"When I get jaded living in the city, I visit John Deere where I can  \"\"When I get jaded living in the city, I visit John Deere where I can'  \"\"When I get jaded living in the city, I visit John Deere where I can't  \"\"When I get jaded living in the city, I visit John Deere where I can't   \"\"When I get jaded living in the city, I visit John Deere where I can't i  \"\"When I get jaded living in the city, I visit John Deere where I can't id  \"\"When I get jaded living in the city, I visit John Deere where I can't ide  \"\"When I get jaded living in the city, I visit John Deere where I can't iden  \"\"When I get jaded living in the city, I visit John Deere where I can't ident  \"\"When I get jaded living in the city, I visit John Deere where I can't identi  \"\"When I get jaded living in the city, I visit John Deere where I can't identid  \"\"When I get jaded living in the city, I visit John Deere where I can't identidy  \"\"When I get jaded living in the city, I visit John Deere where I can't identif  \"\"When I get jaded living in the city, I visit John Deere where I can't identify  \"\"When I get jaded living in the city, I visit John Deere where I can't identify   \"\"When I get jaded living in the city, I visit John Deere where I can't identify h  \"\"When I get jaded living in the city, I visit John Deere where I can't identify ha  \"\"When I get jaded living in the city, I visit John Deere where I can't identify hal  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half   \"\"When I get jaded living in the city, I visit John Deere where I can't identify half t  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half th  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the   \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the i  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the im  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the imp  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the impl  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the imple  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implem  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the impleme  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implemen  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implement  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements   \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements f  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements fe  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements fea  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements feat  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements featu  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements featur  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements feature  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements featured  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements featured   \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements featured o  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements featured on  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements featured on   \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements featured on t  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements featured on th  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements featured on the  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements featured on the   \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements featured on the p  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements featured on the pa  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements featured on the pag  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements featured on the page  \"\"When I get jaded living in the city, I visit John Deere where I can't identify half the implements featured on the page.  \"\"When I get jaded  living in the city, I visit John Deere where I can't identify half the implements featured on the page.  \"\"When I get jaded   living in the city, I visit John Deere where I can't identify half the implements featured on the page.  \"\"When I get jaded b  living in the city, I visit John Deere where I can't identify half the implements featured on the page.  \"\"When I get jaded by  living in the city, I visit John Deere where I can't identify half the implements featured on the page.\"\n",
            "\n",
            "An absence of \"Today's Papers\", whose author had fallen ill, promted several letters in response.\n",
            "\n",
            "Several letters were received about the absence of \"Today's Paper\" after its author fell ill.  \n",
            "\n",
            "Slate received several letters that Scott Shuger had fallen ill.\n",
            "\n",
            "Slate received responses to the absence of \"Today's Papers\", whose author had fallen ill:\n",
            "\n",
            "Remember the scene in Portnoy's Complaint where teen-aged Alex goes to a frozen pond to gaze upon gentile girls ice-skating?\n",
            "\n",
            "Remember the scene in Philip Portnoy's Complaint where the teen-aged Alex goes to a frozen pond in Newark to gaze upon girls ice-skating?\n",
            "\n",
            "Recall the scene in Philip Roth's Portnoy's Complaint where teen-aged Portnoy goes to a frozen pond in Newark to watch girls ice-skating.\n",
            "\n",
            "Remember the scene where the newly teen-aged Alex Portnoy goes to a frozen pond in his hometown to gaze upon girls ice-skating?\n",
            "\n",
            "Remember the scene in Philip Roth's Portnoy's Complaint where teen-aged Alex Portnoy goes to a pond to gaze upon girls ice-skating?\n",
            "\n",
            "Media critic Jon Katz recast some America's most fortunate sons and daughters as victims in a cultural civil war.\n",
            "\n",
            "Jon Katz has achieved the impossible: He's recast some of America's fortunate siblings as victims in a civil war.\n",
            "\n",
            "Jon Katz recast America's most fortunate sons and daughters as victims in a cultural civil war.\n",
            "\n",
            "Jon Katz did the impossible by recasting America's most fortunate children as victims in a cultural civil war\n",
            "\n",
            "TWSJ reports that a phone message at Clinton-Gore headquarters begins, 'The campaign is still open for business.\n",
            "\n",
            "Democrat delay can be shown through the unchanged phone message at Clinton-Gore headquarters promoting their campaign.\n",
            "\n",
            "The WSJ reports that a recorded message at Clinton-Gore headquarters states the campaign is still open for business.\n",
            "\n",
            "WSJ reports that a \"recorded phone message at Clinton-Gore headquarters begins\".\n",
            "\n",
            "Speaking of Democrat delay, WSJ reports that \"The campaign is still open for business\" according to Clinton-Gore HQ.\n",
            "\n",
            "DSM insults victims by calling their problems \"mental disorders,\" implying that the victims are wacko and have brought their problems on themselves.\n",
            "\n",
            "The DSM uses the term \"mental disorders,\" which may be offensive to the sufferers. \n",
            "\n",
            "DSM's phrase \"mental disorders\" insults victims of traumas and societal injustice by implying that they're crazy and are guilty for their problems.\n",
            "\n",
            "The DSM insults victims of traumas and societal injustice by calling them \"mental disorders,\" implying that they have brought it on themselves.\n",
            "\n",
            "The DSM insults the victims of traumas and societal injustice by calling their problems \"mental disorders.\"\n",
            "\n",
            "Your discussion of the winner' curse as it relates to online auctions overlooked an important point: the  Internet reduces transaction costs. \n",
            "\n",
            "The winner's curse related to online auctions has a very important point missing: the multiplier effect from the Internet to reduce transaction costs.\n",
            "\n",
            "Your discussion of the winner's curse relating to online auctions overlooked the multiplier effect that comes from the Internet reducing transaction costs.\n",
            "\n",
            "Your discussion of the winner's curse relating to online auctions missed one important point: the multiplier effect to reduce transaction costs.\n",
            "\n",
            "Discussion of the winner's curse with online auctions overlooked one point: multiplier effects that comes from the power of the internet.\n",
            "\n",
            "Prediction: Showers across the state might deter Democrats, making good news for Roy Barnes and Michael Coles.\n",
            "\n",
            "Prediction: Rain across the state might deter Democrafts, but it stops raining, that's godo news for Democratic candidate Roy Barnes and Democric Michael Coles.\n",
            "\n",
            "Showers across the state might deter Democrats, but if it stops raining in Atlanta, that could be good news.\n",
            "\n",
            "Time claims that Ambrous Tung Young bailed out the Republican National Committee by sending it more than $2 million through a  series of loans. \n",
            "\n",
            "Time claims that Ambrous Tung Young bailed out the Republican National Committee in 94 and 96 by sending it more than $2 mil through loans.\n",
            "\n",
            "Time claims that Ambrous Tung Young bailed out the Republican National Committee in 1994 and 1996 by lending it more than $2 million.\n",
            "\n",
            "Time claims that Ambrous Tung Young bailed out the Republican National Committee in 1994 by sending $2 million through a series of loans.\n",
            "\n",
            "Time claims that businessman Ambrous Tung Young bailed out the RNC in 1994 and 1996 by sending it more than $2 million through loans.\n",
            "\n",
            "Earlier this summer, a friend and I were at the Ballard Seafood Festival, an annual celebration of music, troll dolls and pickled herring in Seattle's Scandinavia neighborhood.\n",
            "\n",
            "Earlier this summer a friend and I attended the Ballard Seafood Festival in the Seattle neighborhood that serves as Scandinavia's unofficial outpost.\n",
            "\n",
            "Earlier this summer, an out-of-town friend and I were taking in the Ballard Seafood Festival, an annual celebration.\n",
            "\n",
            "The Ballard Seafood Festival is an annual celebration of music, trol dolls, and pickled in Seattle.\n",
            "\n",
            "This summer, my friend and I were enjoying the Ballard Seafood Festival: an annual celebration of music, dolls, and pickled herring in the Scandinavian neighborhood of Seattle.\n",
            "\n",
            "I'll be brief, as I've got an appt. at 7 a.m., but I promise two more dispatches today.\n",
            "\n",
            "I'll be brief, as I've got an appt. at 7 a.m., but I promise 2 more dispatches today.\n",
            "\n",
            "I've got a doctor's apt at 7 am so I'll be brief on the first one. I promise two more dispatches!\n",
            "\n",
            "I've got a doctor's appt. at 7am, but I promise two  more dispatches today.\n",
            "\n",
            "On this I'll be brief, I have a doctor's appt. at 7 a.m., but I'll do two more today.\n",
            "\n",
            "Here are the most recent segments of this column: Friday, Oct. 30, and Tuesday, Oct. 27.\n",
            "\n",
            "Most recent installments of this column: Friday, Oct. 30, and Tuesday, Oct. 27.\n",
            "\n",
            "If you missed recent installments, here they are: posted Oct. 30, and Tuesday, Oct. 27.\n",
            "\n",
            "Missed the recent installments of this column? Posted Friday, Oct 30 and Tuesday, Oct 27.\n",
            "\n",
            "On the NYT Op-Ed page, Garry Wills argues that a true test of a candidate is not temperament but the constituency communication.\n",
            "\n",
            "Garry Wills argues that the true test of a presidential candidate is the ability to communicate with a constituency.\n",
            "\n",
            "Gary Willis argues on the NYT Op-Ed page that shrewd communication with a constituency is the true test of a presidential candidate.\n",
            "\n",
            "Garry Wills argues that the true test of a presidential candidate is not temperament or virtue on the NYT Op-Ed page.\n",
            "\n",
            "A new idea developed: We had to enforce a balance between individual liberty and personal responsibility--certainly with authority.\n",
            "\n",
            "A new idea emerged to enforced a balance between individual liberty and personal responsibility. \n",
            "\n",
            "A new idea was made: we had to make balance between liberty and responsibility-- with moral authority and even state authority \n",
            "\n",
            "A balance between individual liberty and personal responsibility needed to be enforced with both moral and state authority.\n",
            "\n",
            "We had to enforce a balance between individual liberty and personal responsibility--certainly with nurturing and moral authority\n",
            "\n",
            "Thinks Cruise and Kidman might be gay but looks forward to them in Eyes Wide Shut.\n",
            "\n",
            "Cruise and Kidman are \"probably gay\", but see them have sex in Eyes Wide Shut.\n",
            "\n",
            "Cruise and Kidman are probably gay, but look forward to seeing them in Eyes Wide Shut.\n",
            "\n",
            "I look forward to seeing Tom Cruise and Nicole Kidman having sex in Eyes Wide Shut.\n",
            "\n",
            "Cruise and Kidman are \"probably gay\" but looks forward to seeing them have sex. \n",
            "\n",
            "Mysterious white bauble on lapel could be a cameo, membership pin, or a dab of spilled food.\n",
            "\n",
            "Mysterious white bauble could be pale and delicate cameo or perhaps a dab of spilled food.\n",
            "\n",
            "Mysterious white bauble on lapel could be a cameo, membership pin, or spilled food.\n",
            "\n",
            "The bauble on lapel could be pale cameo, membership pin in pernicious organization, or perhaps a food dab.\n",
            "\n",
            "White bauble on lapel could be pale and cameo or perhaps a dab of spilled food.\n",
            "\n",
            "Rural Chinese and Africans may not need high dairy consumption. This does not mean that Americans should not drink milk.\n",
            "\n",
            "Rural Chinese and Africans may not need lots of dairy to be healthy, but that doesn't mean Americans shouldn't drink milk.\n",
            "\n",
            "Rural Chinese & Africans may not need high dairy consumption to be healthy, but Americans should still drink milk.\n",
            "\n",
            "because people may not need dairy consumption to be healthy does not mean that Americans should be discouraged from milk.\n",
            "\n",
            "Just because rural Chinese and Africans may not need high dairy consumption does not mean that Americans should avoid milk.\n",
            "\n",
            "The true relevance will be ascertained only by careful research that acknowledges that aspects of this function develop throughout the life.\n",
            "\n",
            "The lateralization of function will be ascertained only by careful research that acknowledges that this function develop beginning at birth, if not before.\n",
            "\n",
            "The relevance of lateralization of function will be gained only by research that acknowledges that it develops throughout the life span, beginning at birth. \n",
            "\n",
            "The true relevance of lateralization of function will be found by research that acknowledges that this function develops since birth, if not before.\n",
            "\n",
            "It's worth reprinting an email a relative sent to my wife after he learned I hated The Phantom Menace:\n",
            "\n",
            "The e-mail a relative sent my wife, after she told him I hated The Phantom Menace, is worth reprinting.\n",
            "\n",
            "It's worth reprinting an email sent to my wife after she let him know I hated The Phantom Menace.\n",
            "\n",
            "It's worth printing an email sent to my wife by a relative once he discovered I hated The Phantom Menace\n",
            "\n",
            "It's worth showing an e-mail sent to my wife, after she'd told a relative that I hated the movie:\n",
            "\n",
            "1) The White House has contacted Networks to reserve television time for a Clinton apology.\n",
            "\n",
            "1) The White House has contacted networks to reserve television time for a Clinton apology.\n",
            "\n",
            "1.) White house contacted networks to save TV time (on Aug 16 or 17) for Clinton's apology\n",
            "\n",
            "The White Houses has reserved television time on Aug. 16 or Aug. 17 for an apology from Clinton. \n",
            "\n",
            "White house has contacted the networks to reserve TV time on 16or 17 Aug) for a clinton apology.\n",
            "\n",
            "That's why activists disapprove the venue, saying the only thing the court will remove is constitutional protection for aliens engaging in unpopular speech.\n",
            "\n",
            "That's why civil-liberties activists are mad at the new venue, saying that it will remove protection for aliens who say politically unpopular speech.\n",
            "\n",
            "Civil-liberties activists are crying foul, saying the only thing the court will remove is protections for aliens who engage in politically unpopular speech.\n",
            "\n",
            "Activists are crying foul at the new venue, saying that the only thing the court will remove is protections for aliens who engage in unpopular speech. \n",
            "\n",
            "Culturebox might say that Janet Maslin was driven from the NYT by the shame of almost having Siegel agree with her.\n",
            "\n",
            "If Culturebox didn't know, she says that Janet Maslin left the NYT by the shame of having Lee Siegel agree with her.\n",
            "\n",
            "Culturebox thinks that Janet Maslin was driven from New York Times by the shame of having Lee Siegel agree with her.\n",
            "\n",
            "Janet Maslin may have been driven from the NYT from the shame of having Lee Siegel agree with her.\n",
            "\n",
            "Culturebox thinks Janet Maslin left the New York Times because of the shame that Lee Siegel almost agreed with her.\n",
            "\n",
            "WWW: Fox TV calls it \"the hippest, funniest action movie of the summer.\"\n",
            "\n",
            "Some guy on Fox TV calls it \"the hippest, funniest action movie of the summer.\" \n",
            "\n",
            "Some guy on Fox TV calls it \"the hippest, funniest action movie of the summer.\"\n",
            "\n",
            "Fox TV calls it \"the hippest, funniest action movie of the summer.\"\n",
            "\n",
            "Some guy on Fox TV that nobody ever heard of calls it \"the...funniest action movie\"\n",
            "\n",
            "Thank you for making the suggestion, Susan, for spotting some useful news items, and Slate for having me.\n",
            "\n",
            "Thank you for making the suggestion, Susan for spotting useful news, and Slate for the ride.\n",
            "\n",
            "Thank you for making the suggestion, Susan for spotting some news items, and Slate for having me in.\n",
            "\n",
            "Thank you for making the suggestion, Susan for spotting some news items, and Slate for having me here. \n",
            "\n",
            "Pralance conflates nerd with nebbish.  The overlao between the two concepts is not large.\n",
            "\n",
            "The parlance conflates nerd with nebbish. The overlap between them is not large, more like this:\n",
            "\n",
            "Nerd is popularly conflated with \"nebbish,\" but the two concepts are fairly different, as such:\n",
            "\n",
            "The popular parlance mix nerd with nebbish. The overlap between the two concepts are not large.\n",
            "\n",
            "Henry Lyons was describing his theft of the $250,000 that the Anti-Defamation League of B'nai B'rith had donated.\n",
            "\n",
            "Henry Lyons described his theft of the $250,000 that the Anti-Defamation League had donated to rebuild black churches.\n",
            "\n",
            "Henry Lyons described his theft of the $250,000 that the Anti-Defamation League donated to rebuild churches. \n",
            "\n",
            "Henry Lyons was describing his theft of the $250,000 was donated to rebuild black churches destroyed by fire.\n",
            "\n",
            "Henry Lyons described stealing $250,000 from the Anti-Defamation League of B'nai B'rith.\n",
            "\n",
            "The Gatorade commercial featuring Mia Hamm and Michael Jordan comes on.\n",
            "\n",
            "A commercial comes on, the Gatorade \"Anything You Can Do, I Can Do Better\" ad.\n",
            "\n",
            "Gatorade's ad \"Anything You Can Do, I Can Do Better\" stars Mia Hamm and Michael Jordan.\n",
            "\n",
            "Gatorade \"Anything You Can Do, I Can Do Better\" ad with Mia Hamm and Michael Jordan.\n",
            "\n",
            "An ad comes on, Gatorade's \"Anything You Can Do, I Can Do Better\" with Hamm & Jordan.\n",
            "\n",
            "It is possible to search for words other than Bill Gates and Slate can't be responsible for the result.\n",
            "\n",
            "It isn't recommended that words other than Bill Gates be searched, Slate is not liable for the results.\n",
            "\n",
            "Searching for words other than Bill Gates is possible on Slate, but not recommended.\n",
            "\n",
            "It is possible to search for words other than Bill Gates, but Slate cannot be responsible for results. \n",
            "\n",
            "It is possible to search for words other than Bill Gates, and Slate cannot be held responsible.\n",
            "\n",
            "Someone not understanding the distinction between acting & being shouldn't be writing movie reviews. \n",
            "\n",
            "If you don't know the difference between acting and being, don't write movie reviews. \n",
            "\n",
            "Someone with a clear lack of understanding of acting and being should not write reviews. \n",
            "\n",
            "Someone who cannot clearly understand acting versus being should perhaps not write movie reviews.\n",
            "\n",
            "Someone who lacks understanding of the distinction between acting and being shouldn't write movies. \n",
            "\n",
            "Martial music and an outrider-flagged motorcade herald Pat Buchanan's return to Crossfire but two stabs at the presidency.\n",
            "\n",
            "Martial music and a motorcade herald Buchanan's return to Crossfire, the show that gave him enough sway in the U.S. to take two stabs at the presidency.\n",
            "\n",
            "Martial music heralds Pat Buchanan's return to Crossfire , the show that gave him enough money in households to attempt the presidency twice.\n",
            "\n",
            "Music and a flagged motorcade herald Pat Buchanan's return to Crossfire , the show that gave him enough currency to take not one, but two stabs at the presidency.\n",
            "\n",
            "Martial music and an outrider-flagged motorcade herald Pat Buchanan's return to Crossfire, the show that gave him enough popularity to run for president twice.\n",
            "\n",
            "K., chagrined by the U'Haul company's errant behavior, is an example of all four phenomena.\n",
            "\n",
            "As an example I refer you to the complaint of K., who is vexed by the behavior of the U-Haul company.\n",
            "\n",
            "As an example of all four phenomena, refer to the complaint of K., who's chagrined by U-Haul's behavior.\n",
            "\n",
            "As an example of all 4 phenomena, see the complaint of K. who is chagrined by the behavior of U-Haul.\n",
            "\n",
            "The editor turns over the space to a colleague, Cyrus Krohn, due to being exhausted.\n",
            "\n",
            "Exhausted by denying poor people a capital-gains tax cut, the editor turns to his colleague, Cyrus Krohn:\n",
            "\n",
            "Exhausted by trying to deny poor people a capital-gains tax cut, the editor turned it over to Cyrus Krohn:\n",
            "\n",
            "Tired from denying the poor a tax cut, the editor gives this space to colleague Cyrus Krohn:\n",
            "\n",
            "Broadcast by the National Association of Manufacturers during the debate for cutting federal taxes, this extends history's reach pushing for tax breaks they favor.\n",
            "\n",
            "During the debate over cutting federal taxes, there was a huge push bor tax breaks by the NAM.\n",
            "\n",
            "Broadcast by the NAM during the debate over cutting federal taxes, pointed spot extends history's reach in an effort to push for the tax breaks favored by the NAM.\n",
            "\n",
            "Broadcast by the NAM,,this timely, pointed spot extends history's reach in an effort to push for the tax breaks.         \n",
            "\n",
            "Broadcast by the NAM during the debate over cutting federal taxes, this pointed spot extends history's reach in effort to push for tax breaks.\n",
            "\n",
            "Whate was removed because the list is arranged by time on death row awaiting execution.\n",
            "\n",
            "The list is of awaiting execution, by time spent on death row; White was removed by lethal injection.\n",
            "\n",
            "List accords men awaiting execution, time of death row; White removed from list by lethal injection\n",
            "\n",
            "The RPH book is followed by the tour, which leads to the next RPH fact:\n",
            "\n",
            "The publication of the RPH book is followed by the book tour:\n",
            "\n",
            "RPH book's publication is followed by the book tour, which leads to the fact:\n",
            "\n",
            "The publication of the RPH book is followed by the book tour, leading to:\n",
            "\n",
            "The publication of the RPH book is followed by the book tour.\n",
            "\n",
            "Prudie hopes the recipient of the bagels & cream cheese is not a friend of Sue's; cream cheese in the closet would be bad.\n",
            "\n",
            "Prudie hopes that Sue's friend wont recieve the bagels and cream cheese, because the cheese in the closet would be a disaster\n",
            "\n",
            "Prudie hopes that the recipient is not also a friend of Sue's, because the cream cheese in the closet would be a disaster.\n",
            "\n",
            "Prudie hopes that the recipient of the cream cheese is not a friend of Sue's; the cream cheese in the closet is bad.\n",
            "\n",
            "Though she doubts the relative will be swayed by your opinion, Prudie agrees with you and hopes your thoughts make a difference. \n",
            "\n",
            "Prudie doubts your opinion will sway the estranged relative but hopes your thoughts might make a difference in someone else.\n",
            "\n",
            "Through Prudie doubts the estranged relative will by your opinion and agrees with you and hopes your thoughts make a difference.\n",
            "\n",
            "Prudie doubts the estranged relative will be swayed by your opinion, but agrees and hopes your thoughts will make a difference.\n",
            "\n",
            "Prudie agrees with you and hopes that your thoughts might make a difference, but doubts your opinion will sway the estranged relative.\n",
            "\n",
            "George W. Bush, while still working on his position on Buchanan, has not addressed the matter yet.\n",
            "\n",
            "G.W. Bush, still working oh his position on Buchanon (or Hitler?), has not addressed the matter.\n",
            "\n",
            "Bush apparently still working on his position on Buchana, has not addressed the matter yet. \n",
            "\n",
            "Heroin is a drug that can kill you right away. Most heroin addicts didn't start out shooting up, they were smoking pot.\n",
            "\n",
            "Heroin can kill on the first attempt, and most heroin addicts don't start with needles--they were smoking pot.\n",
            "\n",
            "Heroin is a drug that can kill you the first time, and most addicts didn't started with heroin but with pot as teenagers.\n",
            "\n",
            "Heroin can kill you on the very first try, and most heroin addicts didn't start with needles - they used pot as teens.\n",
            "\n",
            "Tasters chose one Best and one Worst from the \"flight\" \n",
            "\n",
            "Tasters choose one Best and one Worst from the \"flight\"(wine selection).\n",
            "\n",
            "Tasters chose 1 Best & 1 Worst from the \"flight\".\n",
            "\n",
            "Best and Worst: Tasters chose one Best and one Worst from the \"flight.\" \n",
            "\n",
            "Tasters chose one Best and one Worst from the \"flight\".\n",
            "\n",
            "A passenger may have bad feelings about an airline that messed with his head while he was traveling to his mother's funeral.\n",
            "\n",
            "The passenger might have feelings about an airline after it confused him while traveling to his mom's funeral.\n",
            "\n",
            "A passenger might have \"personal\" feelings about an airline they messed with his head while he traveled to his mom's funeral.\n",
            "\n",
            "A passenger might have bad feelings about an airline after it messed with his head while traveling to his mother's funeral.\n",
            "\n",
            "One could argue that a passenger might have \"personal\" feelings about an airline.\n",
            "\n",
            "What happened to those covered in previous \"Motley Fool\" articles in Slate? Click for an update.\n",
            "\n",
            "Find out what happened to those in previous \"Motley Fool\" articles. Click to get the update.\n",
            "\n",
            "Click for updates on the people and companies covered in Slate's previous \"Motley Fool\" articles.\n",
            "\n",
            "Wonder what's happened to the people covered in previous \"Motley Fool\" articles? Click here.\n",
            "\n",
            "Washington Wire reports that twenty lawmakers who voted this week to restrict satellite exports had urged Clinton to export satellites there.\n",
            "\n",
            "The \"Washington Wire\" reports that some 20 lawmakers who voted to curb satellite exports to China had urged Clinton to export them there.\n",
            "\n",
            "The Wall Street Journal reports that some lawmakers who voted this week to restrict satellite exports to China had previously argued for exports.\n",
            "\n",
            "Washington Wire reports that 20 lawmakers who voted to restrict satellite exports to China had urged Clinton to export satellites there before.\n",
            "\n",
            "The Wall Street Journal reports that twenty lawmakers who voted this week to restrict satellite exports to China had previously urged exports.\n",
            "\n",
            "If you meet a madman saying we are all fish, do you strip to show him that you do not have fins?\n",
            "\n",
            "If someone claims all men are fish, do you strip to show him your lack of fins?\n",
            "\n",
            "If you meet a madman who says that we are all fishes, do you disrobe to show him that you don't have fins?\n",
            "\n",
            "If you meet a man who says everyone's a fish, do you remove your clothes to show him you don't have fins?\n",
            "\n",
            "In the Nov. 20 \"Give It Back to the Injuns,\" an annoyed David Plotz refer to Oklahoma Republicans has negative.\n",
            "\n",
            "In \"Give It Back to the Injuns,\" D. Plotz calls Oklahoma Republicans \"a top to bottom roster of kooks, losers, and terrors.\"\n",
            "\n",
            "In the Nov. 20, \"Give It Back to the Injuns\" David Plotz refers to Oklahoma Republicans. \n",
            "\n",
            "In \"Give It Back to the Injuns,\" David Plotz refers to Oklahoma Republicans as \"a roster of kooks, losers, and terrors.\"\n",
            "\n",
            "In the Nov. 20 \"Give It Back to the Injuns\" David Plotz refers to Oklahoma Republicans as \"a roster of kooks, losers, & terrors.\"\n",
            "\n",
            "A French woman in the United States reportedly healed herself when she wore and Mother Teresa medallion.\n",
            "\n",
            "A woman in the US broke several ribs in a car accident reportedly healed when she wore a Mother Teresa medallion.\n",
            "\n",
            "A woman who broke several ribs in a car accident reportedly healed when she wore a Mother Teresa medallion.\n",
            "\n",
            "A woman in the U.S. who broke her ribs in a car accident healed when she wore a Mother Teresa medallion.\n",
            "\n",
            "A French woman in the US who broke several ribs in a car accident healed when she wore a Mother Teresa medallion.\n",
            "\n",
            "Stay tuned to hear whether Southwest makes good on promise to compensate M. and apologize.\n",
            "\n",
            "Stay tuned to hear if Southwest pays M. and apologize to her for her troubles.\n",
            "\n",
            "Stay tuned to see if Southwest completes it promise to compensate M. for her troubles.\n",
            "\n",
            "Stay tuned, to hear if Soutwest keeps its promise to compensate M, for her troubles.\n",
            "\n",
            "We should do all we can to resolve this and remove Saddam Hussein from office.\n",
            "\n",
            "We should do everything we can to get this resolved and have Saddam Hussein removed from office.\n",
            "\n",
            "We need to get this resolved and have Saddam Hussein removed from office.\n",
            "\n",
            "We should do everything to get this resolved and find a way to have removed from office.\n",
            "\n",
            "Do everything we can to get this resolved and find a way to have [Saddam Hussein] removed.\n",
            "\n",
            "George Will defends the right of African-American hair care practitioners to administer unlicensed \"sisterlocks\".\n",
            "\n",
            "George Will defends, on libertarian grounds, the right of African-American hair care practitioners to administer unlicensed \"sisterlocks.\"\n",
            "\n",
            "In George Will's WP column he defends the right of African-American hair care practitioners to administer unlicensed \"sisterlocks\" on libertarian grounds.\n",
            "\n",
            "Politics has never made stranger bedfellows than when George Will defends the rights of African-American hair care practitioners to give \"sisterlocks.\"\n",
            "\n",
            "Politics strangest bedfellow is George Will's column where he defends the right of African-American hair care specialist to allow unlicensed \"sisterlocks.\"\n",
            "\n",
            "Amistad and Echo of Lions both have a rich black man involved with abolitionist literature\n",
            "\n",
            "Amistad and Echo of Lions have a same character--a wealthy, erudite black man helping print abolitionist writing.\n",
            "\n",
            "Amistad and Echo of Lions both contain a wealthy, erudite black character who prints abolitionist literature.\n",
            "\n",
            "Amistad and Echo of Lions contain a wealthy, black man involved with the printing of abolitionist literature.\n",
            "\n",
            "Match the 60 Minutes II correspondent with the impressive attribute ascribed .\n",
            "\n",
            "Match the 60 Minutes II correspondent with the impressive attribute ascribed to him by Jeff Fager.\n",
            "\n",
            "Match 60 minutes responder with the attributes ascribed to him or her by producer Jeff Fager.\n",
            "\n",
            "Match the 60 Minutes II correspondent with the attribute ascribed to them by Jeff Fager.\n",
            "\n",
            "The president's gun buy-back plan does not include a proposal to eliminate the middleman.\n",
            "\n",
            "The president's gun buy-back plan doesn't include eliminating the middleman.\n",
            "\n",
            "The president's gun-buy back plan proposal funnels $15 million to Smith & Wesson.\n",
            "\n",
            "The President's gun plan doesn't include eliminating the middleman and funnel $15 mil to Smith & Wesson.\n",
            "\n",
            "The president's gun buy-back plan lacks a proposal to cut the middleman and funnel money to Smith & Wesson.\n",
            "\n",
            "Newsweek notes the marketing overkill of the James Bond movie: Companies are running ads that hawk their products and the movie.\n",
            "\n",
            "Newsweek notes the marketing overkill of the new James Bond movie: companies have ads that hawk both their products and the movie.\n",
            "\n",
            "Newsweek notes the marketing overkill of the new James Bond movie: many brands ran commercials with their products and the movie.\n",
            "\n",
            "Newsweek notes overkill of new James Bond Movie from the marketing teams of Heineken, Smirnoff, BMW, Visa and Ericsson.\n",
            "\n",
            "Dr. Veerabhadran Ramanathan's team was surprised by the extent, thickness, and persistence.\n",
            "\n",
            "Dr. Veerabhadran Ramanathan's team from the National Science Foundation & the Scripps Institution of Oceanography was surprised.\n",
            "\n",
            "Dr. Ramanathan's team from the NSF and the Scripps institute was surprised by the extent, thickness, and persistence.\n",
            "\n",
            "Dr. Veerabhadran Ramanathan's team from the Institution of Oceanography was surprised by the extent, thickness, and persistence.\n",
            "\n",
            "The WP, which credits Newsweek in its inside Unabomber story, treats the new round of negotiations as still open.\n",
            "\n",
            "WP, which credits Newsweek in the 4th paragraph of its Unabomber story, treats the negotiations as still open.\n",
            "\n",
            "What's the best way to introduce yourself to someone you don't know in your conversation?\n",
            "\n",
            "How do you best handle the introduction of someone whose name you should know but don't when they join in your conversation?\n",
            "\n",
            "What is the best way to handle introducing someone whose name you should know but don't when they join your conversation?\n",
            "\n",
            "My query is, what is the best way to introduce someone whose name you don't know to join a conversation you are in? \n",
            "\n",
            "My question is: What is the best way to handle the introduction of a name you don't know when they join a conversation?\n",
            "\n",
            "Cigarette with lipstick's traces, romantic places, These foolish things Remind me of you.   \n",
            "\n",
            "A cigarette stained with lipstick, an airline ticket, and my winged heart. These things remind me of you.\n",
            "\n",
            "Cigarettes with lipstick and romantic plane tickets remind my heart with wings of you.\n",
            "\n",
            "A cigarette with lipstick's traces, an airline ticket to romantic places, these things remind me of you. \n",
            "\n",
            "The WSJ noted that the GDP rose 4.3% in the last quarter. For all of 1997, the it grew 3.8%, the best in ten years. \n",
            "\n",
            "The WSJ reports that the GDP jumped 4.3 % for the last quarter of 1997 and that the economy grew 3.8 %.\n",
            "\n",
            "The WSJ reports that the GDP jumped 4.3 percent for the last quarter of 1997 and the economy grew 3.8 percent. \n",
            "\n",
            "GDP jumped 4.3% for the last quarter of '97 and that for all of '97, the economy grew 3.8%, the best rate in ten years.\n",
            "\n",
            "The USAT raising \"serious concerns\" over the physical security at Department of Energy. \n",
            "\n",
            "The USAT lead quotes a Pentagon report over a developing crisis raising \"serious concerns\" over security at Department of Energy storage.\n",
            "\n",
            "The USAT quotes a Pentagon report saying \"serious concerns\" over the security at Department of Energy facilities and worries of crisis.\n",
            "\n",
            "The USAT lead quotes a Pentagon report citing concerns over security at DOE nuke storage facilities and a DOE report on a \"developing crisis.\"\n",
            "\n",
            "In the 7th installment of the No Relation series, Explainer takes on the Gessens, Glennys, and many variations of Kaczynskis. \n",
            "\n",
            "In the 7th installment of the No Relation series, Explainer takes on the Gessens and Glennys, as well as the Kaczynskis.\n",
            "\n",
            "In the 7th installment of the No Relation series, Explainer takes on the Gessens and Glennys, and the many variations of Kaczynskis.\n",
            "\n",
            "The 7th part of the No Relation series, which sorts out newsmakers with confusingly similar names, takes on the Gessens, Glennys, and Kaczynskis.\n",
            "\n",
            "Explainer sorts out newsmakers with similar names. The 7th installment of the No Relations series covers Gessens and Glennys, as well as many Kaczynskis.\n",
            "\n",
            "The tabloids hit a macabre trifecta with reports on three stories: JonBenet Ramsey murder, Princess Diana's death, and the Clinton presidency.\n",
            "\n",
            "The tabloids hit a trifecta with reports on 3 of their major stories: the JonBenet Ramsey murder, the Princess Diana death, and Bill Clinton's presidency.\n",
            "\n",
            "The tabloids received reports on three of their major stories: the murder of JonBenet Ramsey, the death of Princess Diana, and the presidency of Clinton.\n",
            "\n",
            "The murder of JonBenet Ramsey, the death of Princess Di, and Bill Clinton's Presidency all top the tabloids.\n",
            "\n",
            "The tabloids had extensive reports on 3 of their major stories: JonBenet Ramsey's murder, Princess Diana's death, & Clinton's dead duck presidency.\n",
            "\n",
            "The proverb \"If work were good for you, the rich would leave none for the poor,\" sums up the welfare debate.\n",
            "\n",
            "A Haitian proverb sums up the debate: \"If work were good for you, the rich would leave none for the poor.\"\n",
            "\n",
            "I believe a Haitian proverb summarizes the debate: If work was good, the rich would leave none for the poor.\n",
            "\n",
            "If work were good for you, the rich would leave none for the poor., says a Haitian proverb. \n",
            "\n",
            "A proverb sums up the work debate: \"If work were good for you, the rich would leave none for the poor.\"\n",
            "\n",
            "Republicans passed $792 billion, 10 yr tax-cut bills, which they'll reconcile in conference committee before summer recess begins.\n",
            "\n",
            "Republicans passed separate $792 billion, which they hope to reconcile in conference committee before the summer recess begins. \n",
            "\n",
            "House and Senate Republicans passed separate $792 billion, 10-year tax-cut bills, which they hope to reconcile before the recess begins.\n",
            "\n",
            "House and Senate Republicans passed $792 billion bills, which they hope to reconcile in committee before the summer recess begins\n",
            "\n",
            "Republicans passed $792 billion, 10 year tax-cut bills, which they hope to reconcile in conference committee before the end of the week.\n",
            "\n",
            "Kennedy's George and Brown's Talk raise the question: What are a new magazine's chances for survival? \n",
            "\n",
            "The launch of Brown's Talk raise the question, what are a new magazine's chances for survival?\n",
            "\n",
            "The John Kennedy's George demise and the Tina Brown's Talk launch raise the question: Will the magazine survive?\n",
            "\n",
            "The demise of JFK's George and the launch of Tina Brown's Talk ask what magazines chances of survival are.\n",
            "\n",
            "This Jewish sardonic remark is intended to comfort one's grief after making a serious mistake.\n",
            "\n",
            "A Sardonic remark is meant to comfort someone grieving over a mistake in the Jewish tradition.\n",
            "\n",
            "In the Jewish tradition, the remark comforts a person who grieving over a serious mistake.\n",
            "\n",
            "In Jewish tradition, this remark is meant to help a person unhappy over making a serious mistake.\n",
            "\n",
            "In the Jewish tradition, this remark is intended to comfort grief over a serious mistake.\n",
            "\n",
            "In Massachusetts, most jobs set aside for welfare recipients have gone unfilled, and there has been no increase in demand for other assistance. \n",
            "\n",
            "In Massachusetts, most of the jobs set aside for welfare recipients have gone unfilled, and there has been no demand for medical help or child-care assistance.\n",
            "\n",
            "In Mass., most jobs set up for those on welfare go unfilled with no increased demand for medical help or child-care.\n",
            "\n",
            "Most jobs for welfare recipients have gone unfilled, and there has been no increased demand for medical help or child-care assistance.\n",
            "\n",
            "As for \"supportive services,\" in Massachusetts most of the special jobs set aside have gone unfilled, and there has been no increased demand for help. \n",
            "\n",
            "Also in Newsweek, articles cheer the capture of Pol Pot, \"the last monster of the 20th century,\" but notes the effects still felt by his genocide.\n",
            "\n",
            "From Newsweek, articles cheers the capture of Pol Pot--but notes that Cambodia is still scarred by Pol Pot's genocide.\n",
            "\n",
            "Articles in Newsweek cheer the capture of Pol Pot--\"the last monster of the 20th century\"--but notes Cambodia is still hurt by Pol Pot's genocide.\n",
            "\n",
            "Newsweek, package of articles cheers capture of Pol Pot - but notes that Cambodia is still corrupt and scarred by genocide.\n",
            "\n",
            "Scott is not a racist--just a little weak on statistical inferences, like many journalists.\n",
            "\n",
            "Scott is not a racist, just weak on statistical inferences, like many otherwise excellent journalists.\n",
            "\n",
            "Scott is not a racist--just weak on statistical inferences, like many otherwise excellent journalists.\n",
            "\n",
            "Scott is not a racist - just a little weak on statistical inferences.\n",
            "\n",
            "Prudie is unsure how to resolve issues with stories about grade inflation & courses like \"Structure of the Soap Opera\" & \"History of Beads.\"\n",
            "\n",
            "Prudie isn't sure how to square your complaints with all the news stories about grade inflation and college-level courses.\n",
            "\n",
            "Prudie isn't sure how to square your complaints with all the news stories about grade inflation and college-level courses. \n",
            "\n",
            "Prudie can't square complaints with news about grade inflation and courses like \"The Structure of the Soap Opera\" and \"The History of Beads.\"\n",
            "\n",
            "Prudie isn't sure how to square your complaints with the stories about grade inflation and college courses such as \"The History of Beads.\"\n",
            "\n",
            "People get very nervous around somebody whose killed somebody; no matter why he killed them. Now maybe that's unfair, but I'm sure you'll understand it's true.\n",
            "\n",
            "That clipping, Mister Kearny, that's the problem. People get nervous around someone who's killed somebody. Now maybe that's unfair, I'm sure you'll understand it's true.\n",
            "\n",
            "That clipping is the problem. People get nervous around someone who's killed somebody, no matter why he did it. Maybe that's unfair, but I'm sure you'll agree.\n",
            "\n",
            ". People get nervous around somebody who's killed somebody. Now maybe that's unfair, but if you think about it I'm sure you'll understand it's true\n",
            "\n",
            "That clipping is the problem, Mr. Kearny. People get nervous around somebody who's killed somebody, no matter why. Maybe that's unfair, but I'm sure you'll understand.\n",
            "\n",
            "I was brought up to make the bed before leaving, but my friends say it's just more work for the maid.\n",
            "\n",
            "I was brought up to make the bed before leaving, but my friends say it is just more work for the maid.\n",
            "\n",
            "I was taught to make the bed before leaving, but my friends say it's just more work for the maid.\n",
            "\n",
            "I felt the need to make the bed, but my friends assert that the maid would strip the sheets regardless\n",
            "\n",
            "The Post abortion story reports that  abortion remains a common American experience--about half of all American women eventually get one. \n",
            "\n",
            "The Post abortion story reports that despite a rate drop of 20 % since 1980, abortion is common with half of all American women eventually get one.\n",
            "\n",
            "Despite a drop rate of 20 percent since 1980,abortions remain common in the US, with about half of women getting one, according to The Post and NYT.\n",
            "\n",
            "The Post abortion story reports that, despite a 20% rate drop since 1980, abortion remains a common American experience, about half of all women get one.\n",
            "\n",
            "Larry Elder \"sage from South Central\" is expected to break into national talk radio this year.\n",
            "\n",
            "Look for Larry Elder to break into the national talk radio landscape this year.\n",
            "\n",
            "B. \"Look for Larry Elder, the 'sage from South Central,' to break into talk radio this year.\"\n",
            "\n",
            "Larry Elder, the self-described 'sage from South Central ,' on national talk radio this year.\n",
            "\n",
            "Look for Elder, the 'sage from South Central', to break into the national radio landscape.\n",
            "\n",
            "Did you see the story in the far-left column of yesterday's Wall Street Journal? Here's the headline and the lead:\n",
            "\n",
            "Did you see the left column story of yesterday's Wall Street Journal ? My editor showed me; here's the headline and lead:\n",
            "\n",
            "Did you see the story of yesterday's WSJ?  My editor pointed it out to me:\n",
            "\n",
            "Did you see the story in yesterday's Wall Street Journal? Here's the headline and the lead:\n",
            "\n",
            "In other news, did you see the story in yesterday's WSJ? Here's the headline and the lead:\n",
            "\n",
            "Which well-designed and inexpensive CD rack is a figure in Norse mythology that's sold at a popular Swedish store?\n",
            "\n",
            "Which of the following is a CD rack sold at the Swedish furniture store, and which is a figure in Norse mythology?\n",
            "\n",
            "A well-designed yet inexpensive CD rack sold at the popular Swedish furniture store.\n",
            "\n",
            "Which of the following is the Norse god and which is the CD rack?\n",
            "\n",
            "Which of the following is a CD rack sold at a popular furniture store, and which is a figure in Norse mythology?\n",
            "\n",
            "This is a point of supernuance, not a criticism of Newsweek 's integrity, like the story says.\n",
            "\n",
            "4) This was billed in the story as a super nuance, not a major criticism, of Newsweek's integrity.\n",
            "\n",
            "This is a point of supernuance, not a major criticism of Newsweek 's journalistic integrity.\n",
            "\n",
            "With how it was billed in the story, the Newsweek journalistic integrity took some major criticism.\n",
            "\n",
            "This is a point, not a criticism of Newsweek 's journalistic integrity, which was how it was in the story.\n",
            "\n",
            "William Saletan quotes, from The Argument Culture : \"Disputation was rejected in ancient China as incompatible with the decorum and harmony cultivated by the true sage.\"\n",
            "\n",
            "William Saletan quotes from Deborah Tannen \"Disputation was rejected in ancient China as incompatible with the decorum and harmony cultivated by the true sage.\"\n",
            "\n",
            "In \"We Do Understand,\" William Saletan quotes Deborah Tannen's The Argument Culture: \"Disputes were rejected in ancient China as incompatible with the true sage's harmony.\"\n",
            "\n",
            "Saleton quotes this from Tannen's The Argument Culture: \"Disputation was rejected in ancient China as incompatible with the decorum and harmony cultivated by the true sage.\"\n",
            "\n",
            "From The Argument Culture : \"Disputation was rejected in ancient China as incompatible with the decorum and harmony cultivated by the true sage.\"\n",
            "\n",
            "Tom Brokaw asked, \"Is there anything...that a president...can do to interrupt...an evolving culture of violence and rage in America?\"\n",
            "\n",
            "Tom Brokaw asked, \"Can the president of the United States interrupt an evolving culture of violence and rage in America?\"\n",
            "\n",
            "Is there anything that a U.S. President can do to interrupt an evolving culture of violence and rage in America, asked Tom Brokaw.\n",
            "\n",
            "Tom Brokaw asked, \"What can the president of the US do to stop what seems to be an evolving culture of violence & rage in America?\"\n",
            "\n",
            "The photographer's work will make it into the GDP only when Tylenol, or a Buick or an advertisement on the news shows a picture of Lewinsky.\n",
            "\n",
            "The photographer's work will make it into the GDP when someone buys a product advertised on the news show containing Lewinsky's picture.\n",
            "\n",
            "The photographer's work will make it into the GDP only when whatever is advertised on the news show using Lewinsky's  picture is bought.\n",
            "\n",
            "The photographer's work will make it into the GDP when someone buys whatever is advertised on the news show were the image of Lewinsky is on.\n",
            "\n",
            "In Texas, we have a Telecommunications Infrastructure Fund for schools and libraries that antedates the e-rate and is far more generous with the telcos' money.\n",
            "\n",
            "In conservative Texas, we have a Telecommunications Infrastructure Fund for schools and libraries that antedates the e-rate and is far more generous with the telcos' money.\n",
            "\n",
            "In Texas, we have a Telecommunications Infrastructure Fund for schools and libraries that antedates the e-rate and is more generous with the telcos' money. \n",
            "\n",
            "In Texas, we have a Fund for schools and libraries (dreamed up by a state senator, among others) that antedates the e-rate and is far more generous with the telcos' money.\n",
            "\n",
            "In conservative Texas, the Telecommunications Infrastructure Fund for schools & libraries antedates the e-rate & is far more generous with the telcos' money.\n",
            "\n",
            "Congratulations to Tamara Glenny and Robert D. Mare for a victorious six links.\n",
            "\n",
            "Congrats to Tamara Glenny and Robert D. Mare for victory in six links.\n",
            "\n",
            "Congrats to Ms Glenny and Mr Mare for getting from guts and glory to small and hoary in 6 links.\n",
            "\n",
            "Congratulations to Tamara Glenny and Robert D. Mare for victorious six links.\n",
            "\n",
            "Congratulations to Tamara and Robert for getting from glory to hoary in 6 links.\n",
            "\n",
            "For those who argue that our politicians need salary increases, according to the indictment, Cisneros was able to scrape together $250,000 for his girlfriend.\n",
            "\n",
            "For those who argue that  politicians need salary increases, please note that according to the indictment, somehow Cisneros was able to scrape together $250,000.\n",
            "\n",
            "For those who persist in arguing that our politicians need salary increases, somehow Cisneros was able to scrape together a quarter of a million dollars her.  \n",
            "\n",
            "For those arguing that our politicians need salary increases, note that according to the indictment, Cisneros was able to scrape together $.25m for his girlfriend.\n",
            "\n",
            "Ragtime and radio, hillbilly and race records, big bands and showtoons, 45s and triple concept albums, MTV, CDs, and horror.\n",
            "\n",
            "We've come a long way since then: ragtime and radio,  big bands and showtoons, 45s and triple concept albums, MTV and CDs. \n",
            "\n",
            "We've come a long way since then, from ragtime and radio to MTV and CDs and horror-core.\n",
            "\n",
            "We've advanced since then: ragtime & radio, hillbilly & race records, big bands & showtoons, MTV, CDs and horror-core.\n",
            "\n",
            "its mud barrier and mireth next unto Irishmenis now a mere rise of grass,a tree and spruce,where a child is playing at twilight.\n",
            "\n",
            "its ancient barrier unto Irishmenis now a rise of coarse grass, a rowan tree and some spruce, where a child is playing at twilight.\n",
            "\n",
            "The child now plays near an ancient barrier that was once made of mud, brambles, mirth and Irishmenis.\n",
            "\n",
            "its ancient barrier of mud, brambles, and mire is now a rise of grass, a rowan tree and a few spruce, where a child  plays at twilight.\n",
            "\n",
            "to sing like the thrush from the deepest partof the understory, in order to make one sobering sound.\n",
            "\n",
            "The deepest partof the understory, territorial,carnal, thorn-at-the-throat. order to make one sobering sound.\n",
            "\n",
            "To sing like the deepest part of the understory and make sobering sound, it is territorial, carnal\n",
            "\n",
            "To sing like thrush from deepest part of understory order to make one sobering sound.\n",
            "\n",
            "Can you give the literal meaning of these figures of speech, which appeared in the NY Times?\n",
            "\n",
            "give the meaning of these figures of speech, each of which appeared in a quotation in the Times ?\n",
            "\n",
            "Can you give the literal meaning of these figures of speech?\n",
            "\n",
            "Can you give the meaning of these figures of speech from the New York Times recent quotation?\n",
            "\n",
            "Can you give the actual meaning of these allegories, each appeared in the New York Times?\n",
            "\n",
            "Don't stand outside a bodega & ask if Bandito have killed someone & have a death penalty.\n",
            "\n",
            "You don't ask the bandito if he would have killed someone if there was a death penalty.\n",
            "\n",
            "The remark: \"You don't ask someone if he would have killed if there was a death penalty.\"\n",
            "\n",
            "You don't go to a bodega to ask the bandito if he would kill someone if there's a death penalty\n",
            "\n",
            "Working out of Oliver North's old office, Clark's lighthearted attitude has not discouraged Clinton from expanding counterterror activities.\n",
            "\n",
            "Clarke maintains a light hearted attitude toward the law that has not discouraged President Clinton.\n",
            "\n",
            "Clarke maintains a lighthearted attitude toward the law that hasn't discouraged Clinton from expanding counterterror activities into an $11B/year endeavor.\n",
            "\n",
            "Clarke maintains a lighthearted attitude toward a law allowing President Clinton to expand counterterror activities into an $11 billion a year endeavor.\n",
            "\n",
            "when I checked the published text, I was chagrined to discover that the passage\n",
            "\n",
            "d) When I checked the published text, the critical passage mentioning Krugman wasn't there.\n",
            "\n",
            "d) But, when I checked the text, I was chagrined Krugman was missing from a critical passage.\n",
            "\n",
            "When I saw the text, I was happy to see the critical passage mentioning Krugman wasn't there.\n",
            "\n",
            "When I checked the text, I was shocked to find that the passage mentioning Krugman wasn't there.\n",
            "\n",
            "Maybe the tabloid reading Emily Yoffe has done for Slate has taken a toll on her logical capacities.\n",
            "\n",
            "Al the tabloid reading Emily Yoffe has been doing on behalf of Slate has weakened her logical capacity.\n",
            "\n",
            "Maybe all the tabloid reading Emily Yoffe has been doing for Slate has messed up her logical capacity.\n",
            "\n",
            "The paper reading Emily Yoffe has been doing for Slate has hurt her logical capacities (\"Pay for Say\").\n",
            "\n",
            "Perhaps all the tabloid reading Emily Yoffe has been doing for Slate has taken a toll on her thinking.\n",
            "\n",
            "Where fast rural lines are, schools can't afford textbooks and periodicals, let alone new computers and training.\n",
            "\n",
            "Where fast rural lines are available, schools & libraries can barely afford books, let alone computers & training.\n",
            "\n",
            "Rural schools and libraries find it difficult to afford textbooks and periodicals, let alone new computers and training. \n",
            "\n",
            "3) Schools and libraries can barely afford essentials let alone new computers where fast lines are available.\n",
            "\n",
            "Schools and libraries can't afford textbooks and periodicals, let alone new computers and training for Web surfing. \n",
            "\n",
            "NY Times calls Reno's decision a \"turning point\" in that the investigation had swirled around the Oval Office but had not touched Clinton.\n",
            "\n",
            "The New York Times calls the Reno decision a \"potential turning point\" in that\"until now it swirls around the Oval office but had not touched Clinton. \n",
            "\n",
            "NY Times calls Reno decision a \"potention turning point\" in that the investigation had swirled around the oval office but had not touched Clinton.\n",
            "\n",
            "NYT calls Rena decision \"potential turning point\" in which the investigation focused on the Oval Office, but not Clinton.\n",
            "\n",
            "Ballentine recalls that Jones also told her that day about the mysterious so-called \"distinguishing mark\" that Jones' complaint says she saw on Clinton.\n",
            "\n",
            "Ballentine remembers Jones told her about the \"distinguishing mark\" that Jones' complaint says she saw on Clinton. Her lawyers are relying on it to corroborate her account.\n",
            "\n",
            "Ballentine recalls that Jones told her about the so-called \"mark\" that Jones' says she saw on Clinton, and on which Jones' lawyers say are relying to prove her account.\n",
            "\n",
            "Jones also told her about a so-called \"distinguishing mark\" that Jones' complaint says she saw on him, which Jones' lawyers say they are relying to corroborate her account.\n",
            "\n",
            "Batllentine recalls that Jones told her that day about the distinguishing mark that Jones' complaint says she saw on Clinton.\n",
            "\n",
            "After today, I won't talk about this aspect of the book and comment on what it says about Reagan himself.\n",
            "\n",
            "I'll try not to talk about this overanalyzed aspect of the book and comment on what it says about Reagan himself.\n",
            "\n",
            "I'll try not to talk about this overanalyzed aspect of the book and comment on what is says about Regan himself.\n",
            "\n",
            "After today I'll try not to talk about this aspect of the book, and comment on what it says about Reagan.\n",
            "\n",
            "I'll try not to talk about the overanalyzed aspect of the book and comment, as you have already, on what it says about Reagan.\n",
            "\n",
            "The New York Times described Tuesday's episode as: \"Cordelia likes the new watcher.\"\n",
            "\n",
            "NYT described Tuesday's episode as: \"Cordelia likes the new watcher.\"\n",
            "\n",
            "I don't have TV Guide, but the NYT described Tuesday's episode: \"Cordelia likes the new watcher.\"\n",
            "\n",
            "The NYT described Tuesday's episode this way: \"Cordelia likes the new watcher.\"\n",
            "\n",
            "The New York Times summed up Tuesday's episode: \"Cordelia likes the new watcher.\"\n",
            "\n",
            "Left for dead last week, President Clinton is Issues 1, 2, and 3 as he arises to defy predictions that he would soon resign.\n",
            "\n",
            "Contrary to news last week, President Clinton rises from the dead to defy near-unanimous predictions that he would soon resign.\n",
            "\n",
            " President Clinton issues 1, 2, and 3 as he rises to defy last week's near-unanimous predictions that he would soon resign. \n",
            "\n",
            "Left for dead by the media, President Clinton is Issues 1-3 as he rises to defy last week's predictions that he would soon resign.\n",
            "\n",
            "Are there questions of etiquette attached to wearing a wire  with one's friends and colleagues for the benefit of, say, a special prosecutor?\n",
            "\n",
            "Are there any questions attached to wearing a wire and recording conversations with one's friends for the benefit of special prosecutor? \n",
            "\n",
            "Are there questions of etiquette attached to recording conversations with one's friends and colleagues for the benefit of a prosecutor?\n",
            "\n",
            "What is the etiquette for a prosecutor, when wearing a wire to record friends?\n",
            "\n",
            "Beatles  Note: This link goes to a dead page but then proceeds to his new page. \n",
            "\n",
            "Beatles [Gabe Perlmutter](*This link is a dead page but proceeds to his new page.)\n",
            "\n",
            "Beatles [Gabe Perlmutter] ( Note: I'm counting this link as one link.)\n",
            "\n",
            "Beatles [Gabe Perlmutter] (Note: This link automatically proceeds to his page, so I'm counting it as one.)\n",
            "\n",
            "The Washington Post goes local with a report that candidates have no solution of northern Virginia's traffic problems which is a key issue in upcoming elections.\n",
            "\n",
            "Washington Post reports that neither Democrat nor Republican candidates have solved northern Virginia's traffic problems.\n",
            "\n",
            "The WP reports that neither Democrat nor Republican candidates have come up with a solution to northern Virginia's traffic issues, a key issue in the state's elections.\n",
            "\n",
            "The Washington Post goes local with a report that neither Democrat or Republican candidates have come up with a solution to northern Virginia's traffic problems.\n",
            "\n",
            "Washing Post reports that neither Democrat nor Republican candidates came up with a workable solution to northern Virginia's traffic problems.\n",
            "\n",
            "U.S. law prohibits contributions from any individual contractor or partnership doing business with the government.\n",
            "\n",
            "Contributions from anyone doing business with the government is prohibited, and requires name, address, occupation, and employer of anyone contributing over $200.\n",
            "\n",
            "U.S. law prohibits donations from anyone in business with the government, & requires an \"effort\" to obtain the name, address, occupation, & employer of everyone contributing over $200.\n",
            "\n",
            "U.S. law also prohibits contributions from any individual contractor or partnership doing business with the government.\n",
            "\n",
            "Q: The list includes Prowler, Wizard, Mongoose...Astrocam 110, Big Bertha, Big Dawg, and Exo-Skel.\n",
            "\n",
            "The list includes Prowler, Wizard, Mongoose, Venus Probe, Fire Streak, Zinger, Corkscrew, and Exo-Skel. \n",
            "\n",
            "Prowler, Wizard, Mongoose, Venus Probe, Fire Streak, Zinger, etc.\n",
            "\n",
            "The list includes Prowler, Wizard, Mongoose, Venus Probe, Fire Streak, Zinger, Corkscrew and four others.\n",
            "\n",
            "After referring to the report that economists don't seerising gas prices to trigger inflation, concludes with, \"Huh, isn't inflation measured as a rate of cost increase?\"\n",
            "\n",
            "After referring to the USA Today report, concludes with the rhetorical flourish, \"Huh, isn't inflation primarily measured as a rate of increase in cost?\"\n",
            "\n",
            "After referring to the USA Today report that economists don't expect rising gasoline prices to trigger inflation, concludes with the rhetorical flourish. \n",
            "\n",
            "Seeing the USA Today report that rising gas prices aren't expected to trigger inflation,\"Huh?Isn't inflation primarily measured as a rate of increase in cost?\"\n",
            "\n",
            "After referring to the report that gas prices aren't expected to trigger inflation, \"\" asks, \"isn't inflation primarily measured as a rate of increase in cost?\"\n",
            "\n",
            "My recent orthopedic difficulties weren't related to me not wanting to discuss matters with attorneys for Paula Jones, Kenneth Starr, or the media.\n",
            "\n",
            "Recent difficulties were not related to any unwillingness on my part to discuss these matters with attorneys for Paula Jones, Kenneth Starr, or the media.\n",
            "\n",
            "My orthopedic difficulties were not related to any unwillingness on my part to discuss these matters with attorneys for Jones, or the media. \n",
            "\n",
            "My orthopedic difficulties aren't related to unwillingness to discuss these or other matters with attorneys for Paula Jones, Kenneth Starr, or the media.\n",
            "\n",
            "The Washington Post reports the Beltway will get uglier as a federal appeals court brings back plans to replace Woodrow Wilson Memorial Bridge with a 12-lane one.\n",
            "\n",
            "The Beltway will get uglier as a fed appeals plans to replace the Woodrow Wilson Memorial Bridge with a 12-lane one that should alleviate congestion.\n",
            "\n",
            "The Washington Post 's reported that a federal appeals court resurrected plans to replace the deteriorating Woodrow Wilson Memorial Bridge.\n",
            "\n",
            "The Washington Post 's lead is local: The Beltway will get worse, as a court plans to replace the deteriorating bridge with a new one that should alleviate congestion.\n",
            "\n",
            "The Washington Posts' local lead: The Beltway will get uglier as federal appeals court plans to replace the deteriorating Woodrow Wilson Memorial Bridge with 12 lanes.\n",
            "\n",
            "Threats to health from corpses is minimal, so the WHO has urged Turkey to give more for injured and less for disposing the dead.\n",
            "\n",
            "Since the threat from corpses is small, the WHO has suggested focusing more on aiding the injured and less disposing of the dead.\n",
            "\n",
            "Because the threat from corpses is small, the WHO urged Turkey to allocate resources to aiding the injured instead of the dead.\n",
            "\n",
            "Since health threats from corpses are small, the WHO urges Turkey to use more resources aiding the injured.\n",
            "\n",
            "WHO has urged Turkey to allocate more resources to aiding the injured and fewer to disposing the dead.\n",
            "\n",
            "Clem Florio, 67, looked down from his lofty perch as the horses moved toward the starting gate for the sixth race.\n",
            "\n",
            "Clem Florio, 67, looked down from his perch as the horses meandered toward the starting gate for the sixth race. \n",
            "\n",
            "In the press box, the handicapper, Clem Florio, 67, looked down as the horses meandered toward the gate for the race.\n",
            "\n",
            "Clem Florio, 67, sat in the press box, waiting for the sixth race to start.\n",
            "\n",
            "The story's about what I do now, what I did at the White House and how many years I was a career person and a political appointee.\n",
            "\n",
            "The first few paragraphs should be about me--what I do now, what I did and for how many years.\n",
            "\n",
            "The first paragraphs should be about what I do now and did at the White House and how long I was there as a political appointee.\n",
            "\n",
            "The paragraphs should be about me. What I do now, what I did at the White House and how many years I was there as a career person?\n",
            "\n",
            "The first few paragraphs should be about me--what I do now, what I did at the White House and for how many years I was there.\n",
            "\n",
            "Which of the following are actual questions from G.W.'s official list?\n",
            "\n",
            "Which are actual prewritten questions from G.W.'s official list, and which are crude attempts to mock him?\n",
            "\n",
            "Which of the following are questions from G.W.'s official list, and which are attempts to mock him?\n",
            "\n",
            "What are the actual prewritten questions from G.W.'s list, & which are merely crude attempts to mock him.\n",
            "\n",
            "Which of the are questions from G.W.'s list, and which are merely attempts to mock and deride him?\n",
            "\n",
            "Though the O.J. trial was bizarre, Marcia Clark, Judge Ito and Simpson never fought over a check at dinner.\n",
            "\n",
            "The O.J. trial was bizarre, but Marcia Clark, Judge Ito and Simpson never fought over the dinner check.\n",
            "\n",
            "The O.J. trial was odd, but Marcia Clark, Judge Ito & Simpson never fought over a check at dinner.\n",
            "\n",
            "The OJ trial was bizarre, but Marcia Clark, Judge Ito and Simpson never fought over a check at the dinner.\n",
            "\n",
            "The O.J. trail was weird, but Marcia Clark, Judge Ito and Simpson never fought over a check at dinner.\n",
            "\n",
            "A photo accompanying an article in the ssue shows a letter carrier holding a parcel that is smoking. \n",
            "\n",
            "A photo July-August issue shows a letter carrier holding  another danger sign.\n",
            "\n",
            "A photo in an article in the July-August issue shows a parcel that is smoking, probably a danger sign.\n",
            "\n",
            "A photo in a July-August article shows a letter carrier holding a parcel that is smoking.\n",
            "\n",
            "A photo in the July-August issue shows a carrier holding a parcel that is smoking, another danger sign.\n",
            "\n",
            "If ultimately unusable newspaper clippings are the clutter, then the News Quiz Spring Cleaning Extra is the rug under which to sweep them.\n",
            "\n",
            "If amusing but unusable newspaper clippings are the dust of a free-lance living room, then the News Quiz Spring Cleaning Extra is the rug.\n",
            "\n",
            "If newspaper clippings are the dust bunnies of a free-lance humorist's, then the Spring Cleaning Extra is the rug under which to sweep them.\n",
            "\n",
            "If amusing newspaper clipings are dust bunnies in a humorist's room, then the News Quiz Spring Cleaning Extra is the rug to sweep them under.\n",
            "\n",
            "Responding to a question about Sinatra's impact on popular culture, Carney announces that the Dayton, Ohio, riff-rockers are his favorite band. \n",
            "\n",
            "Jay Carney announces that Guided by Voices, Dayton, Ohio, are his favorite band.\n",
            "\n",
            "Responding about Frank Sinatra's impact on culture, Jay Carney announces that Guided by Voices, Dayton, Ohio, riff-rockers, are his favorites.\n",
            "\n",
            "Rockin' Jay Carney: Responding to a question about Sinatra's impact on pop culture, Carney announces that Guided by Voices is his favorite band.\n",
            "\n",
            "Jay Carney responded to a question about Frank Sinatra's impact on popular culture by announcing that his favorite band is Guided by Voices.\n",
            "\n",
            "The insertion of the U.N.-supported peacekeeping force into East Timor is going so uneventfully.\n",
            "\n",
            "The force insertion into East Timor isn't eventful so far that it's off everybody's front save the NYT's.\n",
            "\n",
            "The insertion of the U.N.-supported peacekeeping force into East Timor is going so uneventfully thus far.\n",
            "\n",
            "In Harper: Technoscholars discuss the significance of the showdown between the chess champion Kasparov and a supercomputer.\n",
            "\n",
            "In Harper's: Technoscholars discuss the metaphysical significance of the match between Gary Kasparov and computer.\n",
            "\n",
            "Also in Harper's, scholars discuss the metaphysical significance of chess between champion, Gary Kasparov and a computer.\n",
            "\n",
            "Also: A group of technoscholars discuss the showdown between world chess champion Gary Kasparov and a supercomputer.\n",
            "\n",
            "Technoscholars discuss the significance of the showdown between chess champion Gary Kasparov and a supercomputer.\n",
            "\n",
            "Time reports, the IRS fails to collect billions a year in owed taxes, because its system is too crude to catch frauds.\n",
            "\n",
            "Time reports that the IRS fails to collect $150 billion a year, because its computer system is unable to catch frauds.\n",
            "\n",
            "Time reports the IRS fails to collect $150 billion a year in owed taxes because of its ancient computer system.\n",
            "\n",
            "Time reports that the IRS fails collecting $150 billion a year. Its old system is too crude to catch frauds.\n",
            "\n",
            "IRS fails to collect $150 billion a year in taxes, mostly due to it's computer system's ability to catch frauds.\n",
            "\n",
            "A child-support suit was filed against Roger Clinton, for a child he conceived in 1990.\n",
            "\n",
            "A child support suit was filed against Roger Clinton on behalf of a child he conceived in 1990.\n",
            "\n",
            "A child-support suit was filed against Roger Clinton, because he had a child with a married woman.\n",
            "\n",
            "Health policy debates can be boring, but there are two reasons why you should care about them.\n",
            "\n",
            "Health policy debates can be boring, but here is why observers should care what's going on here:\n",
            "\n",
            "Health policy debates are dull, but there are 2 reasons why observers should care about this.\n",
            "\n",
            "Health policy debates tend to be eye-glazing, but there are reasons why observers should care.\n",
            "\n",
            "Health policy debates tend to be eye-glazing, but observers should care about what's going on.\n",
            "\n",
            "The film The Basketball Diaries ,the game Mortal Kombat, and the sex site Meow Media, what's the connection?\n",
            "\n",
            "How are the film The Basketball Diaries, the game Mortal Combat, and the sex site Meow Media connected?\n",
            "\n",
            "The Basketball Diaries, Mortal Combat, and Meow Media--what's the connection?\n",
            "\n",
            "The Leonardo DiCaprio film The Basketball Diaries , the computer game Mortal Combat...?\n",
            "\n",
            "The film The Basketball Diaries, the game Mortal Combat, and Internet sex site Meow Media, what's the connection?\n",
            "\n",
            "The story reminds us of a truth of consumer service: It's not the crime, it's the cover-up.\n",
            "\n",
            "M's story reminds Shopping Avengers that, \"It's not the crime, it's the cover-up.\"\n",
            "\n",
            "The story of M. reminds the Shopping Avenger of a central truth of consumer service.\n",
            "\n",
            "The Shopping Avenger is reminded of a central truth: It's not the crime but the cover-up.\n",
            "\n",
            "Book-Big Trouble: A Murder in a Small Western Town Sets Off a Struggle for Soul America\n",
            "\n",
            "Big Trouble: A small town murder begins struggle for Soul of America - J. Anthony Lukas;\n",
            "\n",
            "Book -- Big trouble: About a Murder in a small town, by J. Anthony Lukas.\n",
            "\n",
            "Big Trouble: A Murder in a Small Western Town Sets Off a Struggle for the Soul of America\n",
            "\n",
            "Book- Big Trouble: A Murder in a Small Western Town Sets off a Strug..., by J. A. Lukas \n",
            "\n",
            "Prudie is willing to blow her cover & offer you her trick: When stuck, just say, \"Tell me your whole name,\" implying that she remembers.\n",
            "\n",
            "Prudie's trick when stuck is to say \"Tell me your whole name,\" implying that she remembers one name, but not both.\n",
            "\n",
            "Prudie is willing to blow her cover and offer you her trick: when stuck say \"Tell me your whole name,\"\n",
            "\n",
            "Prudie is offering her trick: When stuck, just say, \"Tell me your whole name,\" implying that she remembers one name, but not both.\n",
            "\n",
            "Prudie offers you her trick: When stuck say, \"Tell me your whole name,\" implying that she remembers one name.\n",
            "\n",
            "the breadfruit opens its palms in praise of the bounty, bois-pain , tree of bread, slave food, the bliss of John Clare,\n",
            "\n",
            "cores the dawn clouds with radiance, the breadfruit opens its palms in praise of the bounty, the bliss of John Clare\n",
            "\n",
            "Cores dawn clouds with radiance, breadfruit opens palms in praise of bounty, bliss of John Clare.\n",
            "\n",
            "cores the dawn clouds with radiance, the breadfruit opens its palms, bois-pain, tree of bread, slave food, the bliss of Clare\n",
            "\n",
            "When asked if Blevens still plays a role in Metabolife, it was stated he hasn't.\n",
            "\n",
            "Will Blevens still plays an active role in Metabolife, he hasn't for \"almost a year.\"\n",
            "\n",
            "When asked if Blevens still plays a role in Metabolife, Ellis said not for almost a year.\n",
            "\n",
            "Admirable use of quiz form to slyly denigrate the military-industrial complex.\n",
            "\n",
            "Admirable use of quiz form to denigrate the military industrial complex.\n",
            "\n",
            "Nice use of form to denigrate the military-industrial complex, but the 4th choice might have been Bill Gates.\n",
            "\n",
            "Comment : Admirable use of quiz form to slyly denigrate the military-industrial complex. \n",
            "\n",
            "quiz form slyly belittles military complex, though #4 might have been \"Bill Gates.\"\n",
            "\n",
            "There is an ideology that corporations are unfairly maligned and are less powerful than made out to beb - Professor Michael Pinto-Duchinsky\n",
            "\n",
            "There is an ideology among certain historians that corporations are unfairly maligned and less powerful than they appear to be, says Professor Michael Pinto-Duchinsky.\n",
            "\n",
            "Corporate historians have an ideology that corporations are unfairly maligned & less powerful than they seem says Professor Pinto-Duchinsky of England's Brunel University.\n",
            "\n",
            "Among certain corporate historians, there is an ideology that corporations are unfairly maligned and that they are less powerful than they are made out to be,\n",
            "\n",
            "Like misprinted stamps, the beautiful blanket will have extra meaning because of the erroneous date.\n",
            "\n",
            "Like error stamps that are valuable because they are mistakes, the blanket will have extra meaning because of the wrong date.\n",
            "\n",
            "Like misprinted stamps that become valuable because they are mistakes, the blanket will have more meaning because of the wrong date.\n",
            "\n",
            "Like misprinted stamps become valuable as mistakes, the blanket will have memory and meaning because of the date.\n",
            "\n",
            "After all, if you are one of Newt's revolutionaries, with no messy votes and no responsibility.\n",
            "\n",
            "If you're one of Newt's revolutionaries, an overestimated CPI is similar to Bob Dole's tax cuts, Forbes tax reforms, and Lugar's IRS abolition.\n",
            "\n",
            "An overestimated CPI is the practical equivalent of Bob Dole's tax cuts, Steve Forbes' tax reforms, and Richard Lugar's IRS abolition, with no messy votes or responsibility.\n",
            "\n",
            "If you are one of Newt's revolutionaries, an overestimated CPI is the equivalent of Bob Dole's tax cuts, Steve Forbes' tax reforms, and Richard Lugar's IRS abolition.\n",
            "\n",
            "If you're one of Newt's revolutionaries, an overestimated CPI is the equivalent of Dole's tax cuts, Forbes' tax reforms, and Lugar's IRS abolition- with no responsibility.\n",
            "\n",
            "Due to your sloppy \"gist\" on claimed payments to David Hale, one can assume bias on the author, Franklin Foer\n",
            "\n",
            "The \"Gist\" on David Hale is so sloppy that one may assume some bias by its author, Associate Editor Franklin Foer.\n",
            "\n",
            "Your \"Gist\" on alleged payments to David Hale is so sloppy that you might assume  bias by its author, Franklin Foer.\n",
            "\n",
            "When I need something, I can read up or ask a professional, but what I really wonder is: What sort of earthmover do celebrities recommend?\n",
            "\n",
            "When I need shampoo, stereo, or heavy equipment, I can read or ask a professional, What I wonder is: What earthmover do celebrities recommend?\n",
            "\n",
            "When I need shampoo, a stereo, or industrial equipment, I can read up or ask, but I wonder what earthmover do celebrities recommend.\n",
            "\n",
            "I can read or ask a professional for shampoo, stereo, or industrial equipment, but I wonder: What sort of earthmover do celebrities recommend?\n",
            "\n",
            "When I need anything, I can read up or ask a professional, but what I really wonder is: What sort of earthmover do celebrities recommend?\n",
            "\n",
            "NIDA: Long-term marijuana us produces brain changes similar to those of other major drugs of abuse such as cocaine, heroin, and alcohol.\n",
            "\n",
            "NIDA: \"Long-term use of marijuana changes the brain similarly to those of long term use of drugs like cocaine, heroin, and alcohol.\"\n",
            "\n",
            "Long-term use of Marijuana alter the brain similarly to those seem after long-term use of other abusable drugs.\n",
            "\n",
            "The Jets, many fans' pick to go to the Super Bowl, lost their season opener and 4 starters including quarterback Vinny Testaverde, out for the season.\n",
            "\n",
            "The Jets, many fans pick to make it to the Super Bowl, lost their season opener and four starters including Vinny Testaverde, out for the season with an injury.\n",
            "\n",
            "The Jets, many fans' pick for the Super Bowl, lost their season opener & 4 starters including quarterback Vinny Testaverde.\n",
            "\n",
            "The Jets lost their season opener and four starters, including quarterback Vinny Testaverde, out for the season with a ruptured Achilles' tendon.\n",
            "\n",
            "Smell the wines first, smell the standards, see which terms describe which wine, writes Noble.\n",
            "\n",
            "From this point on, anything goes: Smell the wines first.\n",
            "\n",
            "Smell the wines first, start to see which terms describe which wine, writes Noble. \n",
            "\n",
            "From now on, anything goes: Smell the wines and standards, and match the terms to the wine, writes Noble.\n",
            "\n",
            "\"It is with the deepest regret that we announce the sudden death of our friend Professor Greenbaum. \t23\t3\t2.66666666666667\t300000\t      \"\"I  \"\"It  \"\"It   \"\"It i  \"\"It is  \"\"It is   \"\"It is w  \"\"It is wi  \"\"It is wit  \"\"It is with  \"\"It is with   \"\"It is with t  \"\"It is with th  \"\"It is with the  \"\"It is with the   \"\"It is with the d  \"\"It is with the de  \"\"It is with the dee  \"\"It is with the deep  \"\"It is with the deepe  \"\"It is with the deepes  \"\"It is with the deepest  \"\"It is with the deepest   \"\"It is with the deepest r  \"\"It is with the deepest re  \"\"It is with the deepest reg  \"\"It is with the deepest regr  \"\"It is with the deepest regre  \"\"It is with the deepest regret  \"\"It is with the deepest regret   \"\"It is with the deepest regret t  \"\"It is with the deepest regret th  \"\"It is with the deepest regret tha  \"\"It is with the deepest regret that  \"\"It is with the deepest regret that   \"\"It is with the deepest regret that w  \"\"It is with the deepest regret that we  \"\"It is with the deepest regret that we   \"\"It is with the deepest regret that we a  \"\"It is with the deepest regret that we an  \"\"It is with the deepest regret that we ann  \"\"It is with the deepest regret that we annp  \"\"It is with the deepest regret that we ann  \"\"It is with the deepest regret that we anno  \"\"It is with the deepest regret that we annou  \"\"It is with the deepest regret that we announ  \"\"It is with the deepest regret that we announc  \"\"It is with the deepest regret that we announce  \"\"It is with the deepest regret that we announce   \"\"It is with the deepest regret that we announce t  \"\"It is with the deepest regret that we announce th  \"\"It is with the deepest regret that we announce the  \"\"It is with the deepest regret that we announce the   \"\"It is with the deepest regret that we announce the s  \"\"It is with the deepest regret that we announce the su  \"\"It is with the deepest regret that we announce the sud  \"\"It is with the deepest regret that we announce the sudd  \"\"It is with the deepest regret that we announce the sudde  \"\"It is with the deepest regret that we announce the sudden  \"\"It is with the deepest regret that we announce the sudden   \"\"It is with the deepest regret that we announce the sudden d  \"\"It is with the deepest regret that we announce the sudden de  \"\"It is with the deepest regret that we announce the sudden dea  \"\"It is with the deepest regret that we announce the sudden deat  \"\"It is with the deepest regret that we announce the sudden death  \"\"It is with the deepest regret that we announce the sudden death   \"\"It is with the deepest regret that we announce the sudden death o  \"\"It is with the deepest regret that we announce the sudden death of  \"\"It is with the deepest regret that we announce the sudden death of   \"\"It is with the deepest regret that we announce the sudden death of o  \"\"It is with the deepest regret that we announce the sudden death of ou  \"\"It is with the deepest regret that we announce the sudden death of our  \"\"It is with the deepest regret that we announce the sudden death of our   \"\"It is with the deepest regret that we announce the sudden death of our f  \"\"It is with the deepest regret that we announce the sudden death of our fr  \"\"It is with the deepest regret that we announce the sudden death of our fri  \"\"It is with the deepest regret that we announce the sudden death of our frie  \"\"It is with the deepest regret that we announce the sudden death of our frien  \"\"It is with the deepest regret that we announce the sudden death of our friend  \"\"It is with the deepest regret that we announce the sudden death of our friend   \"\"It is with the deepest regret that we announce the sudden death of our friend P  \"\"It is with the deepest regret that we announce the sudden death of our friend Pr  \"\"It is with the deepest regret that we announce the sudden death of our friend Pro  \"\"It is with the deepest regret that we announce the sudden death of our friend Prof  \"\"It is with the deepest regret that we announce the sudden death of our friend Profe  \"\"It is with the deepest regret that we announce the sudden death of our friend Profes  \"\"It is with the deepest regret that we announce the sudden death of our friend Profess  \"\"It is with the deepest regret that we announce the sudden death of our friend Professo  \"\"It is with the deepest regret that we announce the sudden death of our friend Professor  \"\"It is with the deepest regret that we announce the sudden death of our friend Professor   \"\"It is with the deepest regret that we announce the sudden death of our friend Professor G  \"\"It is with the deepest regret that we announce the sudden death of our friend Professor Gr  \"\"It is with the deepest regret that we announce the sudden death of our friend Professor Gre  \"\"It is with the deepest regret that we announce the sudden death of our friend Professor Gree  \"\"It is with the deepest regret that we announce the sudden death of our friend Professor Green  \"\"It is with the deepest regret that we announce the sudden death of our friend Professor Greenb  \"\"It is with the deepest regret that we announce the sudden death of our friend Professor Greenba  \"\"It is with the deepest regret that we announce the sudden death of our friend Professor Greenbau  \"\"It is with the deepest regret that we announce the sudden death of our friend Professor Greenbaum  \"\"It is with the deepest regret that we announce the sudden death of our friend Professor Greenbaum.  \"\"It is with the deepest regret that we announce the sudden death of our friend Professor Greenbaum. \"\n",
            "\n",
            "It is with the deepest regret that we announce the sudden death of our friend Professor Greenbaum.\n",
            "\n",
            "It's with deep regret that we announce the sudden death of our friend, Professor Greenbaum.\n",
            "\n",
            "We deeply regret that on May 28,1996, while on a speaking engagement in Moscow, Professor Greenbaum died suddenly.\n",
            "\n",
            "The creature APOSTA,falls in love with men, so much that it follows them.\n",
            "\n",
            "APOSTA, a creature in Tobago, often followed them and gazes on them. \n",
            "\n",
            "APOSTA, a creature in the island of Tobago,loves men so much that it often follows them.\n",
            "\n",
            "APOSTA, a creature in the island of Tobago loves men so much that it often follows them. \n",
            "\n",
            "APOSTA in the island of Tobago so much in love with men, that it follows them and gazes on them.\n",
            "\n",
            "Should I ask the manager to change the locks or should I ask for the key back?\n",
            "\n",
            "Should I ask for the locks to be changed or the key back, or let is slide?\n",
            "\n",
            "Should I let the matter go, ask to change the locks, or ask for the key back?\n",
            "\n",
            "Should I let it slide, ask the manager to change the lock, or ask for the key back?\n",
            "\n",
            "Spevack lists the word under Communication (subgroup Pseudo foreign), along with tongue-twisters.\n",
            "\n",
            "Professor Spevack lists that final blend word under Communication, along with tongue-twisters like oscorbidulchos and kerelybonto.\n",
            "\n",
            "Professor Spevack lists that final blend word under Communication along with 36 other tongue-twisters.\n",
            "\n",
            "Spevack lists the final blend word under Communication, and 36 tongue-twisters including oscorbidulchos and kerelybonto.\n",
            "\n",
            "Spevack lists that final blend word under Communication, among them, oscorbidulchos and kerelybonto.\n",
            "\n",
            "Here's Bradley complaining about Gore's implication of raising the eligibility age for Social Security.\n",
            "\n",
            "Here's Bradley complaining to Meet the Press moderator Time Russert about Gore's Social Security insinuations.\n",
            "\n",
            "Here's Bradley complaining to Tim Russert about Gore's insinuation that he might raise the Social Security age. \n",
            "\n",
            "Bradley complaining to Meet the Press mod Tim Russert about Gore raising the eligibility age for Social Security.\n",
            "\n",
            "Bradley comlpains to Tim Russert about Gore's insinuation that he might raise the age for Social Security. \n",
            "\n",
            "There is shifting from the uncritical worship to the new enthusiastic groveling before Hollywood celebrities.\n",
            "\n",
            "Still shifting from old editorial policy of Hollywood celebrity worship to new polity of groveling before celebrities.\n",
            "\n",
            "From old editorial policy of worship of Hollywood celebrities to new policy of groveling before Hollywood celebrities.\n",
            "\n",
            "Shifting from old policy of worship of Hollywood celebrities to new policy of enthusiastic groveling.\n",
            "\n",
            "Still working on rule-making with use of lite/light as a label for malt beverages, wines, & spirits.\n",
            "\n",
            "proposals on hand, is still working on rule-making with regard to the use of light as a alcohol label.\n",
            "\n",
            "Rule-making on the use of lite/light as labels for alchohol are on hand.\n",
            "\n",
            "rules are being proposed for the use of lite/light as a label for malt beverages, wines, and spirits.\n",
            "\n",
            "Did the Roosevelt White House do a disservice in providing a model, in which poor folks and children were sentimentalized as women's work?\n",
            "\n",
            "Did the Roosevelt White House do a disservice in providing a model in which poor folks, children and the lame were sentimentalized as women's work?\n",
            "\n",
            "Did the divided Roosevelt White House provide a bad model for later administrations, by insidiously sentimentalizing people in need as women's work?\n",
            "\n",
            "Did the Roosevelt White House do a disservice in providing a model for later administrations, in which poor folks, children and the lame were women's work?\n",
            "\n",
            "Did Roosevelt White House do a disservice in providing a model for later administrations, in which caregivers were insidiously sentimentalized as women's work\n",
            "\n",
            "I can't see myself asking Jessie out on a date, can you?\n",
            "\n",
            "A boy's best friend is his dog, but I still won't ask Jessie on a date\n",
            "\n",
            "A boy's best friend is his dog, but I can't see myself asking Jessie on a date.\n",
            "\n",
            "A boy's best friend is his dog,but I can not see myself asking it out on a date.\n",
            "\n",
            "Many a denizen of the United States regards light as a label that indicates a beer is lower in calories than its nonlight counterparts.\n",
            "\n",
            "Currently most of the US thinks of light as a label meaning the beer is lower in calories than nonlight beer.\n",
            "\n",
            "Now many living in the U.S. think light is a label that shows a beer is low in calories than nonlight.\n",
            "\n",
            "Currently many denizens of the US regard light as a label indicating that a beer is lower in calories than its nonlight counterparts.\n",
            "\n",
            "I am addressing this to you ... and hope that word may eventually drift back to England.\n",
            "\n",
            "I am writing you since I don't have the address of the journal of original publication, and hope that word may drift back to England.\n",
            "\n",
            "I'm addressing this to you since I don't have the address for The Independent and hope that word may eventually get back to England.\n",
            "\n",
            "I am sending this to you as you do not have the address for the original publication and hope (The Independent) word gets to England.\n",
            "\n",
            "I am addressing this to you since I don't have the address of the journal of original publication. \n",
            "\n",
            "Officer Ron Discher reported that the farm has stopped work on the paddock, an enclosed area where horses graze.\n",
            "\n",
            "Zoning Enforcement Officer Ron Discher reported that the farm has stopped work on the paddock.\n",
            "\n",
            "Official Ron Discher said the farm has stopped work on the enclosed area where horses can graze and be mounted.\n",
            "\n",
            "A Tok Pisin version of Little Red Riding Hood remains to this day one of the most hilarious monologues I have ever heard.\n",
            "\n",
            "Little Red Riding Hood, told by an old Chinese Sailor, remains to be one of the most hilarious monologues I've ever heard.\n",
            "\n",
            "A Tok Pision version of Red Riding Hood told me some years ago by a sailor, remains one of the most hilarious monologues I've heard.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/My Drive/NLP_PROJECT.xlsx\" ."
      ],
      "metadata": {
        "id": "LvcQCmJaLdPO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_excel('NLP_PROJECT.xlsx')"
      ],
      "metadata": {
        "id": "dwPolZL8Lihm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)\n",
        "man_hf = df[\"Manual HF Score\"].values.tolist()\n",
        "print(man_hf)\n",
        "fluency_score1 = df[\"Normalized Fluency Score\"].values.tolist()\n",
        "print(fluency_score1)\n",
        "fluency_score2 = df[\"Normalized Fluency Score1\"].values.tolist()\n",
        "print(fluency_score2)\n",
        "fluency_score3 = df[\"Normalized Fluency Score2\"].values.tolist()\n",
        "print(fluency_score3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jL3REqpFL1Ji",
        "outputId": "f8d2b364-d5bc-47f0-c793-b2890aa13037"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['text', 'readbility_index1_score', 'Normalized readbility_index1_score',\n",
            "       'readbility_index2_score', 'Normalized readbility_index2_score',\n",
            "       'readbility_index3_score', 'Normalized readbility_index3_score',\n",
            "       'readbility_index4_score', 'Normalized readbility_index4_score',\n",
            "       'readbility_index5_score', 'Normalized readbility_index5_score',\n",
            "       'LSTM PERPLIXITY SCORES', 'Normalized LSTM PERPLIXITY SCORES',\n",
            "       'Statistical_model LM score', 'Normalized Statistical_model LM score',\n",
            "       'Normalized Fluency Score', 'Manual HF Score',\n",
            "       'Normalized Fluency Score1', 'Normalized Fluency Score2'],\n",
            "      dtype='object')\n",
            "[2.0, 4.5, 5.0, 4.0, 3.0, 1.5, 3.0, 3.5, 3.5, 4.5, 3.0, 3.0, 4.5, 2.0, 4.5, 1.5, 4.5, 2.5, 3.5, 3.0, 4.0, 2.0, 3.0, 3.5, 4.5, 3.5, 4.0, 2.0, 2.0, 3.0, 3.0, 4.0, 2.0, 3.5, 4.0, 3.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 3.0, 4.0, 2.0, 4.0, 3.0, 2.0, 2.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 4.0, 2.0, 3.0, 1.5, 2.0, 3.0, 3.0, 2.5, 1.5, 2.5, 2.0, 2.5, 2.5, 2.0, 2.0, 2.5, 3.0, 2.0, 2.0, 2.5, 2.5, 2.5, 2.5, 1.5, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0]\n",
            "[6.392822282965525, 5.488174854652169, 5.1662718314537415, 5.094648698015676, 4.603688801107007, 4.573652908813585, 4.552764456994628, 4.549313429697516, 4.482554468119126, 4.1353904336190075, 4.06823604540236, 4.040670544846902, 4.021104102665612, 3.9811429325916676, 3.968640970963089, 3.958358883821539, 3.947482278609276, 3.9265524844651294, 3.924429284730823, 3.9242135346816354, 3.9087113922139616, 3.8842674227691183, 3.8834143694809953, 3.879674087492239, 3.7025374461806786, 3.690094777307223, 3.683911925638138, 3.6767770908135837, 3.6745830941462296, 3.6626994465360085, 3.648653300171093, 3.6462579989674806, 3.6457849590270093, 3.6386798623164225, 3.0250220020465863, 2.9758732877122624, 2.9473212574174483, 2.944775649659897, 2.9258428859044088, 2.923978408186643, 2.915953423680764, 2.9118882078162667, 2.8951972875714342, 2.891865275032821, 2.883145669862237, 2.8823487129495806, 2.8555723382042264, 2.851659164842355, 2.8465917107170235, 2.844952827755145, 2.833690482997342, 2.8320261637202355, 2.8296668229843296, 2.823486580897801, 2.80084839795246, 2.800333754210303, 2.797429657426437, 2.7961082920028737, 2.7938310077736004, 2.789699726388407, 2.7886626108291814, 2.714034916355719, 2.7032320621013306, 2.7003209859262056, 2.6888119501135286, 2.66813928847464, 2.3253225315233688, 2.31432133907322, 2.3091510414463947, 2.3020047918538675, 2.301187976713836, 2.299703192898038, 2.299368996987381, 2.292965861980705, 2.2907932818210996, 2.2829793769745947, 2.2796490978821766, 2.2778896782970586, 2.277567122149363, 2.2704743623449692, 2.2617413284989634, 2.2583336789702493, 2.2564522915329226, 2.2404942075456145, 2.2358528483618083, 2.2210237516896743, 2.2175039160933556, 2.216489658151473, 2.1334584587558387, 1.448361386527424, 1.4256117678044826, 1.4235169974174353, 1.422028899371469, 1.4143702953706114, 1.240406864999009, 1.140704109313459, 1.1300986558362254, 1.1198227557817981]\n",
            "[6.670567349652128, 4.644934172226274, 5.262000503284597, 3.7784440505904984, 4.704023117114126, 3.549303278046385, 3.3124999777092294, 3.1530895727056665, 3.659310297343075, 3.8900912872190334, 3.135342121673788, 3.3074888266181413, 2.744071941721638, 2.9705236902105443, 2.7219458122402207, 2.680533112370348, 2.6983295573773876, 3.6190868742116953, 2.7218416260076816, 2.8938975533123923, 2.7386368212571854, 3.103421690005535, 2.760898857397037, 3.723107952796492, 2.70037857605077, 3.2448876925468184, 3.020757065170252, 2.5521008350215038, 2.766305885880655, 3.1725852152903657, 3.156620968196971, 2.4553416618448627, 2.427133666082214, 2.603933927904765, 2.129210773177011, 2.191544419054288, 2.258988757250543, 2.3313032123031756, 2.3534397484582197, 2.0770924651945526, 1.9331375216927102, 2.0860824264811444, 2.289136992418093, 2.5137768019186497, 2.0192421192552734, 2.0426232309805017, 1.9492572021439634, 2.39285195231929, 2.0328996702788347, 2.3411689694437245, 2.758487361532997, 2.0429000204074903, 2.0262652108835195, 1.9602542236541924, 2.023005710245333, 2.1416389571909153, 1.93294325602508, 2.048582651215041, 2.142022864616696, 2.055538009959858, 2.2185248233917636, 1.9893090645196678, 1.8703069957908425, 1.8322677767468547, 2.099938771042383, 1.9868938869798543, 1.629524838962312, 1.591125073064254, 1.567068615243064, 1.8215473723767714, 1.663962448220556, 1.7226172568091545, 1.5592347606833274, 1.5018208468213432, 1.9236734144167242, 1.6492843544652793, 1.6295605768655705, 1.7538975266815735, 1.6090119825282192, 1.8251064810677173, 1.578588000084213, 1.541936764350314, 1.5828497788449205, 1.7398918526073268, 1.632288593112468, 1.607912040859139, 1.5128140847019682, 1.4812588405706908, 1.4486204548327162, 1.0520364318845123, 1.684306491619456, 1.3313200486248142, 1.032157798652337, 0.9850102812334025, 1.2165086506279001, 0.8378021442322521, 1.070447399701732, 0.9569270967349218]\n",
            "[6.219597048566749, 4.979702438633718, 4.965663984272016, 4.455965657020347, 4.430608051045036, 4.050876668489946, 3.9621724834501486, 3.9100880578897765, 4.025386498538556, 3.8753423660419406, 3.6014362787823484, 3.6404548189137262, 3.4458041168636133, 3.4876899430832053, 3.4041928508264876, 3.3824795564282786, 3.3812962470128167, 3.665322121801817, 3.373520211788892, 3.429248053398191, 3.3685784073175844, 3.4686838693177386, 3.3592779026527726, 3.6599521115991474, 3.225267817816432, 3.3863911350065528, 3.3137723494521962, 3.1766783948355712, 3.226749117383676, 3.3460915341979405, 3.3324568849664704, 3.1128343068068443, 3.1038631638232363, 3.1531608471303145, 2.6100719770389933, 2.6139582137328663, 2.601253767798722, 2.634974518714555, 2.616594239950368, 2.5293089111729494, 2.4786611223286705, 2.5239556407581345, 2.5842558216421265, 2.6455121369421084, 2.4850692842369733, 2.498127609980956, 2.4455857131485685, 2.6045762690566288, 2.465776649543035, 2.5609902823955992, 2.683865336501146, 2.459004935849424, 2.452290878682423, 2.427724307804332, 2.4327430415264533, 2.4697547658389754, 2.4105326955216584, 2.438375931132368, 2.4703717211939313, 2.4357997829980045, 2.4861417907779977, 2.3665677175726314, 2.322349665068613, 2.3088055940397454, 2.384798367030606, 2.336423804448799, 2.014037819404553, 1.986654223190126, 1.9747607040485229, 2.050614394486238, 1.9996638460906668, 2.026132535649348, 1.9656707282409933, 1.9447970891197943, 2.07482046735187, 1.9843761550112338, 1.9800054898456003, 2.0128516951758155, 1.9675010770190426, 2.031923740575899, 1.9479660431690018, 1.9339644871893258, 1.9452370429935304, 1.9848787343121532, 1.9475067501730754, 1.93041245309062, 1.8983888626781977, 1.8878260054883798, 1.8242643963012204, 1.2629352633068744, 1.4430702409291496, 1.331337210121561, 1.2368278141791786, 1.2175254816410621, 1.17843891839293, 0.996838098514595, 1.0651721692952463, 1.0229985380076825]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import pearsonr\n",
        "corr, _ = pearsonr(man_hf, fluency_score1)\n",
        "print('Pearsons correlation: %.3f' % corr)\n",
        "corr, _ = pearsonr(man_hf, fluency_score2)\n",
        "print('Pearsons correlation: %.3f' % corr)\n",
        "corr, _ = pearsonr(man_hf, fluency_score3)\n",
        "print('Pearsons correlation: %.3f' % corr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giS1cvSYNRTJ",
        "outputId": "53945bdc-2fa2-467b-a3bb-6b5278592d5b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pearsons correlation: 0.519\n",
            "Pearsons correlation: 0.429\n",
            "Pearsons correlation: 0.496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "sns.regplot(x=df[\"Manual HF Score\"], y=df[\"Normalized Fluency Score\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "bViDxkUZO4lG",
        "outputId": "60e4f23a-43b9-47d7-badf-f38aed6fc87e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0aad095390>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJW8Qi-pPpep"
      },
      "source": [
        "## Longer runtimes\n",
        "\n",
        "All Colab runtimes are reset after some period of time (which is faster if the runtime isn't executing code). While Colab Pro subscribers still have limits, these will be roughly twice the limits for non-subscribers, with even more stability for Pro+."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLlTRcMM_h0k"
      },
      "source": [
        "## Resource limits in Colab Pro\n",
        "\n",
        "Your resources are not unlimited in Colab. To make the most of Colab Pro and Pro+, please avoid using resources when you don't need them. For example, only use a GPU or high-RAM runtime when required, and close Colab tabs when finished.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm8FzEidvPs6"
      },
      "source": [
        "## Send us feedback!\n",
        "\n",
        "If you have any feedback for us, please let us know. The best way to send feedback is by using the Help > 'Send feedback...' menu. If you encounter usage limits in Colab Pro consider subscribing to Pro+. If you are interested in unlimited pay as you go usage to remove all imposed limits, please do let us know.\n",
        "\n",
        "If you encounter errors or other issues with billing (payments) for Colab Pro or Pro+, please email [colab-billing@google.com](mailto:colab-billing@google.com)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB3bdLe8jkAa"
      },
      "source": [
        "## More Resources\n",
        "\n",
        "### Working with Notebooks in Colab\n",
        "- [Overview of Colaboratory](/notebooks/basic_features_overview.ipynb)\n",
        "- [Guide to Markdown](/notebooks/markdown_guide.ipynb)\n",
        "- [Importing libraries and installing dependencies](/notebooks/snippets/importing_libraries.ipynb)\n",
        "- [Saving and loading notebooks in GitHub](https://colab.research.google.com/github/googlecolab/colabtools/blob/master/notebooks/colab-github-demo.ipynb)\n",
        "- [Interactive forms](/notebooks/forms.ipynb)\n",
        "- [Interactive widgets](/notebooks/widgets.ipynb)\n",
        "- <img src=\"/img/new.png\" height=\"20px\" align=\"left\" hspace=\"4px\" alt=\"New\"></img>\n",
        " [TensorFlow 2 in Colab](/notebooks/tensorflow_version.ipynb)\n",
        "\n",
        "<a name=\"working-with-data\"></a>\n",
        "### Working with Data\n",
        "- [Loading data: Drive, Sheets, and Google Cloud Storage](/notebooks/io.ipynb) \n",
        "- [Charts: visualizing data](/notebooks/charts.ipynb)\n",
        "- [Getting started with BigQuery](/notebooks/bigquery.ipynb)\n",
        "\n",
        "### Machine Learning Crash Course\n",
        "These are a few of the notebooks from Google's online Machine Learning course. See the [full course website](https://developers.google.com/machine-learning/crash-course/) for more.\n",
        "- [Intro to Pandas DataFrame](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/pandas_dataframe_ultraquick_tutorial.ipynb)\n",
        "- [Linear regression with tf.keras using synthetic data](https://colab.research.google.com/github/google/eng-edu/blob/main/ml/cc/exercises/linear_regression_with_synthetic_data.ipynb)\n",
        "\n",
        "\n",
        "<a name=\"using-accelerated-hardware\"></a>\n",
        "### Using Accelerated Hardware\n",
        "- [TensorFlow with GPUs](/notebooks/gpu.ipynb)\n",
        "- [TensorFlow with TPUs](/notebooks/tpu.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFm2S0Gijqo8"
      },
      "source": [
        "<a name=\"machine-learning-examples\"></a>\n",
        "\n",
        "## Machine Learning Examples\n",
        "\n",
        "To see end-to-end examples of the interactive machine learning analyses that Colaboratory makes possible, check out these  tutorials using models from [TensorFlow Hub](https://tfhub.dev).\n",
        "\n",
        "A few featured examples:\n",
        "\n",
        "- [Retraining an Image Classifier](https://tensorflow.org/hub/tutorials/tf2_image_retraining): Build a Keras model on top of a pre-trained image classifier to distinguish flowers.\n",
        "- [Text Classification](https://tensorflow.org/hub/tutorials/tf2_text_classification): Classify IMDB movie reviews as either *positive* or *negative*.\n",
        "- [Style Transfer](https://tensorflow.org/hub/tutorials/tf2_arbitrary_image_stylization): Use deep learning to transfer style between images.\n",
        "- [Multilingual Universal Sentence Encoder Q&A](https://tensorflow.org/hub/tutorials/retrieval_with_tf_hub_universal_encoder_qa): Use a machine learning model to answer questions from the SQuAD dataset.\n",
        "- [Video Interpolation](https://tensorflow.org/hub/tutorials/tweening_conv3d): Predict what happened in a video between the first and the last frame.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "NLP Project- LSTM based NN",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}